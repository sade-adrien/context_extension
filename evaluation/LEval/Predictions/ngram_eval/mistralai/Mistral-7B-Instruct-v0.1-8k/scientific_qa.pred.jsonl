{"query": "How did they obtain the dataset?", "gt": "public resources where suspicious Twitter accounts were annotated, list with another 32 Twitter accounts from BIBREF19 that are considered trustworthy", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 20 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "They obtained the dataset by using two lists of annotated Twitter accounts.", "evaluation": "f1"}
{"query": "What activation function do they use in their model?", "gt": "relu, selu, tanh", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "They use ReLU activation function.", "evaluation": "f1"}
{"query": "What baselines do they compare to?", "gt": "Top-$k$ replies, likes, or re-tweets, FacTweet (tweet-level), LR + All Features (chunk-level), LR + All Features (tweet-level), Tweet2vec, LR + Bag-of-words", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 21 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "They compare their approach to several baselines, including LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), and Top-$k$ replies, likes, or re-tweets.", "evaluation": "f1"}
{"query": "How are chunks defined?", "gt": "Chunks is group of tweets from single account that  is consecutive in time - idea is that this group can show secret intention of malicious accounts.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 26 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Chunks are defined as a sorted sequence of tweets labeled by the corresponding account, with each tweet represented by a vector of features.", "evaluation": "f1"}
{"query": "What features are extracted?", "gt": "Sentiment, Morality, Style, Words embeddings", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Features extracted: sentiment, morality, style, words embeddings.", "evaluation": "f1"}
{"query": "What features are extracted?", "gt": "15 emotion types, sentiment classes, positive and negative, care, harm, fairness, cheating, loyalty, betrayal, authority, subversion, sanctity, and degradation, count of question marks, exclamation marks, consecutive characters and letters, links, hashtags, users' mentions, uppercase ratio, tweet length, words embeddings", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 39 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The features extracted in this work include emotion, sentiment, morality, style, words embeddings, and hashtags. These features are used to detect non-factual Twitter accounts by treating post streams as a sequence of tweet chunks.", "evaluation": "f1"}
{"query": "Was the approach used in this work to detect fake news fully supervised?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "Based on this paper, what is the more predictive set of features to detect fake news?", "gt": "words embeddings, style, and morality features", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Words embeddings, style, and morality features.", "evaluation": "f1"}
{"query": "How big is the dataset used in this work?", "gt": "Total dataset size: 171 account (522967 tweets)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 7 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset used in this work is large.", "evaluation": "f1"}
{"query": "How is a \"chunk of posts\" defined in this work?", "gt": "chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 16 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "A \"chunk of posts\" in this work is a sorted sequence of tweets labeled by the corresponding account.", "evaluation": "f1"}
{"query": "What baselines were used in this work?", "gt": "LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 21 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The baselines used in this work include LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), and Top-$k$ replies, likes, or re-tweets.", "evaluation": "f1"}
{"query": "What models are used in the experiment?", "gt": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Three-level annotation model, SVM, BiLSTM, CNN.", "evaluation": "f1"}
{"query": "What are the differences between this dataset and pre-existing ones?", "gt": "no prior work has explored the target of the offensive language", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "This dataset includes a hierarchical annotation model for offensive language detection, categorization, and target identification.", "evaluation": "f1"}
{"query": "In what language are the tweets?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "English", "evaluation": "f1"}
{"query": "What is the size of the new dataset?", "gt": "14,100 tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Large publicly available dataset.", "evaluation": "f1"}
{"query": "What is the size of the new dataset?", "gt": "Dataset contains total of 14100 annotations.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "New dataset has 14,100 tweets.", "evaluation": "f1"}
{"query": "What kinds of offensive content are explored?", "gt": "non-targeted profanity and swearing, targeted insults such as cyberbullying, offensive content related to ethnicity, gender or sexual orientation, political affiliation, religious belief, and anything belonging to hate speech", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 28 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper explores offensive content in social media, specifically focusing on abusive language, hate speech, toxic comments, and offensive language.", "evaluation": "f1"}
{"query": "What is the best performing model?", "gt": "CNN ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "CNN", "evaluation": "f1"}
{"query": "How many annotators participated?", "gt": "five annotators", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "200", "evaluation": "f1"}
{"query": "What is the definition of offensive language?", "gt": " Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 77 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Offensive language refers to any form of language that is considered inappropriate, derogatory, or harmful to a particular individual or group. This can include insults, threats, profanity, and other forms of language that are intended to offend or harm. Offensive language can be directed towards a specific individual or group, or it can be generalized and directed towards a broader group or category. The definition of offensive language can vary depending on the context and the individuals or groups involved.", "evaluation": "f1"}
{"query": "What are the three layers of the annotation scheme?", "gt": "Level A: Offensive language Detection\n, Level B: Categorization of Offensive Language\n, Level C: Offensive Language Target Identification\n", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The three layers of the annotation scheme are: Level A: Offensive language detection, Level B: Categorization of offensive language, and Level C: Offensive language target identification.", "evaluation": "f1"}
{"query": "How long is the dataset for each step of hierarchy?", "gt": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Dataset for each step of hierarchy: 14,100 tweets.", "evaluation": "f1"}
{"query": "What is the approach of previous work?", "gt": "'shallow' naive Bayes, SVM, hierarchical stacked classifiers, bidirectional recurrent neural networks", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Previous work used shallow methods like Naive Bayes and SVMs for LID.", "evaluation": "f1"}
{"query": "Is the lexicon the same for all languages?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "How do they obtain the lexicon?", "gt": "built over all the data and therefore includes the vocabulary from both the training and testing sets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The lexicon is built over all the data and therefore includes the vocabulary from both the training and testing sets.", "evaluation": "f1"}
{"query": "What evaluation metric is used?", "gt": "average classification accuracy, execution performance", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Accuracy is used as evaluation metric.", "evaluation": "f1"}
{"query": "Which languages are similar to each other?", "gt": "Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The 11 official languages of South Africa are similar to each other.", "evaluation": "f1"}
{"query": "Which datasets are employed for South African languages LID?", "gt": "DSL 2015, DSL 2017, JW300 parallel corpus , NCHLT text corpora", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "NCHLT text corpora, DSL 2015 & 2017, JW300, WiLI-2018, NCHLT, NCHLT text corpora, NCHLT, NCHLT, NCHLT, NCHLT, NCHLT.", "evaluation": "f1"}
{"query": "Does the paper report the performance of a baseline model on South African languages LID?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Yes.", "evaluation": "f1"}
{"query": "Does the algorithm improve on the state-of-the-art methods?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Yes.", "evaluation": "f1"}
{"query": "Do they report results only on English data?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "Do they report results only on English data?", "gt": "The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No, the results are reported on both English and non-English data.", "evaluation": "f1"}
{"query": "What evidence do the authors present that the model can capture some biases in data annotation and collection?", "gt": "Waseem-dataset, Davidson-dataset,", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Evidence: Manual inspection, misclassifications.", "evaluation": "f1"}
{"query": "Which publicly available datasets are used?", "gt": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Two publicly available datasets are used: Waseem and Hovy BIBREF5 and Davidson et al. BIBREF9.", "evaluation": "f1"}
{"query": "What baseline is used?", "gt": "BERT based fine-tuning, Insert nonlinear layers, Insert Bi-LSTM layer, Insert CNN layer", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The baselines used are Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10.", "evaluation": "f1"}
{"query": "What new fine-tuning methods are presented?", "gt": "sampling tweets from specific keywords create systematic and substancial racial biases in datasets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "New fine-tuning methods are presented for hate speech detection using pre-trained BERT.", "evaluation": "f1"}
{"query": "What are the existing biases?", "gt": "Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Existing biases in hate speech detection include racial, gender, and religious biases, as well as biases in data collection and annotation methods.", "evaluation": "f1"}
{"query": "What biases does their model capture?", "gt": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The model captures biases in data collection and annotation.", "evaluation": "f1"}
{"query": "What does the \"sensitivity\" quantity denote?", "gt": "the number of distinct word recognition outputs that an attacker can induce", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The \"sensitivity\" quantity denotes the expected number of unique outputs a word recognition system assigns to a set of adversarial perturbations.", "evaluation": "f1"}
{"query": "What end tasks do they evaluate on?", "gt": "Sentiment analysis and paraphrase detection under adversarial attacks", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Sentiment analysis, paraphrase detection.", "evaluation": "f1"}
{"query": "What is a semicharacter architecture?", "gt": "A semi-character based RNN (ScRNN) treats the first and last characters individually, and is agnostic to the ordering of the internal characters", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "A semicharacter architecture is a type of natural language processing (NLP) model that uses a combination of character-level and word-level processing to recognize words in a sentence.", "evaluation": "f1"}
{"query": "Do they experiment with offering multiple candidate corrections and voting on the model output, since this seems highly likely to outperform a one-best correction?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "Why is the adversarial setting appropriate for misspelling recognition?", "gt": "Adversarial misspellings are a real-world problem", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Adversarial setting appropriate for misspelling recognition.", "evaluation": "f1"}
{"query": "How do the backoff strategies work?", "gt": "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 43 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The backoff strategies work by using a secondary model to predict the correct word when the primary model fails to recognize a word. The secondary model can be a more general model or a specialized model trained on a larger corpus. The backoff strategies can be used to reduce the sensitivity of the primary model and improve its robustness against adversarial attacks.", "evaluation": "f1"}
{"query": "What baseline model is used?", "gt": "same baseline as used by lang2011unsupervised", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The baseline model used is a dependency-based model.", "evaluation": "f1"}
{"query": "Which additional latent variables are used in the model?", "gt": "CLV as a parent of the two corresponding role variables", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Crosslingual latent variables are used in the model.", "evaluation": "f1"}
{"query": "Which additional latent variables are used in the model?", "gt": "crosslingual latent variables", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Crosslingual Latent Variables", "evaluation": "f1"}
{"query": "Which parallel corpora are used?", "gt": "English (EN) and German (DE) sections of the CoNLL 2009 corpus BIBREF13, EN-DE section of the Europarl corpus BIBREF14", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The parallel corpora used are English-German.", "evaluation": "f1"}
{"query": "Overall, does having parallel data improve semantic role induction across multiple languages?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "Do they add one latent variable for each language pair in their Bayesian model?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "What does an individual model consist of?", "gt": "Bayesian model of garg2012unsupervised as our base monolingual model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 9 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "An individual model consists of a set of parameters and a generative process.", "evaluation": "f1"}
{"query": "Do they improve on state-of-the-art semantic role induction?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "how many tags do they look at?", "gt": "48,705", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Many", "evaluation": "f1"}
{"query": "which algorithm was the highest performer?", "gt": "A hybrid model consisting of best performing popularity-based approach with the best similarity-based approach", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The highest performer was the hybrid approach combining popularity-based and similarity-based algorithms.", "evaluation": "f1"}
{"query": "how is diversity measured?", "gt": " the average dissimilarity of all pairs of tags in the list of recommended tags", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Diversity is measured as the average dissimilarity of all pairs of tags in the list of recommended tags.", "evaluation": "f1"}
{"query": "how large is the vocabulary?", "gt": "33,663", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Vocabulary size: Large.", "evaluation": "f1"}
{"query": "what dataset was used?", "gt": " E-book annotation data: editor tags, Amazon search terms, and  Amazon review keywords.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset used in the study was a collection of e-book annotations and Amazon search terms.", "evaluation": "f1"}
{"query": "what algorithms did they use?", "gt": "popularity-based, similarity-based, hybrid", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "They used 19 different algorithms.", "evaluation": "f1"}
{"query": "What baseline method is used?", "gt": "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The baseline method used in the study is the word2vec algorithm.", "evaluation": "f1"}
{"query": "What details are given about the Twitter dataset?", "gt": "one of the Twitter datasets is about Turkish mobile network operators, there are positive, neutral and negative labels and provide the total amount plus the distribution of labels", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 28 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The Twitter dataset used in the study consists of nearly 1.6 million tweets annotated through a distant supervised method with positive, neutral, and negative labels.", "evaluation": "f1"}
{"query": "What details are given about the movie domain dataset?", "gt": "there are 20,244 reviews divided into positive and negative with an average 39 words per review, each one having a star-rating score", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The movie domain dataset is a collection of movie reviews in Turkish, with positive and negative labels.", "evaluation": "f1"}
{"query": "Which hand-crafted features are combined with word2vec?", "gt": "polarity scores, which are minimum, mean, and maximum polarity scores, from each review", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Hand-crafted features are combined with word2vec.", "evaluation": "f1"}
{"query": "What word-based and dictionary-based feature are used?", "gt": "generate word embeddings specific to a domain, TDK (T\u00fcrk Dil Kurumu - \u201cTurkish Language Institution\u201d) dictionary to obtain word polarities", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 20 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Word-based features: Word2vec embeddings, clustering, SVD. Dictionary-based features: TDK dictionary, sentiment lexicons.", "evaluation": "f1"}
{"query": "How are the supervised scores of the words calculated?", "gt": "(+1 or -1), words of opposite polarities (e.g. \u201chappy\" and \u201cunhappy\") get far away from each other", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The supervised scores of the words are calculated by taking into account the polarity scores of the words occurring in the same contexts as the target word. The minimum, maximum, and average scores are taken into consideration.", "evaluation": "f1"}
{"query": "What topic is covered in the Chinese Facebook data? ", "gt": "anti-nuclear-power", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Nuclear power", "evaluation": "f1"}
{"query": "How many layers does the UTCNN model have?", "gt": "eight layers", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "3-layer", "evaluation": "f1"}
{"query": "What topics are included in the debate data?", "gt": "abortion, gay rights, Obama, marijuana", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "CreateDebate dataset includes 4 topics: abortion, gay rights, Obama, and marijuana.", "evaluation": "f1"}
{"query": "What topics are included in the debate data?", "gt": "abortion (ABO), gay rights (GAY), Obama (OBA), and marijuana (MAR)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "CreateDebate dataset includes 4 topics: abortion, gay rights, Obama, and marijuana.", "evaluation": "f1"}
{"query": "What is the size of the Chinese data?", "gt": "32,595", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Large.", "evaluation": "f1"}
{"query": "Did they collected the two datasets?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Yes.", "evaluation": "f1"}
{"query": "What are the baselines?", "gt": "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The baselines for the proposed model are SVM with unigram, bigram, and trigram features, SVM with average word embedding, SVM with average transformed word embeddings, CNN, and Recurrent Convolutional Neural Networks (RCNN).", "evaluation": "f1"}
{"query": "why are their techniques cheaper to implement?", "gt": "They use a slightly modified copy of the target to create the pseudo-text instead of full BT to make their technique cheaper", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The techniques are cheaper to implement because they do not require additional computational resources or specialized hardware.", "evaluation": "f1"}
{"query": "what data simulation techniques were introduced?", "gt": "copy, copy-marked, copy-dummies", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Simulation techniques for NMT.", "evaluation": "f1"}
{"query": "what is their explanation for the effectiveness of back-translation?", "gt": "when using BT, cases where the source is shorter than the target are rarer; cases when they have the same length are more frequent, automatic word alignments between artificial sources tend to be more monotonic than when using natural sources", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 40 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Back-translation (BT) is a technique used to generate artificial parallel data for training neural machine translation (NMT) systems. It involves translating a sentence from one language to another and then translating it back to the original language. The effectiveness of BT is due to the fact that it helps the NMT system learn to generate more fluent and natural-sounding sentences. Additionally, BT can help the NMT system learn to better handle domain-specific vocabulary and syntax.", "evaluation": "f1"}
{"query": "what dataset is used?", "gt": "Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset used in the paper is the Europarl corpus for English-French and English-German translation.", "evaluation": "f1"}
{"query": "what language pairs are explored?", "gt": "English-German, English-French", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "English-French, English-German", "evaluation": "f1"}
{"query": "what language is the data in?", "gt": "English , German, French", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 4 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The data is in English.", "evaluation": "f1"}
{"query": "What metrics are used for evaluation?", "gt": "BLEU-1/4 and ROUGE-L, likelihood of generated recipes using identical input specifications but conditioned on ten different user profiles, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), neural scoring model from BIBREF33 to measure recipe-level coherence", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 35 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper presents a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences. The authors release a new dataset of 180K+ recipes and 700K+ user reviews for this task. They introduce new evaluation strategies for generation quality, centering on quantitative measures of coherence. They show that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "What natural language(s) are the recipes written in?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper \"Generating Plausible and Personalized Recipes from Incomplete Input Specifications\" presents a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences. The authors release a new dataset of 180K+ recipes and 700K+ user reviews for this task. They introduce new evaluation strategies for generation quality, centering on quantitative measures of coherence. The authors show that personalized models generate high-quality and specific recipes that align with historical user preferences. The paper is related to data-to-text natural language generation and recipe generation. The model's input specification consists of the recipe name as a sequence of tokens, a partial list of ingredients, and a caloric level. The output is the recipe instructions as a token sequence. The encoder has three embedding layers: vocabulary embedding, ingredient embedding, and caloric-level embedding. The decoder is a two-layer GRU with hidden state conditioned on previous hidden state and input token from the original recipe text. The authors attend over a user's previously reviewed recipes to jointly determine the final output token distribution. They consider two different schemes to model preferences from user histories: recipe interactions and techniques seen therein. The authors obtain the set of prior recipes for a user: $R^+_u$, where each recipe can be represented by an embedding from a recipe embedding layer or an average of the name tokens embedded by $\\mathcal {V}$. They attend over the $k$-most recent prior recipes, $R^{k+}_u$, to account for temporal drift of user preferences. The authors calculate the token probability:\n$P(w_{r, t}|w_{r, 1:t-1}, \\mathbf {h}_{t-1}, \\mathbf {a}_{t}^{i}, \\mathbf {a}_{t}^{r_u})$\nand maximize the log-likelihood of the generated sequence conditioned on input specifications and user preferences. The authors fuse all contexts calculated at time $t$, concatenating them with decoder GRU output and previous token embedding:\n$\\hat{\\mathbf {h}}_{t} = \\text{Fuse}(\\mathbf {h}_{t-1}, \\mathbf {a}_{t}^{i}, \\mathbf {a}_{t}^{r_u}, \\mathbf {y}_{t})$\nwhere $\\mathbf {y}_{t}$ is the dec", "evaluation": "f1"}
{"query": "What were their results on the new dataset?", "gt": "average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper presents a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences. The authors release a new dataset of 180K+ recipes and 700K+ user reviews for this task. They introduce new evaluation strategies for generation quality in instructional texts, centering on quantitative measures of coherence. The authors attend over historical user preferences from previously consumed recipes to jointly determine the final output token distribution. They fuse all contexts calculated at time $t$, concatenating them with decoder GRU output and previous token embedding. The authors show that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "What are the baseline models?", "gt": "name-based Nearest-Neighbor model (NN), Encoder-Decoder baseline with ingredient attention (Enc-Dec)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper proposes a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences. The authors release a new dataset of 180K+ recipes and 700K+ user reviews for this task. They introduce new evaluation strategies for generation quality in instructional texts, centering on quantitative measures of coherence. The authors attend over historical user preferences from previously consumed recipes to jointly determine the final output token distribution. They fuse all contexts calculated at time $t$, concatenating them with decoder GRU output and previous token embedding. The authors show that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "How did they obtain the interactions?", "gt": "from Food.com", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Recipe Generation", "evaluation": "f1"}
{"query": "Where do they get the recipes from?", "gt": "from Food.com", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Recipe Generation", "evaluation": "f1"}
{"query": "what are their results on the constructed dataset?", "gt": "AutoJudge consistently and significantly outperforms all the baselines, RC models achieve better performance than most text classification models (excluding GRU+Attention), Comparing with conventional RC models, AutoJudge achieves significant improvement", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 29 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The results on the constructed dataset show that the proposed model, AutoJudge, outperforms all baselines, including RC models and other neural text classification models.", "evaluation": "f1"}
{"query": "what evaluation metrics are reported?", "gt": "precision, recall, F1 and accuracy", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Precision, Recall, F1-score, Accuracy.", "evaluation": "f1"}
{"query": "what civil field is the dataset about?", "gt": "divorce", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Divorce", "evaluation": "f1"}
{"query": "what are the state-of-the-art models?", "gt": "SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "State-of-the-art models for text classification and reading comprehension.", "evaluation": "f1"}
{"query": "what is the size of the real-world civil case dataset?", "gt": "100 000 documents", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "7 times more than criminal cases.", "evaluation": "f1"}
{"query": "what datasets are used in the experiment?", "gt": "build a new one, collect INLINEFORM0 cases from China Judgments Online", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The experiment uses a large-scale Chinese civil case dataset.", "evaluation": "f1"}
{"query": "What domains are covered in the corpus?", "gt": "No specific domain is covered in the corpus.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The corpus covers various domains.", "evaluation": "f1"}
{"query": "What is the architecture of their model?", "gt": "follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The architecture of their model is not specified in the given document.", "evaluation": "f1"}
{"query": "How was the dataset collected?", "gt": "Contributors record voice clips by reading from a bank of donated sentences.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset was collected through crowdsourcing and professional translations.", "evaluation": "f1"}
{"query": "Which languages are part of the corpus?", "gt": "French, German, Dutch, Russian, Spanish, Italian, Turkish, Persian, Swedish, Mongolian and Chinese", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The corpus includes 11 languages into English, diversified with over 11,000 speakers and over 60 accents.", "evaluation": "f1"}
{"query": "How is the quality of the data empirically evaluated? ", "gt": "Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test sets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The quality of the data in CoVoST is empirically evaluated using various sanity checks such as sentence-level BLEU, perplexity, and ratio of English characters in translations. Additionally, the overlap between CoVoST transcripts and Tatoeba sentences is reported.", "evaluation": "f1"}
{"query": "Is the data in CoVoST annotated for dialect?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "Is Arabic one of the 11 languages in CoVost?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "What kind of model do they use?", "gt": "visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 39 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The authors use a combination of textual and visual representations to predict document quality. They use a bi-directional LSTM for textual representations and Inception for visual representations. They then combine these two representations using a simple feed-forward layer.", "evaluation": "f1"}
{"query": "What kind of model do they use?", "gt": "Inception V3, biLSTM", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "They use a joint model.", "evaluation": "f1"}
{"query": "Did they release their data set of academic papers?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "Do the methods that work best on academic papers also work best on Wikipedia?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "What is their system's absolute accuracy?", "gt": "59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 26 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The system's absolute accuracy is 59.4% on Wikipedia and 70.2% on arXiv.", "evaluation": "f1"}
{"query": "Which is more useful, visual or textual features?", "gt": "It depends on the dataset. Experimental results over two datasets reveal that textual and visual features are complementary. ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Both visual and textual features are useful for document quality assessment.", "evaluation": "f1"}
{"query": "Which languages do they use?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "English", "evaluation": "f1"}
{"query": "How large is their data set?", "gt": "a sample of  29,794 wikipedia articles and 2,794 arXiv papers ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset has 29,794 articles.", "evaluation": "f1"}
{"query": "Where do they get their ground truth quality judgments?", "gt": "quality class labels assigned by the Wikipedia community, a paper is considered to have been accepted (i.e. is positively labeled) if it matches a paper in the DBLP database or is otherwise accepted by any of the following conferences: ACL, EMNLP, NAACL, EACL, TACL, NIPS, ICML, ICLR, or AAAI", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 49 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The ground truth quality judgments for the Wikipedia dataset are based on the quality ratings assigned by the Wikipedia community through a consensus-based process. For the arXiv dataset, the ground truth quality judgments are based on the acceptance or rejection of papers by top-tier conferences in the field of computer science.", "evaluation": "f1"}
{"query": "What is the seed lexicon?", "gt": "a vocabulary of positive and negative predicates that helps determine the polarity score of an event", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 16 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The seed lexicon is a list of positive and negative words used in the proposed method for recognizing the sentiment polarity of an event. The list consists of 15 positive words and 15 negative words. The positive words are \"\u559c\u3076\", \"\u5b09\u3057\u3044\", \"\u697d\u3057\u3044\", \"\u5e78\u305b\", \"\u611f\u52d5\", \"\u8208\u596e\", \"\u61d0\u304b\u3057\u3044\", \"\u597d\u304d\", \"\u5c0a\u656c\", \"\u5b89\u5fc3\", \"\u611f\u5fc3\", \"\u843d\u3061\u7740\u304f\", \"\u6e80\u8db3\", \"\u7652\u3055\u308c\u308b\", and \"\u30b9\u30c3\u30ad\u30ea\". The negative words are \"\u6012\u308b\", \"\u60b2\u3057\u3044\", \"\u5bc2\u3057\u3044\", \"\u6016\u3044\", \"\u4e0d\u5b89\", \"\u6065\u305a\u304b\u3057\u3044\", \"\u5acc\", \"\u843d\u3061\u8fbc\u3080\", \"\u9000\u5c48\", \"\u7d76\u671b\", \"\u8f9b\u3044\", \"\u56f0\u308b\", \"\u6182\u9b31\", \"\u5fc3\u914d\", and \"\u60c5\u3051\u306a\u3044\".", "evaluation": "f1"}
{"query": "What is the seed lexicon?", "gt": "seed lexicon consists of positive and negative predicates", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The seed lexicon is a list of positive and negative words used in the proposed method for recognizing the sentiment polarity of an event.", "evaluation": "f1"}
{"query": "What are the results?", "gt": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 94 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper proposes a method for recognizing the sentiment polarity of an event using discourse relation-based event pairs. The method requires a very small seed lexicon and a large raw corpus. The seed lexicon consists of positive and negative predicates, and if the predicate of an extracted event is in the seed lexicon and does not involve complex phenomena like negation, the corresponding polarity score is assigned to the event. The method depends only on raw texts and thus has wider applicability. The paper presents experiments using a Japanese web corpus and a collection of affective events. The results show that the proposed method performed well, even with a minimal amount of supervision.", "evaluation": "f1"}
{"query": "How are relations used to propagate polarity?", "gt": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Discourse relations are used to propagate polarity by exploiting the tendency of events to be of the same or opposite polarity based on their discourse relation type (Cause or Concession). The seed lexicon is used to assign initial polarity scores to events, and the polarity function is trained using a combination of automatically labeled pairs (AL), cause/concession pairs (CA), and supervised training data (ACP). The objective functions for each type of event pair are defined using mean squared error, and the model is trained using the Adam optimizer. The model is evaluated on the test set of the ACP Corpus and achieves an accuracy of 81.5%.", "evaluation": "f1"}
{"query": "How big is the Japanese data?", "gt": "The ACP corpus has around 700k events split into positive and negative polarity ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The Japanese data is a large corpus of text that was compiled through various procedures. It contains millions of sentences and is used for various natural language processing tasks.", "evaluation": "f1"}
{"query": "What are labels available in dataset for supervision?", "gt": "negative, positive", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Labels available.", "evaluation": "f1"}
{"query": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "gt": "3%", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Significant.", "evaluation": "f1"}
{"query": "How does their model learn using mostly raw data?", "gt": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The model learns using discourse relations to propagate affective event polarities from seeds.", "evaluation": "f1"}
{"query": "How big is seed lexicon used for training?", "gt": "30 words", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Small seed lexicon.", "evaluation": "f1"}
{"query": "How large is raw corpus used for training?", "gt": "100 million sentences", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Large raw corpus.", "evaluation": "f1"}
{"query": "What data is the language model pretrained on?", "gt": "Chinese general corpus", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "BERT-base", "evaluation": "f1"}
{"query": "What baselines is the proposed model compared against?", "gt": "BERT-Base, QANet", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "BERT, QANet", "evaluation": "f1"}
{"query": "How is the clinical text structuring task defined?", "gt": "Clinical text structuring (CTS) is a critical task for fetching medical research data from electronic health records (EHRs), where structural patient medical data, such as whether the patient has specific symptoms, diseases, or what the tumor size is, how far from the tumor is cut at during the surgery, or what the specific laboratory test result is, are obtained., Unlike the traditional CTS task, our QA-CTS task aims to discover the most related text from original paragraph text. ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 78 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Clinical text structuring (CTS) is a task that involves extracting structured information from unstructured clinical text. It is a final problem in the field of clinical natural language processing (NLP) and has practical applications in biomedical research and clinical decision making. The task involves identifying and extracting specific pieces of information from a given text, such as tumor size, proximal resection margin, or distal resection margin. The goal of CTS is to provide a structured representation of the information in the text, which can be used for further analysis or decision making.", "evaluation": "f1"}
{"query": "How is the clinical text structuring task defined?", "gt": "CTS is extracting structural data from medical research data (unstructured). Authors define QA-CTS task that aims to discover most related text from original text.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Clinical text structuring (CTS) is the task of extracting structured information from unstructured clinical text.", "evaluation": "f1"}
{"query": "What are the specific tasks being unified?", "gt": " three types of questions, namely tumor size, proximal resection margin and distal resection margin", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Clinical Text Structuring Tasks", "evaluation": "f1"}
{"query": "Is all text in this dataset a question, or are there unrelated sentences in between questions?", "gt": "the dataset consists of pathology reports including sentences and questions and answers about tumor size and resection margins so it does include additional sentences ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset contains both questions and unrelated sentences.", "evaluation": "f1"}
{"query": "How many questions are in the dataset?", "gt": "2,714 ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "17833", "evaluation": "f1"}
{"query": "How they introduce domain-specific features into pre-trained language model?", "gt": "integrate clinical named entity information into pre-trained language model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 9 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Introduce named entity information into pre-trained language model.", "evaluation": "f1"}
{"query": "How big is QA-CTS task dataset?", "gt": "17,833 sentences, 826,987 characters and 2,714 question-answer pairs", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "QA-CTS task dataset is large and diverse.", "evaluation": "f1"}
{"query": "What are strong baseline models in specific tasks?", "gt": "state-of-the-art question answering models (i.e. QANet BIBREF39) and BERT-Base BIBREF26", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Strong baseline models in specific tasks are QANet and BERT-Base.", "evaluation": "f1"}
{"query": "What is the previous work's model?", "gt": "Ternary Trans-CNN", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Transfer Learning", "evaluation": "f1"}
{"query": "What dataset is used?", "gt": "HEOT , A labelled dataset for a corresponding english tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset used is HEOT obtained from Mathur et al.", "evaluation": "f1"}
{"query": "How big is the dataset?", "gt": "3189 rows of text messages", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset is small.", "evaluation": "f1"}
{"query": "How big is the dataset?", "gt": "Resulting dataset was 7934 messages for train and 700 messages for test.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset has 3189 rows of text messages of average length of 116 words and with a range of 1, 1295.", "evaluation": "f1"}
{"query": "How is the dataset collected?", "gt": "A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al, HEOT obtained from one of the past studies done by Mathur et al", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 32 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset used in this study was obtained from one of the past studies done by Mathur et al. where they annotated a set of cleaned tweets obtained from Twitter for conversations happening in the Indian subcontinent. A labelled dataset for corresponding English tweets was also obtained from a study conducted by Davidson et al.", "evaluation": "f1"}
{"query": "Was each text augmentation technique experimented individually?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "What models do previous work use?", "gt": "Ternary Trans-CNN , Hybrid multi-channel CNN and LSTM", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Previous work uses Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) for text classification.", "evaluation": "f1"}
{"query": "Does the dataset contain content from various social media platforms?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Yes.", "evaluation": "f1"}
{"query": "What additional techniques are incorporated?", "gt": "incorporating coding syntax tree model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Statistical Machine Translation, Vocabulary Generation, Neural Model Training, Attention Mechanism, Sigmoidal Optimization.", "evaluation": "f1"}
{"query": "What dataset do they use?", "gt": "A parallel corpus where the source is an English expression of code and the target is Python code.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "They use a text-code parallel corpus with 18805 aligned data in English and Python programming language for training their neural machine translation model.", "evaluation": "f1"}
{"query": "Do they compare to other models?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "What is the architecture of the system?", "gt": "seq2seq translation", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Neural Architecture.", "evaluation": "f1"}
{"query": "What additional techniques could be incorporated to further improve accuracy?", "gt": "phrase-based word embedding, Abstract Syntax Tree(AST)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Incorporating more data and using abstract syntax trees could improve accuracy.", "evaluation": "f1"}
{"query": "What programming language is target language?", "gt": "Python", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Python", "evaluation": "f1"}
{"query": "What dataset is used to measure accuracy?", "gt": "validation data", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Validation data", "evaluation": "f1"}
{"query": "What corpus was the source of the OpenIE extractions?", "gt": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper presents a new QA system called TupleInf that can perform reasoning with Open IE tuples for complex multiple-choice questions that require tuples from multiple sentences. The system uses an ILP-based model of inference with tuples, implemented in a reasoner called TupleInf, and demonstrates that it significantly outperforms TableILP by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The gains persist even when both solvers are provided identical knowledge. The paper also discusses related work and provides an overview of the TupleInf system.", "evaluation": "f1"}
{"query": "What is the accuracy of the proposed technique?", "gt": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 32 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The provided text is an abstract of a research paper titled \"A New ILP-based Model of Inference with Tuples for Complex Multiple-Choice Questions\" by Xiaoming Zhang, et al. The paper presents a new inference model called TupleInf that uses tuples to reason with open information extraction (Open IE) for complex multiple-choice questions. The model is implemented in a reasoner called TupleInf and is compared with two state-of-the-art systems for 4th and 8th grade science exams. The results show that TupleInf outperforms the other systems by more than 11%.", "evaluation": "f1"}
{"query": "Is an entity linking process used?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The document describes a new QA system called TupleInf that uses Open IE based tuples to answer complex multiple-choice questions that require tuples from multiple sentences. The system is designed to perform reasoning with Open IE based tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is implemented in a reasoner called TupleInf and is compared with two state-of-the-art systems for 4th and 8th grade science exams. The results show that TupleInf outperforms the other systems by more than 11%. The system uses an ILP-based model of inference with tuples, implemented in a reasoner called TupleInf, to search for an optimal subgraph that connects terms in the question and answer via rows in a set of curated tables. The system is designed to handle noisy tuples and uses a simple ILP formulation that generalizes well to higher grade levels. The system is also designed to be more robust than other systems that rely on shallow reasoning with large text corpora or deeper, structured reasoning with a small amount of automatically acquired or manually curated knowledge.", "evaluation": "f1"}
{"query": "Are the OpenIE extractions all triples?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper presents a new QA system called TupleInf that can perform reasoning with Open IE tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is designed to handle resource-poor domains where curated knowledge is unavailable. The authors demonstrate that TupleInf significantly outperforms TableILP, a related system, by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The gains persist even when both solvers are provided identical knowledge. The paper also discusses related work in retrieval-based web question-answering and science question-answering.", "evaluation": "f1"}
{"query": "What method was used to generate the OpenIE extractions?", "gt": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 56 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The provided text is an abstract of a research paper titled \"A New ILP-based Model of Inference with Tuples for Complex Multiple-Choice Questions\". The paper presents a new QA system called TupleInf that uses a large, automatically extracted tuple knowledge base (TKB) to answer complex multiple-choice questions in resource-poor domains where curated knowledge is unavailable. The TKB is built using the text corpora (S) from the aristo2016:combining dataset and the corresponding training questions (Q_\\_tr). The paper discusses two classes of related work: retrieval-based web question-answering and science question-answering. The TupleInf system uses a tuple selection process that involves scoring from the TKB and on-the-fly tuples extracted from the text corpora (S). The paper presents experimental results that demonstrate the effectiveness of TupleInf in answering complex multiple-choice questions on the 4th and 8th grade science exams.", "evaluation": "f1"}
{"query": "Can the method answer multi-hop questions?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The provided text is an introduction to a research paper that presents a new QA system called TupleInf. The system is designed to answer complex multiple-choice questions that require tuples from multiple sentences using a large, automatically extracted tuple KB. The authors compare TupleInf with two state-of-the-art systems for 4th and 8th grade science exams and demonstrate that TupleInf outperforms both systems. The paper also discusses related work and provides details on the TupleInf model and experiments.", "evaluation": "f1"}
{"query": "What was the textual source to which OpenIE was applied?", "gt": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The paper presents a new QA system called TupleInf that can perform reasoning with Open IE tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is designed to handle resource-poor domains where curated knowledge is unavailable. The authors use the table-knowledge centered inference model as a candidate system for their work. They demonstrate that TupleInf significantly outperforms TableILP by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The gains persist even when both solvers are provided identical knowledge. The authors also discuss two classes of related work: retrieval-based web question-answering and science question-answering.", "evaluation": "f1"}
{"query": "What OpenIE method was used to generate the extractions?", "gt": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 56 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The provided text is an abstract of a research paper titled \"A New ILP-based Model of Inference with Tuples for Complex Multiple-Choice Questions\" by Xiaoming Zhang, et al. The paper presents a new inference model called TupleInf that uses tuples to reason with complex multiple-choice questions. TupleInf is an extension of the TableILP system and is implemented in a reasoner called TupleInf. The paper demonstrates that TupleInf significantly outperforms TableILP by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The paper also discusses related work and provides an overview of the tuples used by the solver, the tuple KB, and the tuple selection process.", "evaluation": "f1"}
{"query": "Is their method capable of multi-hop reasoning?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The provided text is an abstract of a research paper titled \"A New ILP-based Model of Inference with Tuples for Complex Multiple-Choice Questions\" by Xiaoyu Zhang, et al. The paper presents a new inference model called TupleInf that uses tuples to reason with complex multiple-choice questions. The model is based on integer linear programming (ILP) and is implemented in a reasoner called TupleInf. The authors demonstrate that TupleInf significantly outperforms a related system called TableILP on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The paper also discusses related work in retrieval-based web question-answering and science question-answering.", "evaluation": "f1"}
{"query": "What models do they propose?", "gt": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "They propose three multimodal models for hate speech detection in tweets with images.", "evaluation": "f1"}
{"query": "Are all tweets in English?", "gt": "Unanswerable", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "No.", "evaluation": "f1"}
{"query": "How large is the dataset?", "gt": " $150,000$ tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Large dataset.", "evaluation": "f1"}
{"query": "What is the results of multimodal compared to unimodal models?", "gt": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The results of multimodal models are not significantly better than unimodal models in hate speech detection on social media.", "evaluation": "f1"}
{"query": "What is author's opinion on why current multimodal models cannot outperform models analyzing only text?", "gt": "Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Author believes complexity and diversity of multimodal relations are challenges.", "evaluation": "f1"}
{"query": "What metrics are used to benchmark the results?", "gt": "F-score, Area Under the ROC Curve (AUC), mean accuracy (ACC), Precision vs Recall plot, ROC curve (which plots the True Positive Rate vs the False Positive Rate)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 27 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The metrics used to benchmark the results are F-score, Area Under the ROC Curve (AUC), and mean accuracy (ACC).", "evaluation": "f1"}
{"query": "How is data collected, manual collection or Twitter api?", "gt": "Twitter API", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Manual collection.", "evaluation": "f1"}
{"query": "How many tweats does MMHS150k contains, 150000?", "gt": "$150,000$ tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "150,000 tweets.", "evaluation": "f1"}
{"query": "What unimodal detection models were used?", "gt": " single layer LSTM with a 150-dimensional hidden state for hate / not hate classification", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Unimodal detection models used: LSTM, CNN, GloVe embeddings.", "evaluation": "f1"}
{"query": "What different models for multimodal detection were proposed?", "gt": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "Proposed models for multimodal hate speech detection include Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), and Textual Kernels Model (TKM).", "evaluation": "f1"}
{"query": "What annotations are available in the dataset - tweat used hate speach or not?", "gt": "No attacks to any community,  racist, sexist, homophobic, religion based attacks, attacks to other communities", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 15 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k_pred": "The dataset contains annotations for hate speech and not hate speech in tweets.", "evaluation": "f1"}
