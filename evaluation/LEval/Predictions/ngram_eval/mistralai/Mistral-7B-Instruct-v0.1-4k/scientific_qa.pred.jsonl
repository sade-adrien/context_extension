{"query": "How did they obtain the dataset?", "gt": "public resources where suspicious Twitter accounts were annotated, list with another 32 Twitter accounts from BIBREF19 that are considered trustworthy", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 20 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "They obtained the dataset by using two lists of annotated Twitter accounts.", "evaluation": "f1"}
{"query": "What activation function do they use in their model?", "gt": "relu, selu, tanh", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "They use ReLU activation function.", "evaluation": "f1"}
{"query": "What baselines do they compare to?", "gt": "Top-$k$ replies, likes, or re-tweets, FacTweet (tweet-level), LR + All Features (chunk-level), LR + All Features (tweet-level), Tweet2vec, LR + Bag-of-words", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 21 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "They compare their approach to several baselines, including LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), and Top-$k$ replies, likes, or re-tweets.", "evaluation": "f1"}
{"query": "How are chunks defined?", "gt": "Chunks is group of tweets from single account that  is consecutive in time - idea is that this group can show secret intention of malicious accounts.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 26 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Chunks are defined as a sorted sequence of tweets labeled by the corresponding account, with each tweet represented by a vector of features.", "evaluation": "f1"}
{"query": "What features are extracted?", "gt": "Sentiment, Morality, Style, Words embeddings", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Features extracted: sentiment, morality, style, words embeddings.", "evaluation": "f1"}
{"query": "What features are extracted?", "gt": "15 emotion types, sentiment classes, positive and negative, care, harm, fairness, cheating, loyalty, betrayal, authority, subversion, sanctity, and degradation, count of question marks, exclamation marks, consecutive characters and letters, links, hashtags, users' mentions, uppercase ratio, tweet length, words embeddings", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 39 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The features extracted in this work include emotion, sentiment, morality, style, words embeddings, and hashtags. These features are used to detect non-factual Twitter accounts by treating post streams as a sequence of tweet chunks.", "evaluation": "f1"}
{"query": "Was the approach used in this work to detect fake news fully supervised?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "Based on this paper, what is the more predictive set of features to detect fake news?", "gt": "words embeddings, style, and morality features", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Words embeddings, style, and morality features.", "evaluation": "f1"}
{"query": "How big is the dataset used in this work?", "gt": "Total dataset size: 171 account (522967 tweets)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 7 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset used in this work is large.", "evaluation": "f1"}
{"query": "How is a \"chunk of posts\" defined in this work?", "gt": "chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 16 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "A \"chunk of posts\" in this work is a sorted sequence of tweets labeled by the corresponding account.", "evaluation": "f1"}
{"query": "What baselines were used in this work?", "gt": "LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 21 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The baselines used in this work include LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), and Top-$k$ replies, likes, or re-tweets.", "evaluation": "f1"}
{"query": "What models are used in the experiment?", "gt": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Three-level annotation model, SVM, BiLSTM, CNN.", "evaluation": "f1"}
{"query": "What are the differences between this dataset and pre-existing ones?", "gt": "no prior work has explored the target of the offensive language", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "This dataset includes a hierarchical annotation model for offensive language detection, categorization, and target identification.", "evaluation": "f1"}
{"query": "In what language are the tweets?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "English", "evaluation": "f1"}
{"query": "What is the size of the new dataset?", "gt": "14,100 tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Large publicly available dataset.", "evaluation": "f1"}
{"query": "What is the size of the new dataset?", "gt": "Dataset contains total of 14100 annotations.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "New dataset has 14,100 tweets.", "evaluation": "f1"}
{"query": "What kinds of offensive content are explored?", "gt": "non-targeted profanity and swearing, targeted insults such as cyberbullying, offensive content related to ethnicity, gender or sexual orientation, political affiliation, religious belief, and anything belonging to hate speech", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 28 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper explores offensive content in social media, specifically focusing on abusive language, hate speech, toxic comments, and offensive language.", "evaluation": "f1"}
{"query": "What is the best performing model?", "gt": "CNN ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "CNN", "evaluation": "f1"}
{"query": "How many annotators participated?", "gt": "five annotators", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "200", "evaluation": "f1"}
{"query": "What is the definition of offensive language?", "gt": " Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 77 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Offensive language refers to any form of language that is considered inappropriate, derogatory, or harmful to a particular individual or group. This can include insults, threats, profanity, and other forms of language that are intended to offend or harm. Offensive language can be directed towards a specific individual or group, or it can be generalized and directed towards a broader group or category. The definition of offensive language can vary depending on the context and the individuals or groups involved.", "evaluation": "f1"}
{"query": "What are the three layers of the annotation scheme?", "gt": "Level A: Offensive language Detection\n, Level B: Categorization of Offensive Language\n, Level C: Offensive Language Target Identification\n", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The three layers of the annotation scheme are: Level A: Offensive language detection, Level B: Categorization of offensive language, and Level C: Offensive language target identification.", "evaluation": "f1"}
{"query": "How long is the dataset for each step of hierarchy?", "gt": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Dataset for each step of hierarchy: 14,100 tweets.", "evaluation": "f1"}
{"query": "What is the approach of previous work?", "gt": "'shallow' naive Bayes, SVM, hierarchical stacked classifiers, bidirectional recurrent neural networks", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Previous work used shallow methods like Naive Bayes and SVMs for LID.", "evaluation": "f1"}
{"query": "Is the lexicon the same for all languages?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "How do they obtain the lexicon?", "gt": "built over all the data and therefore includes the vocabulary from both the training and testing sets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The lexicon is built over all the data and therefore includes the vocabulary from both the training and testing sets.", "evaluation": "f1"}
{"query": "What evaluation metric is used?", "gt": "average classification accuracy, execution performance", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Accuracy is used as evaluation metric.", "evaluation": "f1"}
{"query": "Which languages are similar to each other?", "gt": "Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The 11 official languages of South Africa are similar to each other.", "evaluation": "f1"}
{"query": "Which datasets are employed for South African languages LID?", "gt": "DSL 2015, DSL 2017, JW300 parallel corpus , NCHLT text corpora", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "NCHLT text corpora, DSL 2015 & 2017, JW300, WiLI-2018, NCHLT, NCHLT text corpora, NCHLT, NCHLT, NCHLT, NCHLT, NCHLT.", "evaluation": "f1"}
{"query": "Does the paper report the performance of a baseline model on South African languages LID?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "Does the algorithm improve on the state-of-the-art methods?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "Do they report results only on English data?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "Do they report results only on English data?", "gt": "The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No, the proposed transfer learning approach for hate speech understanding can be applied to low-resource hate speech languages and improved the task performance on publicly available benchmark datasets.", "evaluation": "f1"}
{"query": "What evidence do the authors present that the model can capture some biases in data annotation and collection?", "gt": "Waseem-dataset, Davidson-dataset,", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Evidence: Bias Detection", "evaluation": "f1"}
{"query": "Which publicly available datasets are used?", "gt": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The document discusses the problem of online abusive detection, specifically hate speech, and proposes a transfer learning approach using the pre-trained language model BERT.", "evaluation": "f1"}
{"query": "What baseline is used?", "gt": "BERT based fine-tuning, Insert nonlinear layers, Insert Bi-LSTM layer, Insert CNN layer", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The baseline used is a logistic regression model with different sets of features.", "evaluation": "f1"}
{"query": "What new fine-tuning methods are presented?", "gt": "sampling tweets from specific keywords create systematic and substancial racial biases in datasets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper presents four new fine-tuning methods for hate speech detection using a pre-trained BERT model.", "evaluation": "f1"}
{"query": "What are the existing biases?", "gt": "Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The existing body of knowledge on online hate speech and offensive language includes features such as bag of words, word-level and character-level $n$-grams, and different algorithms such as Support Vector Machines, Naive Baye, and Logistic Regression.", "evaluation": "f1"}
{"query": "What biases does their model capture?", "gt": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The model captures biases in the process of collecting or annotating datasets.", "evaluation": "f1"}
{"query": "What does the \"sensitivity\" quantity denote?", "gt": "the number of distinct word recognition outputs that an attacker can induce", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The \"sensitivity\" quantity denotes the expected number of unique outputs a word recognition system assigns to a set of adversarial perturbations.", "evaluation": "f1"}
{"query": "What end tasks do they evaluate on?", "gt": "Sentiment analysis and paraphrase detection under adversarial attacks", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper evaluates on text classification tasks.", "evaluation": "f1"}
{"query": "What is a semicharacter architecture?", "gt": "A semi-character based RNN (ScRNN) treats the first and last characters individually, and is agnostic to the ordering of the internal characters", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a task-agnostic defense against adversarial attacks on text classification by attaching a word recognition model that predicts each word in a sentence given a full sequence of (possibly misspelled) inputs. The word recognition model's outputs form the input to a downstream classification model. The paper demonstrates that an adversary can degrade a classifier's performance to that achieved by random guessing by altering just two characters per sentence. The paper also evaluates first-line techniques including data augmentation and adversarial training, and proposes a simple two-stage solution, placing a word recognition model before the downstream classifier, to tackle character-level adversarial attacks. The paper also discusses the importance of the accuracy of the word recognition model and its sensitivity to adversarial perturbations on the same input.", "evaluation": "f1"}
{"query": "Do they experiment with offering multiple candidate corrections and voting on the model output, since this seems highly likely to outperform a one-best correction?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "Why is the adversarial setting appropriate for misspelling recognition?", "gt": "Adversarial misspellings are a real-world problem", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Adversarial setting appropriate for misspelling recognition.", "evaluation": "f1"}
{"query": "How do the backoff strategies work?", "gt": "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 43 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a defense against adversarial attacks on text classification by using a word recognition model that predicts each word in a sentence given a full sequence of (possibly misspelled) inputs. The word recognition model's outputs form the input to a downstream classification model. The paper also introduces a two-stage solution, placing a word recognition model before the downstream classifier, and discusses the importance of the accuracy of the word recognition model and its sensitivity to adversarial perturbations.", "evaluation": "f1"}
{"query": "What baseline model is used?", "gt": "same baseline as used by lang2011unsupervised", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Bayesian model of garg2012unsupervised.", "evaluation": "f1"}
{"query": "Which additional latent variables are used in the model?", "gt": "CLV as a parent of the two corresponding role variables", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The model uses crosslingual latent variables to incorporate soft role agreement between aligned constituents.", "evaluation": "f1"}
{"query": "Which additional latent variables are used in the model?", "gt": "crosslingual latent variables", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Latent variables are used in the model.", "evaluation": "f1"}
{"query": "Which parallel corpora are used?", "gt": "English (EN) and German (DE) sections of the CoNLL 2009 corpus BIBREF13, EN-DE section of the Europarl corpus BIBREF14", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a joint Bayesian model for unsupervised semantic role induction in multiple languages. The model consists of individual Bayesian models for each language and crosslingual latent variables to incorporate soft role agreement between aligned constituents. The model is evaluated on the English and German sections of the CoNLL 2009 corpus and the EN-DE section of the Europarl corpus.", "evaluation": "f1"}
{"query": "Overall, does having parallel data improve semantic role induction across multiple languages?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "Do they add one latent variable for each language pair in their Bayesian model?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "What does an individual model consist of?", "gt": "Bayesian model of garg2012unsupervised as our base monolingual model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 9 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a joint Bayesian model for unsupervised semantic role induction in multiple languages.", "evaluation": "f1"}
{"query": "Do they improve on state-of-the-art semantic role induction?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "how many tags do they look at?", "gt": "48,705", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Annotate", "evaluation": "f1"}
{"query": "which algorithm was the highest performer?", "gt": "A hybrid model consisting of best performing popularity-based approach with the best similarity-based approach", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The highest performer was the hybrid approach that combined popularity-based and similarity-based methods.", "evaluation": "f1"}
{"query": "how is diversity measured?", "gt": " the average dissimilarity of all pairs of tags in the list of recommended tags", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Diversity is measured as the average dissimilarity of all pairs of tags in the list of recommended tags.", "evaluation": "f1"}
{"query": "how large is the vocabulary?", "gt": "33,663", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Large.", "evaluation": "f1"}
{"query": "what dataset was used?", "gt": " E-book annotation data: editor tags, Amazon search terms, and  Amazon review keywords.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset used for this study is a collection of e-book annotation data from 13 publishers.", "evaluation": "f1"}
{"query": "what algorithms did they use?", "gt": "popularity-based, similarity-based, hybrid", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "They used 19 algorithms.", "evaluation": "f1"}
{"query": "What baseline method is used?", "gt": "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper presents a novel approach for sentiment analysis in Turkish using word embeddings. The authors combine unsupervised and supervised scores to generate a unified score for each dimension of the word embeddings. They also use word2vec embeddings trained on a large corpus. The paper evaluates the performance of their approach on two datasets and outperforms the baseline approaches for both languages.", "evaluation": "f1"}
{"query": "What details are given about the Twitter dataset?", "gt": "one of the Twitter datasets is about Turkish mobile network operators, there are positive, neutral and negative labels and provide the total amount plus the distribution of labels", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 28 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper describes a study on sentiment analysis for Turkish language using word embeddings. The study uses official dictionaries for Turkish and combines unsupervised and supervised scores to generate a unified score for each dimension of the word embeddings. The main contribution of the study is the creation of original and effective word vectors that capture syntactic, semantic, and sentimental characteristics of words. The study also utilizes word2vec embeddings trained on a large corpus and generates hand-crafted features on a review basis. The study evaluates the embeddings on two datasets and outperforms the approaches which do not take into account the sentimental information. The source code and datasets are publicly available.", "evaluation": "f1"}
{"query": "What details are given about the movie domain dataset?", "gt": "there are 20,244 reviews divided into positive and negative with an average 39 words per review, each one having a star-rating score", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper presents a method for generating word embeddings that capture syntactic, semantic, and sentimental characteristics of words in the Turkish language. The method uses the official dictionaries for Turkish and combines unsupervised and supervised scores to generate a unified score for each dimension of the word embeddings. The paper evaluates the performance of the proposed approach on two datasets and outperforms other studies carried out on sentiment analysis in Turkish media. The source code and datasets are publicly available.", "evaluation": "f1"}
{"query": "Which hand-crafted features are combined with word2vec?", "gt": "polarity scores, which are minimum, mean, and maximum polarity scores, from each review", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The hand-crafted features that are combined with word2vec are not explicitly mentioned in the document. However, it is stated that the word2vec embeddings are trained on a large corpus and several unsupervised hand-crafted features are generated on a review basis. These features are then combined with the word2vec embeddings to create document vectors.", "evaluation": "f1"}
{"query": "What word-based and dictionary-based feature are used?", "gt": "generate word embeddings specific to a domain, TDK (T\u00fcrk Dil Kurumu - \u201cTurkish Language Institution\u201d) dictionary to obtain word polarities", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 20 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a novel approach for sentiment analysis in Turkish using word embeddings. The approach combines unsupervised and supervised scores to generate a unified score for each dimension of the word embeddings. The main contribution of the paper is the creation of original and effective word vectors that capture syntactic, semantic, and sentimental characteristics of words. The paper also utilizes word2vec embeddings trained on a large corpus and generates hand-crafted features on a review basis. The paper evaluates the embeddings on two datasets and outperforms the approaches that do not take into account the sentimental information. The paper also outperforms other studies carried out on sentiment analysis in Turkish media and English corpora of different genres. The source code and datasets are publicly available.", "evaluation": "f1"}
{"query": "How are the supervised scores of the words calculated?", "gt": "(+1 or -1), words of opposite polarities (e.g. \u201chappy\" and \u201cunhappy\") get far away from each other", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The supervised scores of the words are calculated using the following formula:\n\n$w_{t}$ = (Nt / N) \\* (1 - N^{\\prime }_{t} / N^{\\prime })\n\nwhere:\n\n* $w_{t}$ is the sentiment score of word $t$\n* $N_{t}$ is the number of documents (reviews or tweets) in which $t$ occurs in the dataset of positive polarity\n* $N$ is the number of all the words in the corpus of positive polarity\n* $N^{\\prime }_{t}$ is the number of documents (reviews or tweets) in which $t$ occurs in the dataset of negative polarity\n* $N^{\\prime }$ is the number of all the words in the corpus of negative polarity\n\nThe formula calculates the sentiment score of a word by taking into account the number of documents in which the word appears in the positive and negative polarity datasets, and normalizing the scores to prevent imbalance.", "evaluation": "f1"}
{"query": "What topic is covered in the Chinese Facebook data? ", "gt": "anti-nuclear-power", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The topic covered in the Chinese Facebook data is anti-nuclear power.", "evaluation": "f1"}
{"query": "How many layers does the UTCNN model have?", "gt": "eight layers", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The UTCNN model has 3 layers.", "evaluation": "f1"}
{"query": "What topics are included in the debate data?", "gt": "abortion, gay rights, Obama, marijuana", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a deep learning model for text stance classification on social media platforms.", "evaluation": "f1"}
{"query": "What topics are included in the debate data?", "gt": "abortion (ABO), gay rights (GAY), Obama (OBA), and marijuana (MAR)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a deep learning model called UTCNN for text classification on social media platforms.", "evaluation": "f1"}
{"query": "What is the size of the Chinese data?", "gt": "32,595", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The size of the Chinese data is 2,496.", "evaluation": "f1"}
{"query": "Did they collected the two datasets?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "What are the baselines?", "gt": "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The baselines for the proposed UTCNN model are not explicitly mentioned in the document. However, it is stated that the model is compared with related work in the text classification domain, which may include models such as CNNs, RNNs, and deep learning models for sentiment analysis.", "evaluation": "f1"}
{"query": "why are their techniques cheaper to implement?", "gt": "They use a slightly modified copy of the target to create the pseudo-text instead of full BT to make their technique cheaper", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper \"Better Understanding Back-Translation for Neural Machine Translation\" presents a study on the use of monolingual data in neural machine translation (NMT). The authors aim to answer several questions about the effectiveness of back-translation (BT) in NMT, including the importance of the quality of the generated data, the properties of back-translated sentences that matter for translation quality, and whether BT acts as a regularizer. The authors reimplement several strategies to use monolingual data in NMT and run experiments on two language pairs in a controlled setting. Their main results suggest that the quality of the generated data is important for translation performance, that certain properties of back-translated sentences matter for translation quality, and that back-translation does not act as a regularizer. The authors also find that using artificial parallel data generated through forward translation can also improve translation performance.", "evaluation": "f1"}
{"query": "what data simulation techniques were introduced?", "gt": "copy, copy-marked, copy-dummies", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper discusses the use of monolingual data in Neural Machine Translation (NMT) systems. The authors propose several strategies to improve the effects of using monolingual data in NMT, including the use of back-translation (BT) and the use of artificial parallel data generated through forward translation (FT). The authors also explore the quality of different types of artificial parallel data, including the use of different MT systems to generate the artificial data. The authors compare the performance of different NMT systems using different types of monolingual data and artificial parallel data, and find that the use of monolingual data can significantly improve the performance of NMT systems.", "evaluation": "f1"}
{"query": "what is their explanation for the effectiveness of back-translation?", "gt": "when using BT, cases where the source is shorter than the target are rarer; cases when they have the same length are more frequent, automatic word alignments between artificial sources tend to be more monotonic than when using natural sources", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 40 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper \"Better Understanding Back-Translation for Neural Machine Translation\" explores the strengths and weaknesses of back-translation (BT) as a technique for improving the performance of neural machine translation (NMT) systems. The authors reimplement several strategies for using monolingual data in NMT and conduct experiments on two language pairs in a controlled setting. Their main results suggest that the quality of back-translated data is important for NMT performance, and that properties such as the length and regularity of back-translated sentences matter. The authors also find that back-translation does not act as a regularizer and that it can be efficiently simulated.", "evaluation": "f1"}
{"query": "what dataset is used?", "gt": "Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper \"Better Understanding the Strengths and Weaknesses of Back-Translation in Neural Machine Translation\" presents a study on the use of monolingual data in neural machine translation (NMT). The authors aim to answer several questions about the importance of the quality of back-translated data, the properties of back-translated sentences that matter for NMT, and the role of back-translation as a regularizer.\n\nTo answer these questions, the authors reimplement several strategies to use monolingual data in NMT and run experiments on two language pairs in a controlled setting. They use the Europarl domain for their experiments, focusing on the English INLINEFORM0 German and English INLINEFORM1 French language pairs.\n\nThe authors find that the quality of back-translated data is important for NMT performance, with better artificial parallel data yielding better translation systems. They also find that the properties of back-translated sentences that matter for NMT include the quality of the source language, the length of the sentences, and the monotonicity of the sentence pairs.\n\nThe authors also find that back-translation does not act as a regularizer, as previously thought. They observe that back-translated data improves quickly in the earliest updates and then stays horizontal, while natural data continues improving even after 400k updates.\n\nOverall, the paper provides valuable insights into the use of monolingual data in NMT and the importance of back-translation in improving translation performance.", "evaluation": "f1"}
{"query": "what language pairs are explored?", "gt": "English-German, English-French", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper \"Better Understanding Back-Translation for Neural Machine Translation\" explores the use of monolingual data in neural machine translation (NMT) systems. The authors focus on the Europarl domain, using English INLINEFORM0 German and English INLINEFORM1 French as in-domain training data. They compare the performance of several NMT systems, including those that use artificial parallel data generated through back-translation (BT) and forward translation (FT). The authors also analyze the quality of the back-translated data and the properties of the back-translated sentences that affect the performance of the NMT systems. They find that using artificial parallel data generated through back-translation can significantly improve the performance of NMT systems, and that the quality of the back-translated data and the properties of the back-translated sentences are important factors in determining the effectiveness of the NMT systems.", "evaluation": "f1"}
{"query": "what language is the data in?", "gt": "English , German, French", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 4 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper \"Better Understanding Back-Translation for Neural Machine Translation\" presents a study on the use of monolingual data in neural machine translation (NMT). The authors aim to answer several questions related to the use of back-translation (BT) in NMT, including the importance of the quality of BT data, the properties of back-translated sentences that matter for MT quality, and the role of BT as a regularizer. The authors reimplement several strategies to use monolingual data in NMT and run experiments on two language pairs in a controlled setting. Their main results suggest that the quality of BT data is important for MT performance, that certain properties of back-translated sentences matter for MT quality, and that BT does not act as a regularizer. The authors also find that using artificial parallel data in NMT can improve translation performance, and that the best results are obtained using systems trained with a combination of forward and backward translation.", "evaluation": "f1"}
{"query": "What metrics are used for evaluation?", "gt": "BLEU-1/4 and ROUGE-L, likelihood of generated recipes using identical input specifications but conditioned on ten different user profiles, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), neural scoring model from BIBREF33 to measure recipe-level coherence", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 35 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The main contributions of this work are as follows:\n\n1. The authors propose a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences.\n2. They release a new dataset of 180K+ recipes and 700K+ user reviews for this task.\n3. They introduce new evaluation strategies for generation quality in instructional texts, centering on quantitative measures of coherence.\n4. They show that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "What natural language(s) are the recipes written in?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "English", "evaluation": "f1"}
{"query": "What were their results on the new dataset?", "gt": "average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The authors presented a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences. They released a new dataset of 180K+ recipes and 700K+ user reviews for this task. The authors introduced new evaluation strategies for generation quality in instructional texts, centering on quantitative measures of coherence. They showed that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "What are the baseline models?", "gt": "name-based Nearest-Neighbor model (NN), Encoder-Decoder baseline with ingredient attention (Enc-Dec)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The baseline models are a Nearest-Neighbor model and an Encoder-Decoder model with ingredient attention.", "evaluation": "f1"}
{"query": "How did they obtain the interactions?", "gt": "from Food.com", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "They collected interactions.", "evaluation": "f1"}
{"query": "Where do they get the recipes from?", "gt": "from Food.com", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Food.com", "evaluation": "f1"}
{"query": "what are their results on the constructed dataset?", "gt": "AutoJudge consistently and significantly outperforms all the baselines, RC models achieve better performance than most text classification models (excluding GRU+Attention), Comparing with conventional RC models, AutoJudge achieves significant improvement", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 29 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The proposed Legal Reading Comprehension (LRC) framework and the AutoJudge model show significant improvements over previous methods in automatic judgment prediction in the civil law system of mainland China. The experiment results demonstrate the effectiveness of the LRC framework in modeling the complementary inputs of fact descriptions, pleas, and law articles.", "evaluation": "f1"}
{"query": "what evaluation metrics are reported?", "gt": "precision, recall, F1 and accuracy", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Evaluation metrics reported: accuracy, precision, recall, F1-score.", "evaluation": "f1"}
{"query": "what civil field is the dataset about?", "gt": "divorce", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Mainland China.", "evaluation": "f1"}
{"query": "what are the state-of-the-art models?", "gt": "SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "State-of-the-art models for automatic judgment prediction include text classification, entailment prediction, and reading comprehension.", "evaluation": "f1"}
{"query": "what is the size of the real-world civil case dataset?", "gt": "100 000 documents", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The size of the real-world civil case dataset is \"large-scale\".", "evaluation": "f1"}
{"query": "what datasets are used in the experiment?", "gt": "build a new one, collect INLINEFORM0 cases from China Judgments Online", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset used in the experiment is a large-scale real-world dataset of INLINEFORM0 case documents from mainland China.", "evaluation": "f1"}
{"query": "What domains are covered in the corpus?", "gt": "No specific domain is covered in the corpus.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "CoVoST is a multilingual speech-to-text corpus based on Common Voice. It covers 11 languages into English and is diversified with over 11,000 speakers and over 60 accents. The corpus includes a total 708 hours of speech and is released under CC0 license.", "evaluation": "f1"}
{"query": "What is the architecture of their model?", "gt": "follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper introduces CoVoST, a multilingual speech-to-text corpus based on Common Voice BIBREF10 for 11 languages into English. The corpus includes a total of 708 hours of speech and is diversified with multiple speakers per transcript/translation. The authors also provide baseline models, including the first end-to-end many-to-one multilingual ST models. CoVoST is released under CC0 license and free to use. The Tatoeba evaluation corpus is also available under friendly CC licenses.", "evaluation": "f1"}
{"query": "How was the dataset collected?", "gt": "Contributors record voice clips by reading from a bank of donated sentences.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset was collected from Common Voice and Tatoeba.", "evaluation": "f1"}
{"query": "Which languages are part of the corpus?", "gt": "French, German, Dutch, Russian, Spanish, Italian, Turkish, Persian, Swedish, Mongolian and Chinese", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The corpus, CoVoST, is a multilingual speech-to-text corpus based on Common Voice BIBREF10 for 11 languages into English. It includes a total of 708 hours of speech from French, German, Dutch, Russian, Spanish, Italian, Turkish, Persian, Swedish, Mongolian, and Chinese speakers. The corpus is diversified with multiple speakers per transcript/translation and includes an additional evaluation corpus from Tatoeba for French, German, Dutch, Russian, and Spanish.", "evaluation": "f1"}
{"query": "How is the quality of the data empirically evaluated? ", "gt": "Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test sets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The quality of the data in CoVoST and Tatoeba was evaluated using various methods, including sentence-level BLEU scores, perplexity, and overlap checks.", "evaluation": "f1"}
{"query": "Is the data in CoVoST annotated for dialect?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "Is Arabic one of the 11 languages in CoVost?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "What kind of model do they use?", "gt": "visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 39 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The proposed model for document quality assessment combines visual and textual features. The visual features are learned through Inception V3, while the textual features are learned through a bi-directional LSTM. The two models are combined into a joint model that integrates the visual and textual embeddings.", "evaluation": "f1"}
{"query": "What kind of model do they use?", "gt": "Inception V3, biLSTM", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Visual and Textual Embeddings.", "evaluation": "f1"}
{"query": "Did they release their data set of academic papers?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "Do the methods that work best on academic papers also work best on Wikipedia?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "What is their system's absolute accuracy?", "gt": "59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 26 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a joint model that combines visual and textual features to improve the accuracy of document quality assessment. The visual model is based on fine-tuning an Inception V3 model over visual renderings of documents, while the textual model is based on a hierarchical biLSTM. The joint model achieves state-of-the-art results over 3/4 of their datasets.", "evaluation": "f1"}
{"query": "Which is more useful, visual or textual features?", "gt": "It depends on the dataset. Experimental results over two datasets reveal that textual and visual features are complementary. ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a joint model that combines visual and textual features for document quality assessment. The visual model is based on fine-tuning an Inception V3 model over visual renderings of documents, while the textual model is based on a hierarchical biLSTM. The joint model achieves state-of-the-art results over 3/4 of the datasets.", "evaluation": "f1"}
{"query": "Which languages do they use?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a joint model for document quality assessment that combines textual and visual features. The textual features are learned using a hierarchical biLSTM, while the visual features are learned using a pre-trained Inception V3 model on visual renderings of documents. The joint model achieves state-of-the-art results on two datasets: a Wikipedia dataset and an arXiv dataset. The paper also discusses related work in document quality assessment across different domains.", "evaluation": "f1"}
{"query": "How large is their data set?", "gt": "a sample of  29,794 wikipedia articles and 2,794 arXiv papers ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The Wikipedia dataset consists of 29,794 articles and the arXiv dataset has 3 subsets with 1,000 papers each.", "evaluation": "f1"}
{"query": "Where do they get their ground truth quality judgments?", "gt": "quality class labels assigned by the Wikipedia community, a paper is considered to have been accepted (i.e. is positively labeled) if it matches a paper in the DBLP database or is otherwise accepted by any of the following conferences: ACL, EMNLP, NAACL, EACL, TACL, NIPS, ICML, ICLR, or AAAI", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 49 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The task of document quality assessment is to automatically assess a document according to some predefined inventory of quality labels. This can take many forms, including essay scoring, job application filtering, or answer selection in community question answering. The proposed model combines visual and textual features to achieve better accuracy on document quality assessment. The visual model is based on fine-tuning an Inception V3 model over visual renderings of documents, while the textual model is based on a hierarchical biLSTM. The two models are combined into a joint model. The ground truth quality judgments for the Wikipedia dataset are based on the quality assessment process that the Wikipedia community carries out manually, while for the arXiv dataset, the acceptance or rejection of a paper is the ground truth.", "evaluation": "f1"}
{"query": "What is the seed lexicon?", "gt": "a vocabulary of positive and negative predicates that helps determine the polarity score of an event", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 16 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The seed lexicon is a set of positive and negative words used in the proposed method to learn affective events.", "evaluation": "f1"}
{"query": "What is the seed lexicon?", "gt": "seed lexicon consists of positive and negative predicates", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The seed lexicon is a small set of positive and negative words used to train the model.", "evaluation": "f1"}
{"query": "What are the results?", "gt": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 94 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The paper proposes a method for learning affective events, which are events that typically affect people in positive or negative ways. The method uses discourse relations to efficiently propagate polarity from seed predicates that directly report one's emotions. The authors trained the models using a Japanese web corpus and found that the models performed well, even with a very small seed lexicon and a large raw corpus. The combination of annotated and unannotated data yielded a gain over a purely supervised baseline when labeled data were small. The method is more interested in recognizing the sentiment polarity of an event that pertains to commonsense knowledge, such as getting money and catching cold, rather than compositionality.", "evaluation": "f1"}
{"query": "How are relations used to propagate polarity?", "gt": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Discourse relations are used to propagate polarity by exploiting the tendency of events to have the same or opposite polarity.", "evaluation": "f1"}
{"query": "How big is the Japanese data?", "gt": "The ACP corpus has around 700k events split into positive and negative polarity ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The Japanese data used in the study is about 100 million sentences.", "evaluation": "f1"}
{"query": "What are labels available in dataset for supervision?", "gt": "negative, positive", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Labels available in dataset for supervision: ACP.", "evaluation": "f1"}
{"query": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "gt": "3%", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Improvements.", "evaluation": "f1"}
{"query": "How does their model learn using mostly raw data?", "gt": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The model learns by propagating polarity from seed predicates using discourse relations.", "evaluation": "f1"}
{"query": "How big is seed lexicon used for training?", "gt": "30 words", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Small.", "evaluation": "f1"}
{"query": "How large is raw corpus used for training?", "gt": "100 million sentences", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Raw corpus used for training is large.", "evaluation": "f1"}
{"query": "What data is the language model pretrained on?", "gt": "Chinese general corpus", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical Text Structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The goal of CTS is to obtain specific information such as whether a patient has a specific disease, tumor size, or laboratory test result. CTS is important for clinical research because it allows researchers to extract large-scale structured data from EHRs. However, end-to-end CTS is a challenging task because different CTS tasks have non-uniform output formats. Researchers have to construct different models for each task, which is costly and requires a lot of labeled data. To handle this, researchers often turn to rule-based or pipeline methods. Rule-based methods suffer from costly human-designed extraction rules, while pipeline methods break down the entire process into several pieces, which improves performance but can lead to error propagation. To reduce the pipeline depth and break the barrier of non-uniform output formats, a question answering based clinical text structuring (QA-CTS) task is proposed. The QA-CTS task aims to discover the most related text from the original paragraph text. The proposed model integrates clinical named entity information into a pre-trained language model to improve the performance of the QA-CTS task. The model achieves significantly better performance than strong baseline methods and shows that two-stage training mechanism has a great improvement on the QA-CTS task.", "evaluation": "f1"}
{"query": "What baselines is the proposed model compared against?", "gt": "BERT-Base, QANet", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical Text Structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The task involves identifying specific patient medical data such as symptoms, diseases, tumor size, and laboratory test results. CTS is important for clinical research as it provides large-scale extracted structured data for downstream research. However, end-to-end CTS is a challenging task due to non-uniform output formats, such as specific-class classifications, strings in the original text, and inferred values from part of the original text. Researchers have turned to rule-based and pipeline methods to address this challenge, but these methods have limitations. In this paper, the authors present a question answering-based clinical text structuring (QA-CTS) task that unifies different specific tasks and makes the training data shareable. The QA-CTS task aims to discover the most related text from the original paragraph text. The authors also propose an effective model to integrate clinical named entity information into a pre-trained language model. The proposed model achieves significantly better performance than strong baseline methods and shows that two-stage training can improve the QA-CTS task.", "evaluation": "f1"}
{"query": "How is the clinical text structuring task defined?", "gt": "Clinical text structuring (CTS) is a critical task for fetching medical research data from electronic health records (EHRs), where structural patient medical data, such as whether the patient has specific symptoms, diseases, or what the tumor size is, how far from the tumor is cut at during the surgery, or what the specific laboratory test result is, are obtained., Unlike the traditional CTS task, our QA-CTS task aims to discover the most related text from original paragraph text. ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 78 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical text structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The goal of CTS is to obtain specific information such as whether a patient has a specific disease, tumor size, or laboratory test result. CTS is challenging due to the non-uniform output formats of different CTS tasks, which require different models and labeled data. To address this, researchers have developed various methods such as rule-based, task-specific end-to-end, and pipeline methods. However, these methods have limitations such as high labor cost, non-uniform output formats, and difficulty in handling complex queries. In this paper, the authors present a question answering based clinical text structuring (QA-CTS) task, which unifies different specific tasks and makes the training data shareable. The proposed QA-CTS task aims to discover the most related text from the original paragraph text, and the authors propose an effective model to integrate clinical named entity information into pre-trained language models. The experimental results show that the proposed QA-CTS task leads to significant improvement due to shared dataset, and the proposed model achieves significantly better performance than the strong baseline methods.", "evaluation": "f1"}
{"query": "How is the clinical text structuring task defined?", "gt": "CTS is extracting structural data from medical research data (unstructured). Authors define QA-CTS task that aims to discover most related text from original text.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical text structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The task involves identifying specific patient medical data such as symptoms, diseases, tumor size, and laboratory test results. CTS is important for clinical research as it provides large-scale extracted structured data for downstream research. However, end-to-end CTS is a challenging task due to non-uniform output formats, such as specific-class classifications, strings in the original text, and inferred values from part of the original text. Researchers have turned to rule-based and pipeline methods to address this challenge. In this paper, the authors present a question answering based clinical text structuring (QA-CTS) task that unifies different specific tasks and makes the training data shareable. The QA-CTS task aims to discover the most related text from the original paragraph text. The authors also propose an effective model to integrate clinical named entity information into pre-trained language models. The proposed model achieves significantly better performance than strong baseline methods and shows that two-stage training mechanism has a great improvement on QA-CTS task.", "evaluation": "f1"}
{"query": "What are the specific tasks being unified?", "gt": " three types of questions, namely tumor size, proximal resection margin and distal resection margin", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical text structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The task involves identifying specific information such as symptoms, diseases, tumor size, and laboratory test results from unstructured clinical text. CTS is important for clinical research and decision-making. However, end-to-end CTS is a challenging task due to non-uniform output formats and the need for labeled data. Researchers have developed various methods for CTS, including rule-based, task-specific end-to-end, and pipeline methods. These methods have different strengths and weaknesses, and the choice of method depends on the specific task and available resources.", "evaluation": "f1"}
{"query": "Is all text in this dataset a question, or are there unrelated sentences in between questions?", "gt": "the dataset consists of pathology reports including sentences and questions and answers about tumor size and resection margins so it does include additional sentences ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical text structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The goal of CTS is to obtain specific information such as whether a patient has a specific disease, tumor size, or laboratory test result. CTS is important for clinical research because it allows researchers to extract large-scale structured data from EHRs. However, end-to-end CTS is a challenging task because different CTS tasks have non-uniform output formats. Researchers have to construct different models for each task, which is costly and requires a lot of labeled data. To handle this, researchers often use rule-based or pipeline methods. Rule-based methods suffer from costly human-designed extraction rules, while pipeline methods break down the entire process into several pieces, which improves performance but can lead to error propagation. To reduce the pipeline depth and break the barrier of non-uniform output formats, a question answering based clinical text structuring (QA-CTS) task is proposed. The QA-CTS task aims to discover the most related text from the original paragraph text. The proposed model integrates clinical named entity information into a pre-trained language model to improve the performance of the QA-CTS task. The model achieves significantly better performance than the strong baseline methods and shows that two-stage training mechanism has a great improvement on the QA-CTS task.", "evaluation": "f1"}
{"query": "How many questions are in the dataset?", "gt": "2,714 ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical text structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The goal of CTS is to obtain specific information such as whether a patient has a specific disease, tumor size, or laboratory test result. CTS is important for clinical research because it allows researchers to extract large-scale structured data from EHRs. However, end-to-end CTS is a challenging task because different CTS tasks have non-uniform output formats. Researchers have to construct different models for each task, which is costly and requires a lot of labeled data. To handle this, researchers often use rule-based or pipeline methods. Rule-based methods suffer from costly human-designed extraction rules, while pipeline methods break down the entire process into several pieces, which improves performance but can lead to error propagation.\n\nTo address these challenges, a question answering based clinical text structuring (QA-CTS) task is proposed. The goal of QA-CTS is to discover the most related text from the original paragraph text. QA-CTS unifies the output format of the traditional CTS task and makes the training data shareable, thus enriching the training data. The proposed model integrates clinical named entity information into a pre-trained language model to improve the performance of the QA-CTS task. The model first passes the paragraph text and query text through a clinical named entity recognition (CNER) model to obtain one-hot CNER output tagging sequences. The CNER model is trained on a corpus of clinical text and recognizes named entities such as diseases, symptoms, treatments, exams, and body parts. The paragraph text and query text are then passed through a contextualized representation model, which is a pre-trained language model such as BERT. The contextualized representation model generates a hidden vector that contains both query and text information. The hidden vector and named entity information are then integrated together and fed into a feed-forward network to calculate the start and end index of the answer-related text. The proposed model achieves significantly better performance than the strong baseline methods and shows that two-stage training mechanism has a great improvement on QA-CTS task.", "evaluation": "f1"}
{"query": "How they introduce domain-specific features into pre-trained language model?", "gt": "integrate clinical named entity information into pre-trained language model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 9 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical Text Structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The QA-CTS task is a new approach to CTS that aims to discover the most related text from original paragraph text. The proposed model for QA-CTS task integrates clinical named entity information into pre-trained language model BERT. The model first passes the paragraph text and query text through BERT to obtain contextualized representation vectors. Then, the named entity information vectors are integrated with the contextualized representation vectors to calculate the start and end index of answer-related text. The proposed model achieves significantly better performance than the strong baseline methods and two-stage training mechanism has a great improvement on QA-CTS task.", "evaluation": "f1"}
{"query": "How big is QA-CTS task dataset?", "gt": "17,833 sentences, 826,987 characters and 2,714 question-answer pairs", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Clinical text structuring (CTS) is a critical task for extracting structured data from electronic health records (EHRs). The task involves identifying specific patient medical data such as symptoms, diseases, tumor size, and laboratory test results. CTS is important for clinical research as it provides large-scale extracted structured data for downstream research. However, end-to-end CTS is a challenging task due to non-uniform output formats, such as specific-class classifications, strings in the original text, and inferred values from part of the original text. Researchers have turned to rule-based and pipeline methods to address this challenge. In this paper, the authors present a question answering based clinical text structuring (QA-CTS) task that unifies different specific tasks and makes the training data shareable. The QA-CTS task aims to discover the most related text from the original paragraph text. The authors propose an effective model to integrate clinical named entity information into a pre-trained language model. The model achieves significantly better performance than strong baseline methods and shows that two-stage training mechanism has a great improvement on the QA-CTS task.", "evaluation": "f1"}
{"query": "What are strong baseline models in specific tasks?", "gt": "state-of-the-art question answering models (i.e. QANet BIBREF39) and BERT-Base BIBREF26", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The proposed question answering based clinical text structuring (QA-CTS) task aims to discover the most related text from original paragraph text. The task unifies different specific tasks and makes dataset shareable. The main contributions of this work include a question answering based clinical text structuring task, an effective model to integrate clinical named entity information into pre-trained language model, and experimental results showing the effectiveness of the proposed method. The QA-CTS task leads to significant improvement due to shared dataset, and the proposed model achieves significantly better performance than the strong baseline methods. The two-stage training mechanism also has a great improvement on QA-CTS task.", "evaluation": "f1"}
{"query": "What is the previous work's model?", "gt": "Ternary Trans-CNN", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Transfer Learning", "evaluation": "f1"}
{"query": "What dataset is used?", "gt": "HEOT , A labelled dataset for a corresponding english tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset used for the task is HEOT obtained from one of the past studies done by Mathur et al.", "evaluation": "f1"}
{"query": "How big is the dataset?", "gt": "3189 rows of text messages", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset is very small.", "evaluation": "f1"}
{"query": "How big is the dataset?", "gt": "Resulting dataset was 7934 messages for train and 700 messages for test.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset used in the study is HEOT, which contains cleaned tweets obtained from Twitter for conversations happening in the Indian subcontinent.", "evaluation": "f1"}
{"query": "How is the dataset collected?", "gt": "A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al, HEOT obtained from one of the past studies done by Mathur et al", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 32 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The document discusses the use of Hinglish, a blend of Hindi and English, and its usage in social media platforms such as Twitter. The authors aim to classify tweets that contain hate speech or offensive content. They face challenges such as geographical variation, language and phonetics variation, and lack of grammar rules. The authors use data augmentation techniques to address the small size of the labeled dataset. They experiment with various model architectures, including fully connected dense networks, convolution-based architectures, and sequence models. The best performance is achieved with a bidirectional LSTM model with 32 units.", "evaluation": "f1"}
{"query": "Was each text augmentation technique experimented individually?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "What models do previous work use?", "gt": "Ternary Trans-CNN , Hybrid multi-channel CNN and LSTM", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Hinglish is a blend of Hindi and English spoken in India.", "evaluation": "f1"}
{"query": "Does the dataset contain content from various social media platforms?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "What additional techniques are incorporated?", "gt": "incorporating coding syntax tree model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Statistical Machine Translation, Vocabulary Generation, Neural Model Training, Attention Mechanism, Sigmoidal Optimization.", "evaluation": "f1"}
{"query": "What dataset do they use?", "gt": "A parallel corpus where the source is an English expression of code and the target is Python code.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "They use a text-code parallel corpus with 18805 aligned data in English and Python programming language for training their neural machine translation model.", "evaluation": "f1"}
{"query": "Do they compare to other models?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "What is the architecture of the system?", "gt": "seq2seq translation", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Neural Architecture.", "evaluation": "f1"}
{"query": "What additional techniques could be incorporated to further improve accuracy?", "gt": "phrase-based word embedding, Abstract Syntax Tree(AST)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Incorporating more data and using abstract syntax trees could improve accuracy.", "evaluation": "f1"}
{"query": "What programming language is target language?", "gt": "Python", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Python", "evaluation": "f1"}
{"query": "What dataset is used to measure accuracy?", "gt": "validation data", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Validation data", "evaluation": "f1"}
{"query": "What corpus was the source of the OpenIE extractions?", "gt": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The source of the OpenIE extractions was the text corpora (S) from BIBREF6.", "evaluation": "f1"}
{"query": "What is the accuracy of the proposed technique?", "gt": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 32 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The proposed technique, TupleInf, achieved an accuracy of 71.2% on a broad set of over 1,300 science questions, outperforming the related work by 11.8%.", "evaluation": "f1"}
{"query": "Is an entity linking process used?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "Are the OpenIE extractions all triples?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "No.", "evaluation": "f1"}
{"query": "What method was used to generate the OpenIE extractions?", "gt": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 56 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The document describes a method for developing a question answering (QA) system that can perform reasoning with Open IE (Information Extraction) tuples for complex multiple-choice questions. The system, called TupleInf, uses an ILP-based model of inference with tuples, implemented in a reasoner. The system is designed to handle noisy tuples and to generalize well to higher grade levels. The method used to generate the Open IE extractions is not specified in the document.", "evaluation": "f1"}
{"query": "Can the method answer multi-hop questions?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "What was the textual source to which OpenIE was applied?", "gt": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The textual source to which OpenIE was applied is not specified in the given document.", "evaluation": "f1"}
{"query": "What OpenIE method was used to generate the extractions?", "gt": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 56 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The document describes a new ILP-based model of inference with tuples called TupleInf, which is implemented in a reasoner called TupleInf. The model is used to answer complex multiple-choice questions in resource-poor domains where curated knowledge is unavailable. The system uses Open IE based QA and is able to perform reasoning with Open IE tuples for complex multiple-choice questions that require tuples from multiple sentences. The system outperforms a related work, TableILP, by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels.", "evaluation": "f1"}
{"query": "Is their method capable of multi-hop reasoning?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Yes.", "evaluation": "f1"}
{"query": "What models do they propose?", "gt": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The authors propose a novel task of hate speech detection in multimodal publications, collect and annotate a large-scale dataset, evaluate state-of-the-art multimodal models, and study the challenges of the proposed task. They also compare the performance of multimodal models with unimodal textual models.", "evaluation": "f1"}
{"query": "Are all tweets in English?", "gt": "Unanswerable", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The document discusses the task of hate speech detection in multimodal publications, which include both text and images. The authors propose a novel task and collect, annotate, and publish a large-scale dataset for this task. They evaluate state-of-the-art multimodal models on this specific task and compare their performance with unimodal textual detection. The authors also study the challenges of the proposed task and open the field for future research.\n\nThe document discusses the related work on detecting hate speech on online textual publications and visual and textual data fusion. The authors summarize existing hate speech datasets and mention some contributions that exploit visual information. They also take inspiration from the visual question answering literature for the tested models.\n\nThe document describes the methodology used in the proposed task, including the unimodal treatment of images and tweet text. The authors use a CNN as the image features extractor and train a single layer LSTM with a 150-dimensional hidden state for hate/not hate classification. They also mention the pre-processing steps used for the tweet text before generating the word embeddings.", "evaluation": "f1"}
{"query": "How large is the dataset?", "gt": " $150,000$ tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The dataset is large.", "evaluation": "f1"}
{"query": "What is the results of multimodal compared to unimodal models?", "gt": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The proposed work focuses on hate speech detection in multimodal publications, which include images and text. The authors collect and annotate a large-scale dataset of such publications, and evaluate the performance of state-of-the-art multimodal models on this specific task. They also study the challenges of the proposed task and open the field for future research. The results show that while images are useful for hate speech detection, the proposed multimodal models do not outperform unimodal textual models.", "evaluation": "f1"}
{"query": "What is author's opinion on why current multimodal models cannot outperform models analyzing only text?", "gt": "Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The proposed task is hate speech detection in multimodal publications, which includes both text and images. The contributions of this work include a novel task, a large-scale dataset, and the evaluation of state-of-the-art multimodal models on this specific task. The authors also study the challenges of the proposed task and open the field for future research. The proposed multimodal models do not outperform unimodal textual models, suggesting that the presence of images does not necessarily improve hate speech detection.", "evaluation": "f1"}
{"query": "What metrics are used to benchmark the results?", "gt": "F-score, Area Under the ROC Curve (AUC), mean accuracy (ACC), Precision vs Recall plot, ROC curve (which plots the True Positive Rate vs the False Positive Rate)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 27 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The contributions of this work are as follows:\n\n* Propose the novel task of hate speech detection in multimodal publications\n* Collect, annotate and publish a large scale dataset\n* Evaluate state of the art multimodal models on this specific task and compare their performance with unimodal detection\n* Study the challenges of the proposed task and open the field for future research.", "evaluation": "f1"}
{"query": "How is data collected, manual collection or Twitter api?", "gt": "Twitter API", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Twitter API.", "evaluation": "f1"}
{"query": "How many tweats does MMHS150k contains, 150000?", "gt": "$150,000$ tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The document discusses the task of hate speech detection in multimodal publications, which include both text and images. The authors propose a novel task of hate speech detection in multimodal publications and collect, annotate, and publish a large-scale dataset for this task. They evaluate state-of-the-art multimodal models on this specific task and compare their performance with unimodal textual detection. The authors also study the challenges of the proposed task and open the field for future research. The document includes related work on detecting hate speech on online textual publications and visual and textual data fusion. The authors also provide a summary of existing hate speech datasets.", "evaluation": "f1"}
{"query": "What unimodal detection models were used?", "gt": " single layer LSTM with a 150-dimensional hidden state for hate / not hate classification", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The proposed task is hate speech detection in multimodal publications, which includes both text and images. The contributions of this work include a novel task, a large-scale dataset, and the evaluation of state-of-the-art multimodal models on this specific task. The dataset, MMHS150K, was created by gathering real-time tweets from September 2018 until February 2019, selecting the ones containing any of the 51 Hatebase terms that are more common in hate speech tweets, and filtering out retweets, tweets containing less than three words, and tweets containing porn related terms. The dataset was annotated by three workers, and the tweets were labeled as hate or not hate. The unimodal detection models used in this work include a CNN as the image features extractor and a single layer LSTM with a 150-dimensional hidden state for hate/not hate classification.", "evaluation": "f1"}
{"query": "What different models for multimodal detection were proposed?", "gt": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "Multimodal hate speech detection models have been proposed to combine text and image information for better performance.", "evaluation": "f1"}
{"query": "What annotations are available in the dataset - tweat used hate speach or not?", "gt": "No attacks to any community,  racist, sexist, homophobic, religion based attacks, attacks to other communities", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 15 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-4k_pred": "The document discusses the task of hate speech detection in multimodal publications, which include both text and images. The authors propose a novel task of hate speech detection in multimodal publications and collect, annotate, and publish a large-scale dataset for this task. They evaluate state-of-the-art multimodal models on this specific task and compare their performance with unimodal textual detection. The authors also study the challenges of the proposed task and open the field for future research. The related work section discusses existing datasets and models for hate speech detection, as well as visual and textual data fusion. The authors also describe the creation of the MMHS150K dataset, which is a manually annotated multimodal hate speech dataset formed by 150,000 tweets, each containing text and an image.", "evaluation": "f1"}
