{"query": "How did they obtain the dataset?", "gt": "public resources where suspicious Twitter accounts were annotated, list with another 32 Twitter accounts from BIBREF19 that are considered trustworthy", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 20 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They obtained the dataset by using two lists of annotated Twitter accounts.", "evaluation": "f1"}
{"query": "What activation function do they use in their model?", "gt": "relu, selu, tanh", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They use ReLU activation function.", "evaluation": "f1"}
{"query": "What baselines do they compare to?", "gt": "Top-$k$ replies, likes, or re-tweets, FacTweet (tweet-level), LR + All Features (chunk-level), LR + All Features (tweet-level), Tweet2vec, LR + Bag-of-words", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 21 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They compare their approach to several baselines, including LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), and Top-$k$ replies, likes, or re-tweets.", "evaluation": "f1"}
{"query": "How are chunks defined?", "gt": "Chunks is group of tweets from single account that  is consecutive in time - idea is that this group can show secret intention of malicious accounts.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 26 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Chunks are defined as a sorted sequence of tweets labeled by the corresponding account, with each tweet represented by a vector of features.", "evaluation": "f1"}
{"query": "What features are extracted?", "gt": "Sentiment, Morality, Style, Words embeddings", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Features extracted: sentiment, morality, style, words embeddings.", "evaluation": "f1"}
{"query": "What features are extracted?", "gt": "15 emotion types, sentiment classes, positive and negative, care, harm, fairness, cheating, loyalty, betrayal, authority, subversion, sanctity, and degradation, count of question marks, exclamation marks, consecutive characters and letters, links, hashtags, users' mentions, uppercase ratio, tweet length, words embeddings", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 39 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The features extracted in this work include emotion, sentiment, morality, style, words embeddings, and hashtags. These features are used to detect non-factual Twitter accounts by treating post streams as a sequence of tweet chunks.", "evaluation": "f1"}
{"query": "Was the approach used in this work to detect fake news fully supervised?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "Based on this paper, what is the more predictive set of features to detect fake news?", "gt": "words embeddings, style, and morality features", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Words embeddings, style, and morality features.", "evaluation": "f1"}
{"query": "How big is the dataset used in this work?", "gt": "Total dataset size: 171 account (522967 tweets)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 7 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset used in this work is large.", "evaluation": "f1"}
{"query": "How is a \"chunk of posts\" defined in this work?", "gt": "chunk consists of a sorted sequence of tweets labeled by the label of its corresponding account", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 16 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "A \"chunk of posts\" in this work is a sorted sequence of tweets labeled by the corresponding account.", "evaluation": "f1"}
{"query": "What baselines were used in this work?", "gt": "LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), Top-$k$ replies, likes, or re-tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 21 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The baselines used in this work include LR + Bag-of-words, Tweet2vec, LR + All Features (tweet-level), LR + All Features (chunk-level), FacTweet (tweet-level), and Top-$k$ replies, likes, or re-tweets.", "evaluation": "f1"}
{"query": "What models are used in the experiment?", "gt": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Three-level annotation model, SVM, BiLSTM, CNN.", "evaluation": "f1"}
{"query": "What are the differences between this dataset and pre-existing ones?", "gt": "no prior work has explored the target of the offensive language", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "This dataset includes a hierarchical annotation model for offensive language detection, categorization, and target identification.", "evaluation": "f1"}
{"query": "In what language are the tweets?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "English", "evaluation": "f1"}
{"query": "What is the size of the new dataset?", "gt": "14,100 tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Large publicly available dataset.", "evaluation": "f1"}
{"query": "What is the size of the new dataset?", "gt": "Dataset contains total of 14100 annotations.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "New dataset has 14,100 tweets.", "evaluation": "f1"}
{"query": "What kinds of offensive content are explored?", "gt": "non-targeted profanity and swearing, targeted insults such as cyberbullying, offensive content related to ethnicity, gender or sexual orientation, political affiliation, religious belief, and anything belonging to hate speech", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 28 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The paper explores offensive content in social media, specifically focusing on abusive language, hate speech, toxic comments, and offensive language.", "evaluation": "f1"}
{"query": "What is the best performing model?", "gt": "CNN ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "CNN", "evaluation": "f1"}
{"query": "How many annotators participated?", "gt": "five annotators", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "200", "evaluation": "f1"}
{"query": "What is the definition of offensive language?", "gt": " Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 77 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Offensive language refers to any form of language that is considered inappropriate, derogatory, or harmful to a particular individual or group. This can include insults, threats, profanity, and other forms of language that are intended to offend or harm. Offensive language can be directed towards a specific individual or group, or it can be generalized and directed towards a broader group or category. The definition of offensive language can vary depending on the context and the individuals or groups involved.", "evaluation": "f1"}
{"query": "What are the three layers of the annotation scheme?", "gt": "Level A: Offensive language Detection\n, Level B: Categorization of Offensive Language\n, Level C: Offensive Language Target Identification\n", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The three layers of the annotation scheme are: Level A: Offensive language detection, Level B: Categorization of offensive language, and Level C: Offensive language target identification.", "evaluation": "f1"}
{"query": "How long is the dataset for each step of hierarchy?", "gt": "Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Dataset for each step of hierarchy: 14,100 tweets.", "evaluation": "f1"}
{"query": "What is the approach of previous work?", "gt": "'shallow' naive Bayes, SVM, hierarchical stacked classifiers, bidirectional recurrent neural networks", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Previous work used shallow methods like Naive Bayes and SVMs for LID.", "evaluation": "f1"}
{"query": "Is the lexicon the same for all languages?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "How do they obtain the lexicon?", "gt": "built over all the data and therefore includes the vocabulary from both the training and testing sets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The lexicon is built over all the data and therefore includes the vocabulary from both the training and testing sets.", "evaluation": "f1"}
{"query": "What evaluation metric is used?", "gt": "average classification accuracy, execution performance", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Accuracy is used as evaluation metric.", "evaluation": "f1"}
{"query": "Which languages are similar to each other?", "gt": "Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The 11 official languages of South Africa are similar to each other.", "evaluation": "f1"}
{"query": "Which datasets are employed for South African languages LID?", "gt": "DSL 2015, DSL 2017, JW300 parallel corpus , NCHLT text corpora", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "NCHLT text corpora, DSL 2015 & 2017, JW300, WiLI-2018, NCHLT, NCHLT text corpora, NCHLT, NCHLT, NCHLT, NCHLT, NCHLT.", "evaluation": "f1"}
{"query": "Does the paper report the performance of a baseline model on South African languages LID?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Yes.", "evaluation": "f1"}
{"query": "Does the algorithm improve on the state-of-the-art methods?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Yes.", "evaluation": "f1"}
{"query": "Do they report results only on English data?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "Do they report results only on English data?", "gt": "The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No, the results are reported on both English and non-English data.", "evaluation": "f1"}
{"query": "What evidence do the authors present that the model can capture some biases in data annotation and collection?", "gt": "Waseem-dataset, Davidson-dataset,", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Evidence: Misclassifications", "evaluation": "f1"}
{"query": "Which publicly available datasets are used?", "gt": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Waseem and Hovey, Davidson.", "evaluation": "f1"}
{"query": "What baseline is used?", "gt": "BERT based fine-tuning, Insert nonlinear layers, Insert Bi-LSTM layer, Insert CNN layer", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The baselines used are Waseem and Hovey (2015), Davidson et al. (2019), and Waseem et al. (2018).", "evaluation": "f1"}
{"query": "What new fine-tuning methods are presented?", "gt": "sampling tweets from specific keywords create systematic and substancial racial biases in datasets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "New fine-tuning methods for hate speech detection using BERT are presented.", "evaluation": "f1"}
{"query": "What are the existing biases?", "gt": "Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The existing biases in hate speech detection include biases in data collection, annotation, and language models.", "evaluation": "f1"}
{"query": "What biases does their model capture?", "gt": "Waseem and Hovy BIBREF5, Davidson et al. BIBREF9, and Waseem et al. BIBREF10", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The model captures biases in data collection and annotation.", "evaluation": "f1"}
{"query": "What does the \"sensitivity\" quantity denote?", "gt": "the number of distinct word recognition outputs that an attacker can induce", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The \"sensitivity\" quantity denotes the number of unique outputs predicted by a word recognition model for a set of adversarial perturbations.", "evaluation": "f1"}
{"query": "What end tasks do they evaluate on?", "gt": "Sentiment analysis and paraphrase detection under adversarial attacks", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Sentiment analysis, paraphrase detection.", "evaluation": "f1"}
{"query": "What is a semicharacter architecture?", "gt": "A semi-character based RNN (ScRNN) treats the first and last characters individually, and is agnostic to the ordering of the internal characters", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "A semicharacter architecture is a type of natural language processing (NLP) model that uses a combination of character-level and word-level features to process text.", "evaluation": "f1"}
{"query": "Do they experiment with offering multiple candidate corrections and voting on the model output, since this seems highly likely to outperform a one-best correction?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "Why is the adversarial setting appropriate for misspelling recognition?", "gt": "Adversarial misspellings are a real-world problem", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Adversarial setting appropriate for misspelling recognition.", "evaluation": "f1"}
{"query": "How do the backoff strategies work?", "gt": "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 43 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The backoff strategies work by providing a fallback mechanism when the word recognition model predicts an unknown word (UNK). The backoff strategies include pass-through, neutral, and background backoff. Pass-through backoff simply passes the UNK word through to the downstream classifier. Neutral backoff replaces the UNK word with a fixed neutral word. Background backoff replaces the UNK word with a word from a larger corpus.", "evaluation": "f1"}
{"query": "What baseline model is used?", "gt": "same baseline as used by lang2011unsupervised", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The baseline model used is a dependency-based model.", "evaluation": "f1"}
{"query": "Which additional latent variables are used in the model?", "gt": "CLV as a parent of the two corresponding role variables", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Crosslingual latent variables are used in the model.", "evaluation": "f1"}
{"query": "Which additional latent variables are used in the model?", "gt": "crosslingual latent variables", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Crosslingual Latent Variables", "evaluation": "f1"}
{"query": "Which parallel corpora are used?", "gt": "English (EN) and German (DE) sections of the CoNLL 2009 corpus BIBREF13, EN-DE section of the Europarl corpus BIBREF14", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The paper proposes a joint Bayesian model for unsupervised semantic role induction in multiple languages using word alignments to capture crosslingual semantic role patterns.", "evaluation": "f1"}
{"query": "Overall, does having parallel data improve semantic role induction across multiple languages?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Yes.", "evaluation": "f1"}
{"query": "Do they add one latent variable for each language pair in their Bayesian model?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Yes.", "evaluation": "f1"}
{"query": "What does an individual model consist of?", "gt": "Bayesian model of garg2012unsupervised as our base monolingual model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 9 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "An individual model consists of a set of parameters and a generative process.", "evaluation": "f1"}
{"query": "Do they improve on state-of-the-art semantic role induction?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "how many tags do they look at?", "gt": "48,705", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They look at 19.", "evaluation": "f1"}
{"query": "which algorithm was the highest performer?", "gt": "A hybrid model consisting of best performing popularity-based approach with the best similarity-based approach", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The highest performer was the hybrid approach that combined popularity-based and similarity-based algorithms.", "evaluation": "f1"}
{"query": "how is diversity measured?", "gt": " the average dissimilarity of all pairs of tags in the list of recommended tags", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Diversity is measured as the average dissimilarity of all pairs of tags in the list of recommended tags.", "evaluation": "f1"}
{"query": "how large is the vocabulary?", "gt": "33,663", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Vocabulary", "evaluation": "f1"}
{"query": "what dataset was used?", "gt": " E-book annotation data: editor tags, Amazon search terms, and  Amazon review keywords.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset used for the present study is a collection of e-book metadata and Amazon search query logs.", "evaluation": "f1"}
{"query": "what algorithms did they use?", "gt": "popularity-based, similarity-based, hybrid", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They used 19 different algorithms.", "evaluation": "f1"}
{"query": "What baseline method is used?", "gt": "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The baseline method used in the study is the word2vec algorithm.", "evaluation": "f1"}
{"query": "What details are given about the Twitter dataset?", "gt": "one of the Twitter datasets is about Turkish mobile network operators, there are positive, neutral and negative labels and provide the total amount plus the distribution of labels", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 28 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The Twitter dataset is a collection of tweets annotated through a distant supervised method with positive, neutral, and negative labels. It has nearly 1.6 million tweets.", "evaluation": "f1"}
{"query": "What details are given about the movie domain dataset?", "gt": "there are 20,244 reviews divided into positive and negative with an average 39 words per review, each one having a star-rating score", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The movie domain dataset is a collection of movie reviews in Turkish, with positive and negative labels. The dataset contains 20,244 reviews, with an average of 39 words per review. The dataset is split into 7,020 positive and 7,020 negative reviews.", "evaluation": "f1"}
{"query": "Which hand-crafted features are combined with word2vec?", "gt": "polarity scores, which are minimum, mean, and maximum polarity scores, from each review", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The hand-crafted features that are combined with word2vec are:\n\n1. Minimum\n2. Mean\n3. Maximum\n4. Sentiment lexicon\n5. Domain-specific co-occurrence statistics\n6. Word embeddings\n7. Contextual information\n8. Supervised scores\n9. Polarity scores\n10. Word vectors\n11. Document vectors\n12. Supervised hand-crafted features\n13. Unsupervised hand-crafted features", "evaluation": "f1"}
{"query": "What word-based and dictionary-based feature are used?", "gt": "generate word embeddings specific to a domain, TDK (T\u00fcrk Dil Kurumu - \u201cTurkish Language Institution\u201d) dictionary to obtain word polarities", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 20 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The paper proposes a novel approach for sentiment analysis in Turkish and English. The approach combines word embeddings with hand-crafted features to improve the accuracy of sentiment analysis. The word embeddings are generated using the corpus-based approach, which captures contextual information, and the dictionary-based approach, which leverages the sentiment lexicon. The hand-crafted features are extracted from the reviews and include the minimum, mean, and maximum polarity scores. The approach is evaluated on two Turkish and two English datasets and outperforms the baseline approach and other state-of-the-art models.", "evaluation": "f1"}
{"query": "How are the supervised scores of the words calculated?", "gt": "(+1 or -1), words of opposite polarities (e.g. \u201chappy\" and \u201cunhappy\") get far away from each other", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The supervised scores of the words are calculated using the sentiment lexicon and the sentiment scores of the reviews.", "evaluation": "f1"}
{"query": "What topic is covered in the Chinese Facebook data? ", "gt": "anti-nuclear-power", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Nuclear power", "evaluation": "f1"}
{"query": "How many layers does the UTCNN model have?", "gt": "eight layers", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The paper proposes a deep learning model called UTCNN (User-Topic-Comment Neural Network) for text classification on social media platforms. The model incorporates user, topic, content, and comment information to improve the performance of stance classification. The model has multiple layers.", "evaluation": "f1"}
{"query": "What topics are included in the debate data?", "gt": "abortion, gay rights, Obama, marijuana", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Abortion, gay rights, Obama, marijuana.", "evaluation": "f1"}
{"query": "What topics are included in the debate data?", "gt": "abortion (ABO), gay rights (GAY), Obama (OBA), and marijuana (MAR)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The CreateDebate dataset includes four topics: abortion, gay rights, Obama, and marijuana.", "evaluation": "f1"}
{"query": "What is the size of the Chinese data?", "gt": "32,595", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Large.", "evaluation": "f1"}
{"query": "Did they collected the two datasets?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Yes.", "evaluation": "f1"}
{"query": "What are the baselines?", "gt": "SVM with unigram, bigram, trigram features, with average word embedding, with average transformed word embeddings, CNN and RCNN, SVM, CNN, RCNN with comment information", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The baselines for the proposed model are SVM with unigram, bigram, and trigram features, SVM with average word embedding, CNN, and Recurrent Convolutional Neural Networks (RCNN).", "evaluation": "f1"}
{"query": "why are their techniques cheaper to implement?", "gt": "They use a slightly modified copy of the target to create the pseudo-text instead of full BT to make their technique cheaper", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 22 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The techniques for integrating monolingual data in NMT are cheaper to implement because they do not require additional computational resources or specialized hardware.", "evaluation": "f1"}
{"query": "what data simulation techniques were introduced?", "gt": "copy, copy-marked, copy-dummies", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Simulation techniques for NMT.", "evaluation": "f1"}
{"query": "what is their explanation for the effectiveness of back-translation?", "gt": "when using BT, cases where the source is shorter than the target are rarer; cases when they have the same length are more frequent, automatic word alignments between artificial sources tend to be more monotonic than when using natural sources", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 40 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Back-translation (BT) is a technique used to generate artificial parallel data for training neural machine translation (NMT) systems. It involves translating a source text into a target language and then translating the target text back into the source language. The resulting artificial parallel data can be used to improve the performance of NMT systems, particularly in domain adaptation scenarios.", "evaluation": "f1"}
{"query": "what dataset is used?", "gt": "Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 17 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The paper \"Improving NMT with Monolingual Data\" discusses the use of monolingual data in neural machine translation (NMT) systems. The authors explore various ways to use monolingual data in NMT and find that back-translation (BT) is the most effective method. They also find that the quality of BT data matters for NMT and that the properties of back-translated sentences actually matter for MT quality. The authors also find that using artificial parallel data in NMT is more efficient than using a target-side language model.", "evaluation": "f1"}
{"query": "what language pairs are explored?", "gt": "English-German, English-French", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "English-French, English-German", "evaluation": "f1"}
{"query": "what language is the data in?", "gt": "English , German, French", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 4 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The data is in English.", "evaluation": "f1"}
{"query": "What metrics are used for evaluation?", "gt": "BLEU-1/4 and ROUGE-L, likelihood of generated recipes using identical input specifications but conditioned on ten different user profiles, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), neural scoring model from BIBREF33 to measure recipe-level coherence", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 35 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The main contributions of this document are as follows:\n\n* The authors propose a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences.\n* They release a new dataset of 180K+ recipes and 700K+ user reviews for this task.\n* They introduce new evaluation strategies for generation quality in instructional texts, centering on quantitative measures of coherence.\n* They show that personalized models generate high-quality and specific recipes that align with historical user preferences.\n\nThe document combines two important tasks from natural language processing and recommender systems: data-to-text generation and personalized recommendation. The model takes as user input the name of a specific dish, a few key ingredients, and a calorie level. The model passes these loose input specifications to an encoder-decoder framework and attends on user profiles to generate a recipe personalized to the user's tastes. The authors fuse these `user-aware' representations with decoder output in an attention fusion layer to jointly determine text generation. They show that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "What natural language(s) are the recipes written in?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research paper that proposes a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences. The paper introduces a new dataset of 180K+ recipes and 700K+ user reviews for this task and proposes a new approach that combines two important tasks from natural language processing and recommender systems. The model takes as user input the name of a specific dish, a few key ingredients, and a calorie level and passes these loose input specifications to an encoder-decoder framework and attends on user profiles to generate a recipe personalized to the user's tastes. The paper presents qualitative and quantitative analysis on user-aware model outputs and shows that personalization indeed assists in generating plausible recipes from incomplete ingredients. The paper also compares the personalized models against two baselines and shows that personalized models make more diverse recipes than baseline and obtain a correspondingly lower BLEU-1 score. The paper also presents sample outputs for a cocktail recipe and additional recipes in the appendix.", "evaluation": "f1"}
{"query": "What were their results on the new dataset?", "gt": "average recipe-level coherence scores of 1.78-1.82, human evaluators preferred personalized model outputs to baseline 63% of the time", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research paper that proposes a model to generate personalized recipes from incomplete input specifications. The model uses user preferences extracted from previously consumed recipes to generate a recipe personalized to the user's tastes. The paper introduces a new dataset of 180K+ recipes and 700K+ user reviews for this task and presents qualitative and quantitative analysis on user-aware model outputs. The paper also compares the personalized models against two baselines and presents sample outputs for a cocktail recipe.", "evaluation": "f1"}
{"query": "What are the baseline models?", "gt": "name-based Nearest-Neighbor model (NN), Encoder-Decoder baseline with ingredient attention (Enc-Dec)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The main contributions of this document are as follows:\n\n* The authors propose a new task of generating plausible and personalized recipes from incomplete input specifications by leveraging historical user preferences.\n* They release a new dataset of 180K+ recipes and 700K+ user reviews for this task.\n* They introduce new evaluation strategies for generation quality in instructional texts, centering on quantitative measures of coherence.\n* They show that personalized models generate high-quality and specific recipes that align with historical user preferences.\n\nThe document is related to the following works:\n\n* Large-scale transformer-based language models have shown surprising expressivity and fluency in creative and conditional long-text generation.\n* Recent works have proposed hierarchical methods that condition on narrative frameworks to generate internally consistent long texts.\n* Recipe generation belongs to the field of data-to-text natural language generation.\n* BIBREF14, BIBREF15 model recipes as a structured collection of ingredient entities acted upon by cooking actions.\n* BIBREF0 imposes a `checklist' attention constraint emphasizing hitherto unused ingredients during generation.\n* A recent line of work has explored user- and item-dependent aspect-aware review generation.\n\nThe model's input specification consists of: the recipe name as a sequence of tokens, a partial list of ingredients, and a caloric level (high, medium, low). It outputs the recipe instructions as a token sequence: $\\mathcal {W}_r=\\lbrace w_{r,0}, \\dots , w_{r,T}\\rbrace $ for a recipe $r$ of length $T$. To personalize output, the authors use historical recipe interactions of a user $u \\in \\mathcal {U}$.\n\nThe encoder has three embedding layers: vocabulary embedding $\\mathcal {V}$, ingredient embedding $\\mathcal {I}$, and caloric-level embedding $\\mathcal {C}$. Each token in the (length $L_n$) recipe name is embedded via $\\mathcal {V}$; the embedded token sequence is passed to a two-layered bidirectional GRU (BiGRU) BIBREF17, which outputs hidden states for names $\\lbrace \\mathbf {n}_{\\text{enc},j} \\in \\mathbb {R}^{2d_h}\\rbrace $, with hidden size $", "evaluation": "f1"}
{"query": "How did they obtain the interactions?", "gt": "from Food.com", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research paper that proposes a new approach to generating personalized recipes from incomplete input specifications. The paper introduces a new dataset of 180K+ recipes and 700K+ user reviews for this task, and presents a new model that combines two important tasks from natural language processing and recommender systems. The model takes as user input the name of a specific dish, a few key ingredients, and a calorie level, and passes these loose input specifications to an encoder-decoder framework and attends on user profiles to generate a recipe personalized to the user's tastes. The paper presents quantitative and qualitative analysis on user-aware model outputs and shows that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "Where do they get the recipes from?", "gt": "from Food.com", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research paper that proposes a model to generate personalized recipes from incomplete input specifications. The model uses user preferences extracted from previously consumed recipes to generate a recipe personalized to the user's tastes. The paper introduces a new dataset of 180K+ recipes and 700K+ user reviews for this task and introduces new evaluation strategies for generation quality in instructional texts. The paper also compares the personalized models against two baselines and shows that personalized models generate high-quality and specific recipes that align with historical user preferences.", "evaluation": "f1"}
{"query": "what are their results on the constructed dataset?", "gt": "AutoJudge consistently and significantly outperforms all the baselines, RC models achieve better performance than most text classification models (excluding GRU+Attention), Comparing with conventional RC models, AutoJudge achieves significant improvement", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 29 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The results of the proposed model on the constructed dataset show significant improvement over other baselines, including text classification models and reading comprehension models. The model achieves an accuracy of 85.2% and an F1 score of 0.83.", "evaluation": "f1"}
{"query": "what evaluation metrics are reported?", "gt": "precision, recall, F1 and accuracy", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Accuracy, F1 score, precision, recall, support.", "evaluation": "f1"}
{"query": "what civil field is the dataset about?", "gt": "divorce", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Divorce", "evaluation": "f1"}
{"query": "what are the state-of-the-art models?", "gt": "SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "State-of-the-art models for judgment prediction in civil law include SVM, attention-based methods, and reading comprehension models.", "evaluation": "f1"}
{"query": "what is the size of the real-world civil case dataset?", "gt": "100 000 documents", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "7 times more than criminal cases.", "evaluation": "f1"}
{"query": "what datasets are used in the experiment?", "gt": "build a new one, collect INLINEFORM0 cases from China Judgments Online", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 11 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset used in the experiment is a real-world dataset of Chinese civil cases.", "evaluation": "f1"}
{"query": "What domains are covered in the corpus?", "gt": "No specific domain is covered in the corpus.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The corpus covers various domains.", "evaluation": "f1"}
{"query": "What is the architecture of their model?", "gt": "follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The architecture of their model is not specified in the given document.", "evaluation": "f1"}
{"query": "How was the dataset collected?", "gt": "Contributors record voice clips by reading from a bank of donated sentences.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset was collected through crowdsourcing and professional translations.", "evaluation": "f1"}
{"query": "Which languages are part of the corpus?", "gt": "French, German, Dutch, Russian, Spanish, Italian, Turkish, Persian, Swedish, Mongolian and Chinese", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The corpus includes 11 languages into English, diversified with over 11,000 speakers and over 60 accents.", "evaluation": "f1"}
{"query": "How is the quality of the data empirically evaluated? ", "gt": "Validated transcripts were sent to professional translators., various sanity checks to the translations,  sanity check the overlaps of train, development and test sets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The quality of the data in CoVoST is empirically evaluated using various sanity checks such as sentence-level BLEU, perplexity, and ratio of English characters in translations. Additionally, the overlaps of train, development, and test sets in terms of transcripts and voice clips are confirmed to be disjoint.", "evaluation": "f1"}
{"query": "Is the data in CoVoST annotated for dialect?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "Is Arabic one of the 11 languages in CoVost?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "What kind of model do they use?", "gt": "visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 39 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The authors propose a joint model that combines textual and visual features to assess document quality. The textual features are learned using a biLSTM model, while the visual features are learned using a fine-tuned Inception V3 model. The two models are combined using a simple feed-forward layer.", "evaluation": "f1"}
{"query": "What kind of model do they use?", "gt": "Inception V3, biLSTM", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They use a joint model.", "evaluation": "f1"}
{"query": "Did they release their data set of academic papers?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "Do the methods that work best on academic papers also work best on Wikipedia?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "What is their system's absolute accuracy?", "gt": "59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 26 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The system's absolute accuracy is 59.4% on Wikipedia and 71.2% on arXiv.", "evaluation": "f1"}
{"query": "Which is more useful, visual or textual features?", "gt": "It depends on the dataset. Experimental results over two datasets reveal that textual and visual features are complementary. ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Both visual and textual features are useful for document quality assessment, but combining them can lead to better accuracy.", "evaluation": "f1"}
{"query": "Which languages do they use?", "gt": "English", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "English, German, French, Spanish, Italian, Portuguese, Russian, Chinese, Japanese, Korean, Arabic, Turkish, Hindi, Bengali, Vietnamese, Indonesian, Thai, Filipino, Malayalam, Tamil, Telugu, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, Tamil, Marathi, Urdu, Punjabi, Gujarati, Hindi, Bengali, Telugu, T", "evaluation": "f1"}
{"query": "How large is their data set?", "gt": "a sample of  29,794 wikipedia articles and 2,794 arXiv papers ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset is large, with 29,794 articles.", "evaluation": "f1"}
{"query": "Where do they get their ground truth quality judgments?", "gt": "quality class labels assigned by the Wikipedia community, a paper is considered to have been accepted (i.e. is positively labeled) if it matches a paper in the DBLP database or is otherwise accepted by any of the following conferences: ACL, EMNLP, NAACL, EACL, TACL, NIPS, ICML, ICLR, or AAAI", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 49 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The ground truth quality judgments for document quality assessment are typically obtained through human evaluation, where human annotators assign a quality label to a given document based on a set of predefined criteria.", "evaluation": "f1"}
{"query": "What is the seed lexicon?", "gt": "a vocabulary of positive and negative predicates that helps determine the polarity score of an event", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 16 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The seed lexicon is a set of positive and negative words used to train the model. It consists of 15 positive words and 15 negative words. The positive words are \"\u559c\u3076\", \"\u5b09\u3057\u3044\", \"\u697d\u3057\u3044\", \"\u5e78\u305b\", \"\u611f\u52d5\", \"\u8208\u596e\", \"\u61d0\u304b\u3057\u3044\", \"\u597d\u304d\", \"\u5c0a\u656c\", \"\u5b89\u5fc3\", \"\u611f\u5fc3\", \"\u843d\u3061\u7740\u304f\", \"\u6e80\u8db3\", \"\u7652\u3055\u308c\u308b\", and \"\u30b9\u30c3\u30ad\u30ea\". The negative words are \"\u6012\u308b\", \"\u60b2\u3057\u3044\", \"\u5bc2\u3057\u3044\", \"\u6016\u3044\", \"\u4e0d\u5b89\", \"\u6065\u305a\u304b\u3057\u3044\", \"\u5acc\", \"\u843d\u3061\u8fbc\u3080\", \"\u9000\u5c48\", \"\u7d76\u671b\", \"\u8f9b\u3044\", \"\u56f0\u308b\", \"\u6182\u9b31\", \"\u60c5\u3051\u306a\u3044\", and \"\u5fc3\u914d\".", "evaluation": "f1"}
{"query": "What is the seed lexicon?", "gt": "seed lexicon consists of positive and negative predicates", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The seed lexicon is a set of positive and negative words used to train the model.", "evaluation": "f1"}
{"query": "What are the results?", "gt": "Using all data to train: AL -- BiGRU achieved 0.843 accuracy, AL -- BERT achieved 0.863 accuracy, AL+CA+CO -- BiGRU achieved 0.866 accuracy, AL+CA+CO -- BERT achieved 0.835, accuracy, ACP -- BiGRU achieved 0.919 accuracy, ACP -- BERT achived 0.933, accuracy, ACP+AL+CA+CO -- BiGRU achieved 0.917 accuracy, ACP+AL+CA+CO -- BERT achieved 0.913 accuracy. \nUsing a subset to train: BERT achieved 0.876 accuracy using ACP (6K), BERT achieved 0.886 accuracy using ACP (6K) + AL, BiGRU achieved 0.830 accuracy using ACP (6K), BiGRU achieved 0.879 accuracy using ACP (6K) + AL + CA + CO.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 94 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The paper proposes a method for learning the polarity of an affective event, which is represented by a score ranging from $-1$ (negative) to 1 (positive). The method uses discourse relations to efficiently propagate polarity from seed predicates that directly report one's emotions. The key idea is that if events $x_1$ and $x_2$ are in the discourse relation of Cause (i.e., $x_1$ causes $x_2$), if the seed lexicon suggests $x_2$ is positive, $x_1$ is also likely to be positive because it triggers the positive emotion. The paper trained the models using a Japanese web corpus and found that the models performed well even with a minimal amount of supervision. The combination of annotated and unannotated data yielded a gain over a purely supervised baseline when labeled data were small. The paper also compared the performance of the proposed method with other related work and found that the proposed method outperformed supervised models and performed competitively with other methods.", "evaluation": "f1"}
{"query": "How are relations used to propagate polarity?", "gt": "cause relation: both events in the relation should have the same polarity; concession relation: events should have opposite polarity", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 19 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Discourse relations are used to propagate polarity by exploiting the tendency of events to be of the same polarity. For example, if two events are in the discourse relation of Cause and the seed lexicon suggests that the latter event is positive, the former event is likely to be positive because it triggers the positive emotion. Similarly, if two events are in the discourse relation of Concession, the reverse of the latter event's polarity can be propagated to the former event. This is done by exploiting the tendency of events to be of the same polarity or of the reverse polarity.", "evaluation": "f1"}
{"query": "How big is the Japanese data?", "gt": "The ACP corpus has around 700k events split into positive and negative polarity ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The Japanese data used in the paper is a web corpus that was compiled through the procedures proposed by BIBREF13. To extract event pairs tagged with discourse relations, the authors used the Japanese dependency parser KNP and in-house postprocessing scripts. The corpus contains about 100 million sentences.", "evaluation": "f1"}
{"query": "What are labels available in dataset for supervision?", "gt": "negative, positive", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Labels available in dataset for supervision: positive, negative.", "evaluation": "f1"}
{"query": "How big are improvements of supervszed learning results trained on smalled labeled data enhanced with proposed approach copared to basic approach?", "gt": "3%", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Improvements.", "evaluation": "f1"}
{"query": "How does their model learn using mostly raw data?", "gt": "by exploiting discourse relations to propagate polarity from seed predicates to final sentiment polarity", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The proposed method learns affective events by exploiting discourse relations to propagate polarity from seed predicates.", "evaluation": "f1"}
{"query": "How big is seed lexicon used for training?", "gt": "30 words", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The seed lexicon used for training is small.", "evaluation": "f1"}
{"query": "How large is raw corpus used for training?", "gt": "100 million sentences", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Large raw corpus.", "evaluation": "f1"}
{"query": "What data is the language model pretrained on?", "gt": "Chinese general corpus", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 3 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "BERT-base", "evaluation": "f1"}
{"query": "What baselines is the proposed model compared against?", "gt": "BERT-Base, QANet", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "BERT, QANet", "evaluation": "f1"}
{"query": "How is the clinical text structuring task defined?", "gt": "Clinical text structuring (CTS) is a critical task for fetching medical research data from electronic health records (EHRs), where structural patient medical data, such as whether the patient has specific symptoms, diseases, or what the tumor size is, how far from the tumor is cut at during the surgery, or what the specific laboratory test result is, are obtained., Unlike the traditional CTS task, our QA-CTS task aims to discover the most related text from original paragraph text. ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 78 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Clinical text structuring (CTS) is a task in natural language processing that involves extracting structured data from unstructured clinical text. The task is defined as follows: given a paragraph of clinical text, the goal is to extract a specific piece of information (e.g., the size of a tumor) that is relevant to a query term. The extracted information is often in the form of a key-value pair, where the key is the query term and the value is the result of the query term in the paragraph text. The task is often used in the medical field to extract structured data from electronic health records (EHRs) for downstream clinical research.", "evaluation": "f1"}
{"query": "How is the clinical text structuring task defined?", "gt": "CTS is extracting structural data from medical research data (unstructured). Authors define QA-CTS task that aims to discover most related text from original text.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Clinical text structuring (CTS) is the task of extracting structured data from unstructured clinical text.", "evaluation": "f1"}
{"query": "What are the specific tasks being unified?", "gt": " three types of questions, namely tumor size, proximal resection margin and distal resection margin", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Clinical Text Structuring (CTS) tasks are being unified.", "evaluation": "f1"}
{"query": "Is all text in this dataset a question, or are there unrelated sentences in between questions?", "gt": "the dataset consists of pathology reports including sentences and questions and answers about tumor size and resection margins so it does include additional sentences ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 24 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset in the paper is a collection of clinical text that includes both questions and unrelated sentences.", "evaluation": "f1"}
{"query": "How many questions are in the dataset?", "gt": "2,714 ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "17833", "evaluation": "f1"}
{"query": "How they introduce domain-specific features into pre-trained language model?", "gt": "integrate clinical named entity information into pre-trained language model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 9 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They introduce named entity information into pre-trained language model.", "evaluation": "f1"}
{"query": "How big is QA-CTS task dataset?", "gt": "17,833 sentences, 826,987 characters and 2,714 question-answer pairs", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "QA-CTS task dataset is large.", "evaluation": "f1"}
{"query": "What are strong baseline models in specific tasks?", "gt": "state-of-the-art question answering models (i.e. QANet BIBREF39) and BERT-Base BIBREF26", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Strong baseline models in specific tasks are rule-based, task-specific end-to-end methods, and pipeline methods.", "evaluation": "f1"}
{"query": "What is the previous work's model?", "gt": "Ternary Trans-CNN", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Transfer Learning", "evaluation": "f1"}
{"query": "What dataset is used?", "gt": "HEOT , A labelled dataset for a corresponding english tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 10 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset used is HEOT obtained from Mathur et al.", "evaluation": "f1"}
{"query": "How big is the dataset?", "gt": "3189 rows of text messages", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset is small.", "evaluation": "f1"}
{"query": "How big is the dataset?", "gt": "Resulting dataset was 7934 messages for train and 700 messages for test.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset has 3189 rows of text messages of average length of 116 words and with a range of 1, 1295.", "evaluation": "f1"}
{"query": "How is the dataset collected?", "gt": "A labelled dataset for a corresponding english tweets were also obtained from a study conducted by Davidson et al, HEOT obtained from one of the past studies done by Mathur et al", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 32 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset used in this study was obtained from one of the past studies done by Mathur et al. where they annotated a set of cleaned tweets obtained from Twitter for conversations happening in the Indian subcontinent. A labelled dataset for corresponding English tweets was also obtained from a study conducted by Davidson et al.", "evaluation": "f1"}
{"query": "Was each text augmentation technique experimented individually?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "What models do previous work use?", "gt": "Ternary Trans-CNN , Hybrid multi-channel CNN and LSTM", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 8 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Previous work uses Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) for text classification.", "evaluation": "f1"}
{"query": "Does the dataset contain content from various social media platforms?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Yes.", "evaluation": "f1"}
{"query": "What additional techniques are incorporated?", "gt": "incorporating coding syntax tree model", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 5 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Statistical Machine Translation, Vocabulary Generation, Neural Model Training, Attention Mechanism, Sigmoidal Optimization.", "evaluation": "f1"}
{"query": "What dataset do they use?", "gt": "A parallel corpus where the source is an English expression of code and the target is Python code.", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They use a text-code parallel corpus with 18805 aligned data in English and Python programming language for training their neural machine translation model.", "evaluation": "f1"}
{"query": "Do they compare to other models?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "What is the architecture of the system?", "gt": "seq2seq translation", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Neural Architecture.", "evaluation": "f1"}
{"query": "What additional techniques could be incorporated to further improve accuracy?", "gt": "phrase-based word embedding, Abstract Syntax Tree(AST)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 6 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Incorporating more data and using abstract syntax trees could improve accuracy.", "evaluation": "f1"}
{"query": "What programming language is target language?", "gt": "Python", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Python", "evaluation": "f1"}
{"query": "What dataset is used to measure accuracy?", "gt": "validation data", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Validation data", "evaluation": "f1"}
{"query": "What corpus was the source of the OpenIE extractions?", "gt": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a new QA system called TupleInf that uses Open IE tuples to answer complex multiple-choice questions. The system is designed to perform reasoning with Open IE tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is implemented in a reasoner called TupleInf and is compared with two state-of-the-art systems for 4th and 8th grade science exams. The results show that TupleInf outperforms the other systems and achieves scores comparable to TableILP on the Regents questions. The system is also complementary to IR and can be used in an ensemble with other solvers to improve performance.", "evaluation": "f1"}
{"query": "What is the accuracy of the proposed technique?", "gt": "51.7 and 51.6 on 4th and 8th grade question sets with no curated knowledge. 47.5 and 48.0 on 4th and 8th grade question sets when both solvers are given the same knowledge", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 32 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a new QA system called TupleInf that uses Open IE based tuples to answer complex multiple-choice questions that require tuples from multiple sentences. The system is designed to perform reasoning with Open IE based tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is implemented in a reasoner called TupleInf and is compared with two state-of-the-art systems for 4th and 8th grade science exams. The results show that TupleInf outperforms the other systems by more than 11%. The system is also complementary to an information-retrieval baseline and an ensemble system. The system is designed to be simple and generalizable, and it is able to achieve scores comparable to the state-of-the-art on the target Regents questions without any specialized rules. The system is able to handle noisy tuples and is able to combine parallel evidence. The system is able to handle complex multiple-choice questions that require tuples from multiple sentences.", "evaluation": "f1"}
{"query": "Is an entity linking process used?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research project that aims to develop a question answering (QA) system that can perform reasoning with Open IE (Information Extraction) tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is designed to answer questions in resource-poor domains where curated knowledge is unavailable. The authors present a new ILP-based model of inference with tuples, implemented in a reasoner called TupleInf. They demonstrate that TupleInf significantly outperforms TableILP by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The authors also discuss related work in retrieval-based web question-answering and science question-answering.", "evaluation": "f1"}
{"query": "Are the OpenIE extractions all triples?", "gt": "No", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research project that aims to develop a question-answering (QA) system that can perform reasoning with Open IE (Information Extraction) tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is designed to answer complex questions in resource-poor domains where curated knowledge is unavailable. The authors present a new ILP-based model of inference with tuples, implemented in a reasoner called TupleInf. They demonstrate that TupleInf significantly outperforms TableILP by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The authors also discuss related work in retrieval-based web question-answering and science question-answering.", "evaluation": "f1"}
{"query": "What method was used to generate the OpenIE extractions?", "gt": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 56 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a new QA system called TupleInf that uses Open IE based knowledge to answer complex multiple-choice questions. The system is designed to work with a large, automatically extracted tuple KB that has broader coverage than structured curated KBs. The system uses an ILP-based model of inference with tuples to search for an optimal subgraph that connects terms in the question and answer via rows in a set of curated tables. The system is tested on a broad set of over 1,300 science questions and outperforms a state-of-the-art system called TableILP by 11.8%. The system is also able to generalize well to higher grade levels.", "evaluation": "f1"}
{"query": "Can the method answer multi-hop questions?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research project that aims to develop a question-answering (QA) system that can perform reasoning with Open IE (Information Extraction) tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is designed to answer complex questions in resource-poor domains where curated knowledge is unavailable. The authors present a new ILP-based model of inference with tuples, implemented in a reasoner called TupleInf. They demonstrate that TupleInf significantly outperforms TableILP by 11.8% on a broad set of over 1,300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The authors also discuss related work and provide an overview of the TupleInf system.", "evaluation": "f1"}
{"query": "What was the textual source to which OpenIE was applied?", "gt": "domain-targeted $~$ 80K sentences and 280 GB of plain text extracted from web pages used by BIBREF6 aristo2016:combining", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 18 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a research project that aims to develop a question-answering (QA) system that can perform reasoning with Open IE (Information Extraction) tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is designed to answer complex questions in resource-poor domains where curated knowledge is unavailable. The authors present a new ILP-based model of inference with tuples, implemented in a reasoner called TupleInf. They demonstrate that TupleInf significantly outperforms TableILP by 11.8% on a broad set of over 1300 science questions, without requiring manually curated tables, using a substantially simpler ILP formulation, and generalizing well to higher grade levels. The authors also discuss related work in retrieval-based web question-answering and science question-answering.", "evaluation": "f1"}
{"query": "What OpenIE method was used to generate the extractions?", "gt": "for each multiple-choice question $(q,A) \\in Q_\\mathit {tr}$ and each choice $a \\in A$ , we use all non-stopword tokens in $q$ and $a$ as an ElasticSearch query against S, take the top 200 hits, run Open IE v4, and aggregate the resulting tuples over all $a \\in A$ and over all questions in $Q_\\mathit {tr}$", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 56 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a new QA system called TupleInf that uses Open IE based tuples to answer complex multiple-choice questions. The system is designed to perform reasoning with Open IE based tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is implemented in a reasoner called TupleInf and is compared with two state-of-the-art systems for 4th and 8th grade science exams. The results show that TupleInf outperforms the other systems by more than 11%. The system uses an ILP-based model of inference with tuples, implemented in a reasoner called TupleInf, to search for an optimal subgraph that connects terms in the question and answer via rows in a set of curated tables. The system is designed to handle noisy tuples and uses a simple ILP formulation that generalizes well to higher grade levels.", "evaluation": "f1"}
{"query": "Is their method capable of multi-hop reasoning?", "gt": "Yes", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The document describes a new QA system called TupleInf that uses Open IE based tuples to answer complex multiple-choice questions that require tuples from multiple sentences. The system is designed to perform reasoning with Open IE based tuples for complex multiple-choice questions that require tuples from multiple sentences. The system is implemented in a reasoner called TupleInf and is compared with two state-of-the-art systems for 4th and 8th grade science exams. The results show that TupleInf with only automatically extracted tuples significantly outperforms TableILP with its original curated knowledge as well as with additional tuples, and that TupleInf's complementary approach to IR leads to an improved ensemble. The system is designed to be able to handle noisy tuples and to generalize well to higher grade levels.", "evaluation": "f1"}
{"query": "What models do they propose?", "gt": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "They propose three multimodal models for hate speech detection in social media publications.", "evaluation": "f1"}
{"query": "Are all tweets in English?", "gt": "Unanswerable", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 1 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "No.", "evaluation": "f1"}
{"query": "How large is the dataset?", "gt": " $150,000$ tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Large.", "evaluation": "f1"}
{"query": "What is the results of multimodal compared to unimodal models?", "gt": "Unimodal LSTM vs Best Multimodal (FCM)\n- F score: 0.703 vs 0.704\n- AUC: 0.732 vs 0.734 \n- Mean Accuracy: 68.3 vs 68.4 ", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 23 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The proposed multimodal models do not outperform the textual models in hate speech detection on multimodal publications.", "evaluation": "f1"}
{"query": "What is author's opinion on why current multimodal models cannot outperform models analyzing only text?", "gt": "Noisy data, Complexity and diversity of multimodal relations, Small set of multimodal examples", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 13 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The author believes that current multimodal models cannot outperform textual models due to noisy data, complexity, and small set of examples.", "evaluation": "f1"}
{"query": "What metrics are used to benchmark the results?", "gt": "F-score, Area Under the ROC Curve (AUC), mean accuracy (ACC), Precision vs Recall plot, ROC curve (which plots the True Positive Rate vs the False Positive Rate)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 27 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The metrics used to benchmark the results are F-score, Area Under the ROC Curve (AUC), and mean accuracy (ACC).", "evaluation": "f1"}
{"query": "How is data collected, manual collection or Twitter api?", "gt": "Twitter API", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "Manual collection.", "evaluation": "f1"}
{"query": "How many tweats does MMHS150k contains, 150000?", "gt": "$150,000$ tweets", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 2 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "150,000 tweets.", "evaluation": "f1"}
{"query": "What unimodal detection models were used?", "gt": " single layer LSTM with a 150-dimensional hidden state for hate / not hate classification", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 14 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The unimodal detection models used are LSTM for text and CNN for images.", "evaluation": "f1"}
{"query": "What different models for multimodal detection were proposed?", "gt": "Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), Textual Kernels Model (TKM)", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 12 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The proposed models for multimodal hate speech detection are: Feature Concatenation Model (FCM), Spatial Concatenation Model (SCM), and Textual Kernels Model (TKM).", "evaluation": "f1"}
{"query": "What annotations are available in the dataset - tweat used hate speach or not?", "gt": "No attacks to any community,  racist, sexist, homophobic, religion based attacks, attacks to other communities", "prompt": "[INST]Now you are given a very long document. Please follow the instruction after this document. These instructions may include summarizing a document, answering questions based on the document, or writing a required paragraph. Document is as follows. {document} Instruction: {inst} \nAnswer this question with 15 words.[/INST]", "mistralai/Mistral-7B-Instruct-v0.1-8k-noSW_pred": "The dataset contains annotations for hate speech and not hate speech tweets.", "evaluation": "f1"}
