{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/et/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login 993395b2e1419dcfe584aaa7de88f2a16decd906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "from scipy.stats import expon\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16c6c112dda45c7ba3f11a84a2498f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "checkpoint = \"mistralai/Mistral-7B-v0.1\"\n",
    "#checkpoint = \"lmsys/vicuna-7b-v1.3\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "config.update({'_flash_attn_2_enabled' : True})  #Flash Attention\n",
    "#config.update({'sliding_window' : 15_000})  #eliminating sliding window\n",
    "#config.update({'rope_scaling' : {\"type\": \"linear\",\n",
    "#                                 \"factor\": .5,\n",
    "#                                }})             #Position Interpolation\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast = False, revision = 'main', config = config,)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
    "                                             low_cpu_mem_usage = True,\n",
    "                                             torch_dtype = torch.float16,\n",
    "                                             revision='main',\n",
    "                                             device_map='auto',\n",
    "                                             #load_in_8bit=True,\n",
    "                                             config = config,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "        r=8, #dimension of the low-rank matrices\n",
    "        lora_alpha=32, # scaling factor for the weight matrices\n",
    "        lora_dropout=0.05, # dropout probability of the LoRA layers\n",
    "        bias=\"none\", # set to all to train all bias parameters\n",
    "        task_type=\"CAUSAL_LM\",  # casual language modeling\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"] # the layer within a neural networkk to which LoRA reg will be applied\n",
    "        )\n",
    "\n",
    "model.enable_input_require_grads()\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable_params: 136,056,832\n"
     ]
    }
   ],
   "source": [
    "def _prepare_lora_plus_training(model):\n",
    "    for n,p in model.named_parameters():\n",
    "        p.requires_grad = False\n",
    "        if any(s in n for s in ['lora', 'embed', 'norm']):\n",
    "            p.requires_grad = True\n",
    "            p.data = p.data.to(torch.float32)\n",
    "    \n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'trainable_params: {trainable_params:,}')\n",
    "\n",
    "_prepare_lora_plus_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    if any(s in n for s in ['lora', 'embed', 'norm']):\n",
    "        p.data = torch.zeros_like(p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-4.8380e-03,  1.1869e-03, -4.3838e-03,  ...,  9.2233e-03,\n",
       "         -6.1412e-03, -1.3354e-02],\n",
       "        [-8.4266e-03,  5.2014e-03,  1.3912e-02,  ...,  1.2110e-02,\n",
       "         -1.3493e-03,  1.4394e-02],\n",
       "        [ 4.5906e-03, -1.6146e-03, -8.2205e-03,  ...,  1.0393e-02,\n",
       "         -2.5918e-03, -3.6423e-03],\n",
       "        ...,\n",
       "        [ 1.4877e-02, -7.4961e-03,  9.3996e-03,  ...,  1.2108e-02,\n",
       "         -1.1141e-02,  1.0538e-02],\n",
       "        [-1.0172e-02,  1.1314e-02, -8.0768e-06,  ..., -1.0956e-02,\n",
       "          1.4113e-02, -1.3649e-03],\n",
       "        [-4.2998e-04, -3.5449e-03,  5.2839e-04,  ..., -1.4141e-02,\n",
       "         -1.3931e-03,  4.9458e-03]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.model.embed_tokens.weight\n",
    "model.model.model.layers[-1].self_attn.q_proj.lora_A.default.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_lora_plus_weights(model, dir):\n",
    "    filtered_state_dict = {key: value for key, value in model.state_dict().items() if any(s in key for s in ['lora', 'embed', 'norm'])}\n",
    "    torch.save(filtered_state_dict, dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = torch.load('./model_weights/Mistral-7B-v0.1-context_extension-stage1/checkpoint_3.pt')\n",
    "for k,v in saved['model_state_dict'].items():\n",
    "    for n,p in model.named_parameters():\n",
    "        if n == k:\n",
    "            p.data = v.data\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_save_lora_plus_weights(model, 'test.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(story):\n",
    "    instruction = \"Below is a story. Your task is to provide a short summary of it - only from what is below, do not introduce exterior knowledge. It should retain only the major milestones of the story while ignoring all superfluours details.\"\n",
    "    full_prompt = \"### Human\\n\" + instruction + \"\\nStory: \" + story + \"\\n### Assistant\\n\"\n",
    "    input_ids = tokenizer(full_prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "    print(input_ids.shape[1])\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1291\n"
     ]
    }
   ],
   "source": [
    "story = \"\"\"Title: \"The Adventures of Luna the Brave Bunny\"\n",
    "\n",
    "Once upon a time, in a cozy little burrow nestled deep in the heart of the Enchanted Forest, there lived a brave and curious bunny named Luna. Luna was a little bunny with a big heart, and she loved to explore. She had soft, white fur, big, floppy ears, and bright, sparkling eyes that shone like the stars in the night sky.\n",
    "\n",
    "Every evening, Luna's mother would tell her bedtime stories about the magical wonders of the Enchanted Forest. Luna would snuggle up in her soft, fluffy blanket, and her eyes would widen with excitement as her mother's stories whisked her away to far-off places filled with talking animals, friendly fairies, and shimmering streams.\n",
    "\n",
    "One night, as the moon hung low in the sky, Luna's mother began a story about the Great Tree at the heart of the forest. It was said that at the very top of the Great Tree, there was a magical wishing star that could grant any wish, no matter how big or small. The catch was that only the bravest of creatures could reach the top, and Luna was determined to be one of them.\n",
    "\n",
    "From that night on, Luna could think of nothing else. She wanted to climb the Great Tree and make a wish. She believed her wish could bring something wonderful to her family and all the forest creatures.\n",
    "\n",
    "The next morning, Luna packed a small bag with some carrot sticks, her favorite stuffed animal, a tiny lantern, and her mother's special map that marked the path to the Great Tree. She kissed her mother goodbye, and with her heart pounding in her chest, she set off on her adventure.\n",
    "\n",
    "As she ventured deeper into the forest, Luna encountered all sorts of animals. There was Wise Old Owl, who shared his wisdom about the forest, and Squirrel Sammy, who taught her to leap from branch to branch like a pro. Luna made new friends with every step, and she felt like the forest was guiding her.\n",
    "\n",
    "The path grew steeper and more challenging, but Luna was determined. She stumbled and fell a few times, but her new friends were always there to help her up and encourage her to keep going. As the sun began to set, Luna's little lantern cast a warm, golden glow on the path, guiding her way.\n",
    "\n",
    "Luna climbed higher and higher, her heart filled with hope. She could see the Great Tree in the distance, its branches reaching toward the sky like a ladder to the stars. The moonlight began to dance on the leaves, and the tree's leaves whispered secrets in the gentle breeze.\n",
    "\n",
    "Finally, Luna reached the base of the Great Tree. It was enormous, and Luna's heart pounded with both excitement and fear. She looked up, up, up, and it seemed like the top was a thousand miles away. But Luna had come too far to give up now. She started her ascent, taking one branch at a time.\n",
    "\n",
    "Luna's courage and determination propelled her higher and higher. She met creatures along the way who cheered her on and shared their wisdom. She learned from the wise old owl, danced with a friendly firefly, and even shared stories with a chatty butterfly.\n",
    "\n",
    "As Luna neared the top, she felt a sense of magic in the air. She could see the wishing star sparkling like a diamond, just within reach. Luna closed her eyes, made her wish, and whispered it to the star. Then, with a leap, she reached out and touched it.\n",
    "\n",
    "With a soft shimmer, the star granted Luna's wish, and she felt a warm, comforting feeling wash over her. She knew her wish would come true, and it filled her heart with joy.\n",
    "\n",
    "Luna began her descent, and the journey back down the Great Tree was just as magical as the climb. The forest creatures greeted her with cheers and smiles, and Luna felt like she was gliding down on a cloud.\n",
    "\n",
    "When she finally reached her cozy burrow, her mother was waiting for her, her eyes filled with love and worry. Luna's mother hugged her tightly and asked about her adventure. Luna told her all about the friends she had made, the challenges she had faced, and the magical wishing star at the top of the Great Tree.\n",
    "\n",
    "Luna's mother listened with a smile, and Luna realized that her true wish had already come true. She had found the courage to explore the world, make new friends, and return to her loving family. It was the greatest adventure of all.\n",
    "\n",
    "From that day on, Luna continued to explore the Enchanted Forest, but she also learned that the most precious adventures were the ones spent with family and friends. And as she fell asleep each night, Luna would look up at the moon and know that the stars above held all the magic in the world, and that she was a brave little bunny with a heart full of wonder.\n",
    "\n",
    "And so, the brave and curious bunny, Luna, lived happily ever after, sharing her stories of the Great Tree, the magical wishing star, and the enchanting Enchanted Forest with all the creatures who were lucky enough to meet her along the way.\n",
    "\n",
    "The end.\"\"\"\n",
    "\n",
    "input_ids = prepare_input(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"Title: \"The Courageous Knight, the Enchanted Princess, and the Wise Rabbit\"\n",
    "\n",
    "In a land where rolling meadows stretched as far as the eye could see, and majestic castles dotted the landscape like sentinels of time, there lived a kind-hearted and courageous knight named Sir Cedric. He was known throughout the realm as a paragon of bravery and justice, always ready to come to the aid of those in need, regardless of the peril that might await him.\n",
    "\n",
    "Sir Cedric, a tall and strong man with eyes that sparkled like sapphires, was renowned not only for his courage but also for his unwavering belief in the magic that surrounded him. He was a dreamer, one who saw enchantment in every whisper of the wind through the trees, in every dewdrop glistening on a blade of grass at sunrise.\n",
    "\n",
    "One sunny morning, as Sir Cedric was preparing for a tournament in the grand city of Galadore, a pure-white dove appeared at his window. The dove carried a message, a message from a king of a distant kingdom whose heart was heavy with despair. The message spoke of a great misfortune that had befallen his family. His beloved daughter, Princess Isabella, had been locked away in a mysterious castle for many long years.\n",
    "\n",
    "The message told of a powerful enchantment that encircled the castle, a spell so potent that none who ventured near it returned. The king had heard of Sir Cedric's unmatched bravery and knew in his heart that this knight was the only one who could break the curse and rescue his precious daughter. The plea was heartfelt, and it moved Sir Cedric to the core.\n",
    "\n",
    "Without a moment's hesitation, Sir Cedric mounted his trusty steed, Thunder, and set off on a long and arduous journey to the distant kingdom. He traversed lush forests, climbed towering mountains, and forded swift rivers, his thoughts always centered on the captive princess and the daunting task that lay before him.\n",
    "\n",
    "As Sir Cedric approached the kingdom, he saw the castle in the distance, perched high on a rocky hill and shrouded in an eerie, foreboding mist. The land surrounding the castle was barren and desolate, as if the enchantment that held it had drained all life from the very soil. The villagers told chilling tales of the castle, warning Sir Cedric that it was guarded by fierce magical creatures and surrounded by impenetrable barriers.\n",
    "\n",
    "But Sir Cedric's determination was unshakable. He knew that his courage would guide him through the darkest of trials. With his trusty sword at his side and his heart full of hope, he approached the castle.\n",
    "\n",
    "The moment he stepped into the castle's shadow, the ground trembled beneath his feet, and the sky overhead darkened with ominous clouds. The castle gates slammed shut behind him, and Sir Cedric was trapped within. He had entered a world of magic, mystery, and peril.\n",
    "\n",
    "Inside the castle, Sir Cedric encountered a room with walls that seemed to be made of swirling water. As he advanced, the water formed into a formidable water elemental, its form ever-changing and its intention clear: it meant to engulf him. With a swift and strategic strike of his sword, Sir Cedric overcame the water elemental, but it became evident that the castle was fraught with enchanting challenges.\n",
    "\n",
    "In the next room, he faced a wall of thorny vines that seemed to reach out hungrily, ready to ensnare him. Sir Cedric recalled a tale of a friendly forest sprite who was known to come to the aid of those in dire need. With kindness in his heart, he called out to the sprite. A tiny, mischievous figure appeared, and with a wave of its dainty hand, the thorns retracted, allowing Sir Cedric to pass.\n",
    "\n",
    "As he ventured further into the castle's depths, he encountered a room filled with enchanted mirrors. Each mirror distorted reality and showed a different path. Sir Cedric was faced with a crucial choice. Drawing upon his courage and the wisdom of those who had come before him, he selected the mirror that reflected his true self. This mirror led him safely to the next trial.\n",
    "\n",
    "The castle's corridors seemed to extend endlessly, but Sir Cedric pressed on with unwavering determination, resolute in his quest to find the captive princess. Finally, after much time had passed, he arrived at a massive door. It was covered in dense vines and thorns, known to be the door to the heart of the castle, the place where the princess was held.\n",
    "\n",
    "With immense effort, Sir Cedric forced the door open and stepped into a grand chamber. In the center of the room stood a breathtaking and enchanting fountain. It sparkled with waters so clear and pure, they seemed to be touched by magic. Surrounding the fountain were the guards of the castle, a group of formidable stone statues brought to life by the curse.\n",
    "\n",
    "The stone guards, with their lifeless eyes and towering swords, lunged at Sir Cedric, their movements synchronized and relentless. It was a battle of epic proportions, and the outcome was uncertain. But Sir Cedric's skills and unyielding bravery prevailed, one by one, and the enchantment that held the princess captive began to wane.\n",
    "\n",
    "In the very heart of the chamber, the beautiful fountain started to glow with a soft, radiant light. From the fountain, a shimmering figure emerged, revealing the ethereal form of Princess Isabella. She looked at Sir Cedric with gratitude in her eyes and whispered, \"Thank you for breaking the curse and setting me free.\"\n",
    "\n",
    "Before their very eyes, the room transformed. The walls, once covered in thorns and vines, retreated and revealed the magnificent architecture of the castle. The mirrors, which had shown deceptive paths, now reflected the truth. The water elemental, once fierce and unpredictable, turned into a peaceful stream that meandered gently through the chamber. The castle itself seemed to come alive, as if celebrating its liberation.\n",
    "\n",
    "With the enchantment finally lifted, Sir Cedric and Princess Isabella made their way out of the castle and back into the kingdom. The land, once barren and desolate, now burst with life and color. Villagers gathered, cheering and clapping, as they welcomed their princess home.\n",
    "\n",
    "The king, overjoyed to have his daughter returned to him, was filled with gratitude for Sir Cedric's bravery. He offered the noble knight a place in the kingdom as his trusted advisor and protector, a role that Sir Cedric embraced with humility and honor.\n",
    "\n",
    "Sir Cedric and Princess Isabella soon became the closest of friends, their bond solidified by the remarkable adventure they had shared. They spent their days exploring the beautiful kingdom, discovering its hidden wonders, and sharing stories of their adventures.\n",
    "\n",
    "In a kingdom filled with magic, mystery, and courage, the story of Sir Cedric and Princess Isabella became a beloved and timeless tale. It was passed down through generations as a testament to the power of bravery, the magic of friendship, and the enduring belief that love and courage could break even the most potent enchantments.\n",
    "\n",
    "But this was not the end of\n",
    "\n",
    " the story, for there was another character who played a crucial role in this tale of bravery and enchantment.\n",
    "\n",
    "While Sir Cedric was embarking on his epic quest, another story was unfolding in a quiet corner of the realm. In a tranquil glade, not far from the castle, lived a wise and gentle rabbit named Luna. Luna, with her silvery fur and wise, knowing eyes, was no ordinary rabbit. She had a gift—the ability to understand the secrets of the forest, to speak to the animals, and to glean wisdom from the ancient trees.\n",
    "\n",
    "Luna had sensed the enchantment that held the castle and had known, deep within her heart, that she could not ignore the call of destiny. She had observed Sir Cedric's arrival in the kingdom and had watched as he embarked on his perilous journey to rescue the princess.\n",
    "\n",
    "One day, as Sir Cedric was making his way through the forest surrounding the castle, he came across Luna. The wise rabbit hopped out from behind a bush, her eyes filled with curiosity and kindness. Sir Cedric, his heart full of gratitude for the kindness that had been shown to him on his journey, paused to acknowledge the small creature.\n",
    "\n",
    "\"Who are you, little one?\" he asked, his voice gentle and his eyes filled with respect.\n",
    "\n",
    "Luna, with her gift of understanding, replied in a voice as soft as the rustling leaves, \"I am Luna, a humble guardian of the forest. I sensed your noble quest and the enchantment that holds the castle. I am here to offer my aid if you should require it.\"\n",
    "\n",
    "Sir Cedric, struck by the rabbit's wisdom and the aura of magic that surrounded her, accepted her offer with gratitude. \"Your presence is a gift, Luna. I would be honored to have your guidance on my journey to rescue Princess Isabella.\"\n",
    "\n",
    "And so, Luna, with her silent but wise presence, accompanied Sir Cedric on his perilous quest. Together, they faced the challenges of the enchanted castle, drawing upon their unique abilities and unwavering courage.\n",
    "\n",
    "In the room with the water elemental, Luna hopped to the forefront, her words a soothing balm to calm the raging waters. With a gentle and knowing whisper, she convinced the elemental to recede, allowing Sir Cedric to pass unharmed.\n",
    "\n",
    "In the chamber with the thorny vines, Luna's gift with the forest came to the forefront. She called upon the spirits of the woods to still the thorns, granting safe passage to Sir Cedric.\n",
    "\n",
    "When they reached the room of enchanted mirrors, Luna, with her deep understanding of the forest's ways, guided Sir Cedric to the mirror that reflected his true self. With her wisdom, the path to the next challenge was revealed.\n",
    "\n",
    "Throughout their journey, Luna's quiet presence and sage advice served as a steady anchor for Sir Cedric. Together, they overcame each challenge, drawing strength from their unique abilities and unwavering determination.\n",
    "\n",
    "Finally, when they reached the grand chamber, it was Luna who spoke words of kindness and hope to the stone guards, quelling their fierce attacks. With her soothing presence, Luna created an aura of peace that resonated with the enchantment, causing it to wane and setting Princess Isabella free.\n",
    "\n",
    "As the beautiful fountain in the center of the chamber sparkled with newfound radiance, Luna hopped forward to offer her wisdom to the castle itself. With words of understanding and compassion, she called upon the ancient magic of the land to help in the transformation of the castle, so it celebrated its own liberation.\n",
    "\n",
    "With the enchantment finally lifted, Luna, Sir Cedric, and Princess Isabella made their way out of the castle and back into the kingdom. The land, once barren and desolate, now burst with life and color. Villagers gathered, cheering and clapping, as they welcomed their princess home.\n",
    "\n",
    "The king, overjoyed to have his daughter returned to him, was filled with gratitude for the bravery and wisdom of both Sir Cedric and Luna. He offered Luna a place of honor in the kingdom as a wise and revered guardian of the forest.\n",
    "\n",
    "And so, the kingdom flourished under the watchful eye of both Sir Cedric, the knight who had rescued the princess, and Luna, the wise guardian of the forest. The three friends, Sir Cedric, Princess Isabella, and Luna, spent their days exploring the beautiful kingdom, discovering its hidden wonders, and sharing stories of their adventures.\n",
    "\n",
    "In a kingdom filled with magic, mystery, and courage, the story of Sir Cedric, Princess Isabella, and Luna became a beloved and timeless tale, celebrated by all as a testament to the power of bravery, the magic of friendship, and the enduring belief that love and courage could break even the most potent enchantments.\n",
    "\n",
    "And so, in this enchanting land where the meadows stretched far and the castles stood tall, the tale of Sir Cedric, Princess Isabella, and Luna remained a cherished story, inspiring all to dream and believe in the magic that lies just beyond the horizon.\n",
    "\n",
    "The end.\"\"\"\n",
    "\n",
    "input_ids = prepare_input(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"Very long ago, as old people have told me, there lived a terrible monster, who came out of the North, and laid waste whole tracts of country, devouring both men and beasts; and this monster was so destructive that it was feared that unless help came no living creature would be left on the face of the earth.\n",
    "\n",
    "It had a body like an ox, and legs like a frog, two short fore-legs, and two long ones behind, and besides that it had a tail like a serpent, ten fathoms in length. When it moved it jumped like a frog, and with every spring it covered half a mile of ground.\n",
    "\n",
    "Fortunately its habit, was to remain for several years in the same place, and not to move on till the whole neighbourhood was eaten up. Nothing could hunt it, because its whole body was covered with scales, which were harder than stone or metal; its two great eyes shone by night, and even by day, like the brightest lamps, and anyone who had the ill luck to look into those eyes became as it were bewitched, and was obliged to rush of his own accord into the monster’s jaws.\n",
    "\n",
    "In this way the Dragon was able to feed upon both men and beasts without the least trouble to itself, as it needed not to move from the spot where it was lying. All the neighbouring kings had offered rich rewards to anyone who should be able to destroy the monster, either by force or enchantment, and many had tried their luck, but all had miserably failed.\n",
    "\n",
    "Once a great forest in which the Dragon lay had been set on fire; the forest was burnt down, but the fire did not do the monster the least harm. However, there was a tradition amongst the wise men of the country that the Dragon might be overcome by one who possessed King Solomon’s signet-ring, upon which a secret writing was engraved. This inscription would enable anyone who was wise enough to interpret it to find out how the Dragon could be destroyed. Only no one knew where the ring was hidden, nor was there any sorcerer or learned man to be found who would be able to explain the inscription.\n",
    "\n",
    "At last a young man, with a good heart and plenty of courage, set out to search for the ring. He took his way towards the sunrising, because he knew that all the wisdom of old time comes from the East.\n",
    "\n",
    "After some years he met with a famous Eastern magician, and asked for his advice in the matter. The magician answered:\n",
    "\n",
    "‘Mortal men have but little wisdom, and can give you no help, but the birds of the air would be better guides to you if you could learn their language. I can help you to understand it if you will stay with me a few days.’\n",
    "\n",
    "The youth thankfully accepted the magician’s offer, and said, ‘I cannot now offer you any reward for your kindness, but should my undertaking succeed your trouble shall be richly repaid.’\n",
    "\n",
    "Then the magician brewed a powerful potion out of nine sorts of herbs which he had gathered himself all alone by moonlight, and he gave the youth nine spoonfuls of it daily for three days, which made him able to understand the language of birds.\n",
    "\n",
    "At parting the magician said to him. ‘If you ever find Solomon’s ring and get possession of it, then come back to me, that I may explain the inscription on the ring to you, for there is no one else in the world who can do this.’\n",
    "\n",
    "From that time the youth never felt lonely as he walked along; he always had company, because he understood the language of birds; and in this way he learned many things which mere human knowledge could never have taught him. But time went on, and he heard nothing about the ring.\n",
    "\n",
    "It happened one evening, when he was hot and tired with walking, and had sat down under a tree in a forest to eat his supper, that he saw two gaily-plumaged birds, that were strange to him, sitting at the top of the tree talking to one another about him. The first bird said:\n",
    "\n",
    "‘I know that wandering fool under the tree there, who has come so far without finding what he seeks. He is trying to find King Solomon’s lost ring.’\n",
    "\n",
    "The other bird answered,\n",
    "\n",
    "‘He will have to seek help from the Witch-maiden, who will doubtless be able to put him on the right track. If she has not got the ring herself, she knows well enough who has it.’\n",
    "\n",
    "‘But where is he to find the Witch-maiden?’ said the first bird. ‘She has no settled dwelling, but is here to-day and gone to-morrow. He might as well try to catch the wind.’\n",
    "\n",
    "The other replied, ‘I do not know, certainly, where she is at present, but in three nights from now she will come to the spring to wash her face, as she does every month when the moon is full, in order that she may never grow old nor wrinkled, but may always keep the bloom of youth.’\n",
    "\n",
    "‘Well,’ said the first bird, ‘the spring is not far from here. Shall we go and see how it is she does it?’\n",
    "\n",
    "‘Willingly, if you like,’ said the other.\n",
    "\n",
    "The youth immediately resolved to follow the birds to the spring, only two things made him uneasy: first, lest he might be asleep when the birds went, and secondly, lest he might lose sight of them, since he had not wings to carry him along so swiftly. He was too tired to keep awake all night, yet his anxiety prevented him from sleeping soundly, and when with the earliest dawn he looked up to the tree-top, he was glad to see his feathered companions still asleep with their heads under their wings.\n",
    "\n",
    "He ate his breakfast, and waited until the birds should start, but they did not leave the place all day. They hopped about from one tree to another looking for food, all day long until the evening, when they went back to their old perch to sleep.\n",
    "\n",
    "The next day the same thing happened, but on the third morning one bird said to the other,\n",
    "\n",
    "‘To-day we must go to the spring to see the Witch-maiden wash her face.’ They remained on the tree till noon; then they flew away and went towards the south.\n",
    "\n",
    "The young man’s heart beat with anxiety lest he should lose sight of his guides, but he managed to keep the birds in view until they again perched upon a tree. The young man ran after them until he was quite exhausted and out of breath, and after three short rests the birds at length reached a small open space in the forest, on the edge of which they placed themselves on the top of a high tree. When the youth had overtaken them, he saw that there was a clear spring in the middle of the space. He sat down at the foot of the tree upon which the birds were perched, and listened attentively to what they were saying to each other.\n",
    "\n",
    "‘The sun is not down yet,’ said the first bird; ‘we must wait yet awhile till the moon rises and the maiden comes to the spring. Do you think she will see that young man sitting under the tree?’\n",
    "\n",
    "‘Nothing is likely to escape her eyes, certainly not a young man,’ said the other bird. ‘Will the youth have the sense not to let himself be caught in her toils?’\n",
    "\n",
    "‘We will wait,’ said the first bird, ‘and see how they get on together.’\n",
    "\n",
    "The evening light had quite faded, and the full moon was already shining down upon the forest, when the young man heard a slight rustling sound. After a few moments there came out of the forest a maiden, gliding over the grass so lightly that her feet seemed scarcely to touch the ground, and stood beside the spring. The youth could not turn away his eyes from the maiden, for he had never in his life seen a woman so beautiful. Without seeming to notice anything, she went to the spring, looked up to the full moon, then knelt down and bathed her face nine times, then looked up to the moon again and walked nine times round the well, and as she walked she sang this song:\n",
    "\n",
    "‘Full-faced moon with light unshaded,\n",
    "Let my beauty ne’er be faded.\n",
    "Never let my cheek grow pale!\n",
    "While the moon is waning nightly,\n",
    "May the maiden bloom more brightly,\n",
    "May her freshness never fail!’\n",
    "\n",
    "Then she dried her face with her long hair, and was about to go away, when her eye suddenly fell upon the spot where the young man was sitting, and she turned towards the tree.\n",
    "\n",
    "The youth rose and stood waiting.\n",
    "\n",
    "Then the maiden said, ‘You ought to have a heavy punishment because you have presumed to watch my secret doings in the moonlight. But I will forgive you this time, because you are a stranger and knew no better. But you must tell me truly who you are and how you came to this place, where no mortal has ever set foot before.’\n",
    "\n",
    "The youth answered humbly: ‘Forgive me, beautiful maiden, if I have unintentionally offended you. I chanced to come here after long wandering, and found a good place to sleep under this tree. At your coming I did not know what to do, but stayed where I was, because I thought my silent watching could not offend you.’\n",
    "\n",
    "The maiden answered kindly, ‘Come and spend this night with us. You will sleep better on a pillow than on damp moss.’\n",
    "\n",
    "The youth hesitated for a little, but presently he heard the birds saying from the top of the tree, ‘Go where she calls you, but take care to give no blood, or you will sell your soul.’\n",
    "\n",
    "So the youth went with her, and soon they reached a beautiful garden, where stood a splendid house, which glittered in the moonlight as if it was all built out of gold and silver. When the youth entered he found many splendid chambers, each one finer than the last. Hundreds of tapers burnt upon golden candlesticks, and shed a light like the brightest day.\n",
    "\n",
    "At length they reached a chamber where a table was spread with the most costly dishes. At the table were placed two chairs, one of silver, the other of gold. The maiden seated herself upon the golden chair, and offered the silver one to her companion. They were served by maidens dressed in white, whose feet made no sound as they moved about, and not a word was spoken during the meal.\n",
    "\n",
    "Afterwards the youth and the Witch-maiden conversed pleasantly together, until a woman, dressed in red, came in to remind them that it was bedtime. The youth was now shown into another room, containing a silken bed with down cushions, where he slept delightfully, yet he seemed to hear a voice near his bed which repeated to him, ‘Remember to give no blood!’\n",
    "\n",
    "The next morning the maiden asked him whether he would not like to stay with her always in this beautiful place, and as he did not answer immediately, she continued: ‘You see how I always remain young and beautiful, and I am under no one’s orders, but can do just what I like, so that I have never thought of marrying before. But from the moment I saw you I took a fancy to you, so if you agree, we might be married and might live together like princes, because I have great riches.’\n",
    "\n",
    "The youth could not but be tempted with the beautiful maiden’s offer, but he remembered how the birds had called her the witch, and their warning always sounded in his ears. Therefore he answered cautiously, ‘Do not be angry, dear maiden, if I do not decide immediately on this important matter. Give me a few days to consider before we come to an understanding.’\n",
    "\n",
    "‘Why not?’ answered the maiden. ‘Take some weeks to consider if you like, and take counsel with your own heart.’\n",
    "\n",
    "And to make the time pass pleasantly, she took the youth over every part of her beautiful dwelling, and showed him all her splendid treasures. But these treasures were all produced by enchantment, for the maiden could make anything she wished appear by the help of King Solomon’s signet ring; only none of these things remained fixed; they passed away like the wind without leaving a trace behind. But the youth did not know this; he thought they were all real.\n",
    "\n",
    "One day the maiden took him into a secret chamber, where a little gold box was standing on a silver table. Pointing to the box, she said, ‘Here is my greatest treasure, whose like is not to be found in the whole world. It is a precious gold ring. When you marry me, I will give you this ring as a marriage gift, and it will make you the happiest of mortal men. But in order that our love may last for ever, you must give me for the ring three drops of blood from the little finger of your left hand.’\n",
    "\n",
    "When the youth heard these words a cold shudder ran over him, for he remembered that his soul was at stake. He was cunning enough, however, to conceal his feelings and to make no direct answer, but he only asked the maiden, as if carelessly, what was remarkable about the ring?\n",
    "\n",
    "She answered, ‘No mortal is able entirely to understand the power of this ring, because no one thoroughly understands the secret signs engraved upon it. But even with my half-knowledge I can work great wonders. If I put the ring upon the little finger of my left hand, then I can fly like a bird through the air wherever I wish to go. If I put it on the third finger of my left hand I am invisible, and I can see everything that passes around me, though no one can see me. If I put the ring upon the middle finger of my left hand, then neither fire nor water nor any sharp weapon can hurt me. If I put it on the forefinger of my left hand, then I can with its help produce whatever I wish. I can in a single moment build houses or anything I desire. Finally, as long as I wear the ring on the thumb of my left hand, that hand is so strong that it can break down rocks and walls. Besides these, the ring has other secret signs which, as I said, no one can understand. No doubt it contains secrets of great importance. The ring formerly belonged to King Solomon, the wisest of kings, during whose reign the wisest men lived. But it is not known whether this ring was ever made by mortal hands: it is supposed that an angel gave it to the wise King.’\n",
    "\n",
    "When the youth heard all this he determined to try and get possession of the ring, though he did not quite believe in all its wonderful gifts. He wished the maiden would let him have it in his hand, but he did not quite like to ask her to do so, and after a while she put it back into the box.\n",
    "\n",
    "A few days after they were again speaking of the magic ring, and the youth said,\n",
    "\n",
    "‘I do not think it possible that the ring can have all the power you say it has.’\n",
    "\n",
    "Then the maiden opened the box and took the ring out, and it glittered as she held it like the clearest sunbeam. She put it on the middle finger of her left hand, and told the youth to take a knife and try as hard as he could to cut her with it, for he would not be able to hurt her. He was unwilling at first, but the maiden insisted. Then he tried, at first only in play, and then seriously, to strike her with the knife, but an invisible wall of iron seemed to be between them, and the maiden stood before him laughing and unhurt. Then she put the ring on her third finger, and in an instant she had vanished from his eyes. Presently she was beside him again laughing, and holding the ring between her fingers.\n",
    "\n",
    "‘Do let me try,’ said the youth, ‘whether I can do these wonderful things.’\n",
    "\n",
    "The maiden, suspecting no treachery, gave him the magic ring.\n",
    "\n",
    "The youth pretended to have forgotten what to do, and asked what finger he must put the ring on so that no sharp weapon could hurt him?’\n",
    "\n",
    "‘Oh, the middle finger of your left hand,’ the maiden answered, laughing.\n",
    "\n",
    "She took the knife and tried to strike the youth, and he even tried to cut himself with it, but found it impossible.\n",
    "\n",
    "Then he asked the maiden to show him how to split stones and rocks with the help of the ring. So she led him into a courtyard where stood a great boulder-stone.\n",
    "\n",
    "‘Now,’ she said, ‘put the ring upon the thumb of your left hand, and you will see how strong that hand has become.’\n",
    "\n",
    "The youth did so, and found to his astonishment that with a single blow of his fist the stone flew into a thousand pieces. Then the youth bethought him that he who does not use his luck when he has it is a fool, and that this was a chance which once lost might never return. So while they stood laughing at the shattered stone he placed the ring, as if in play, upon the third finger of his left hand.\n",
    "\n",
    "‘Now,’ said the maiden, ‘you are invisible to me until you take the ring off again.’\n",
    "\n",
    "But the youth had no mind to do that; on the contrary, he went farther off, then put the ring on the little finger of his left hand, and soared into the air like a bird.\n",
    "\n",
    "When the maiden saw him flying away she thought at first that he was still in play, and cried, ‘Come back, friend, for now you see I have told you the truth.’ But the young man never came back.\n",
    "\n",
    "Then the maiden saw she was deceived, and bitterly repented that she had ever trusted him with the ring.\n",
    "\n",
    "The young man never halted in his flight until he reached the dwelling of the wise magician who had taught him the speech of birds. The magician was delighted to find that his search had been successful, and at once set to work to interpret the secret signs engraved upon the ring, but it took him seven weeks to make them out clearly. Then he gave the youth the following instructions how to overcome the Dragon of the North:\n",
    "\n",
    "‘You must have an iron horse cast, which must have little wheels under each foot. You must also be armed with a spear two fathoms long, which you will be able to wield by means of the magic ring upon your left thumb. The spear must be as thick in the middle as a large tree, and both its ends must be sharp. In the middle of the spear you must have two strong chains ten fathoms in length. As soon as the Dragon has made himself fast to the spear, which you must thrust through his jaws, you must spring quickly from the iron horse and fasten the ends of the chains firmly to the ground with iron stakes, so that he cannot get away from them. After two or three days the monster’s strength will be so far exhausted that you will be able to come near him. Then you can put Solomon’s ring upon your left thumb and give him the finishing stroke, but keep the ring on your third finger until you have come close to him, so that the monster cannot see you, else he might strike you dead with his long tail. But when all is done, take care you do not lose the ring, and that no one takes it from you by cunning.’\n",
    "\n",
    "The young man thanked the magician for his directions, and promised, should they succeed, to reward him. But the magician answered, ‘I have profited so much by the wisdom the ring has taught me that I desire no other reward.’ Then they parted, and the youth quickly flew home through the air.\n",
    "\n",
    "After remaining in his own home for some weeks, he heard people say that the terrible Dragon of the North was not far off, and might shortly be expected in the country.\n",
    "\n",
    "The King announced publicly that he would give his daughter in marriage, as well as a large part of his kingdom, to whosoever should free the country from the monster. The youth then went to the King and told him that he had good hopes of subduing the Dragon, if the King would grant him all he desired for the purpose. The King willingly agreed, and the iron horse, the great spear, and the chains were all prepared as the youth requested.\n",
    "\n",
    "When all was ready, it was found that the iron horse was so heavy that a hundred men could not move it from the spot, so the youth found there was nothing for it but to move it with his own strength by means of the magic ring.\n",
    "\n",
    "The Dragon was now so near that in a couple of springs he would be over the frontier. The youth now began to consider how he should act, for if he had to push the iron horse from behind he could not ride upon it as the sorcerer had said he must. But a raven unexpectedly gave him this advice:\n",
    "\n",
    "‘Ride upon the horse, and push the spear against the ground, as if you were pushing off a boat from the land.’\n",
    "\n",
    "The youth did so, and found that in this way he could easily move forwards. The Dragon had his monstrous jaws wide open, all ready for his expected prey. A few paces nearer, and man and horse would have been swallowed up by them! The youth trembled with horror, and his blood ran cold, yet he did not lose his courage; but, holding the iron spear upright in his hand, he brought it down with all his might right through the monster’s lower jaw. Then quick as lightning he sprang from his horse before the Dragon had time to shut his mouth. A fearful clap like thunder, which could be heard for miles around, now warned him that the Dragon’s jaws had closed upon the spear.\n",
    "\n",
    "When the youth turned round he saw the point of the spear sticking up high above the Dragon’s upper jaw, and knew that the other end must be fastened firmly to the ground; but the Dragon had got his teeth fixed in the iron horse, which was now useless. The youth now hastened to fasten down the chains to the ground by means of the enormous iron pegs which he had provided. The death struggle of the monster lasted three days and three nights; in his writhing he beat his tail so violently against the ground, that at ten miles’ distance the earth trembled as if with an earthquake. When he at length lost power to move his tail, the youth with the help of the ring took up a stone which twenty ordinary men could not have moved, and beat the Dragon so hard about the head with it that very soon the monster lay lifeless before him.\n",
    "\n",
    "You can fancy how great was the rejoicing when the news was spread abroad that the terrible monster was dead. His conqueror was received into the city with as much pomp as if he had been the mightiest of kings. The old King did not need to urge his daughter to marry the slayer of the Dragon; he found her already willing to bestow her hand upon this hero, who had done all alone what whole armies had tried in vain to do. In a few days a magnificent wedding was celebrated, at which the rejoicings lasted four whole weeks, for all the neighbouring kings had met together to thank the man who had freed the world from their common enemy.\n",
    "\n",
    "But everyone forgot amid the general joy that they ought to have buried the Dragon’s monstrous body, for it began now to have such a bad smell that no one could live in the neighbourhood, and before long the whole air was poisoned, and a pestilence broke out which destroyed many hundreds of people. In this distress, the King’s son-in-law resolved to seek help once more from the Eastern magician, to whom he at once travelled through the air like a bird by the help of the ring.\n",
    "\n",
    "But there is a proverb which says that ill-gotten gains never prosper, and the Prince found that the stolen ring brought him ill-luck after all. The Witch-maiden had never rested night nor day until she had found out where the ring was. As soon as she had discovered by means of magical arts that the Prince in the form of a bird was on his way to the Eastern magician, she changed herself into an eagle and watched in the air until the bird she was waiting for came in sight, for she knew him at once by the ring which was hung round his neck by a ribbon. Then the eagle pounced upon the bird, and the moment she seized him in her talons she tore the ring from his neck before the man in bird’s shape had time to prevent her. Then the eagle flew down to the earth with her prey, and the two stood face to face once more in human form.\n",
    "\n",
    "‘Now, villain, you are in my power!’ cried the Witch-maiden. ‘I favoured you with my love, and you repaid me with treachery and theft. You stole my most precious jewel from me, and do you expect to live happily as the King’s son-in-law? Now the tables are turned; you are in my power, and I will be revenged on you for your crimes.’\n",
    "\n",
    "‘Forgive me! forgive me!’ cried the Prince; ‘I know too well how deeply I have wronged you, and most heartily do I repent it.’\n",
    "\n",
    "The maiden answered, ‘Your prayers and your repentance come too late, and if I were to spare you everyone would think me a fool. You have doubly wronged me; first you scorned my love, and then you stole my ring, and you must bear the punishment.’\n",
    "\n",
    "With these words she put the ring upon her left thumb, lifted the young man with one hand, and walked away with him under her arm. This time she did not take him to a splendid palace, but to a deep cave in a rock, where there were chains hanging from the wall. The maiden now chained the young man’s hands and feet so that he could not escape; then she said in an angry voice, ‘Here you shall remain chained up until you die. I will bring you every day enough food to prevent you dying of hunger, but you need never hope for freedom any more.’\n",
    "\n",
    "With these words she left him.\n",
    "\n",
    "The old King and his daughter waited anxiously for many weeks for the Prince’s return, but no news of him arrived. The King’s daughter often dreamed that her husband was going through some great suffering: she therefore begged her father to summon all the enchanters and magicians, that they might try to find out where the Prince was and how he could be set free. But the magicians, with all their arts, could find out nothing, except that he was still living and undergoing great suffering; but none could tell where he was to be found.\n",
    "\n",
    "At last a celebrated magician from Finland was brought before the King, who had found out that the King’s son-in-law was imprisoned in the East, not by men, but by some more powerful being. The King now sent messengers to the East to look for his son-in-law, and they by good luck met with the old magician who had interpreted the signs on King Solomon’s ring, and thus was possessed of more wisdom than anyone else in the world. The magician soon found out what he wished to know, and pointed out the place where the Prince was imprisoned, but said:\n",
    "\n",
    "‘He is kept there by enchantment, and cannot be set free without my help. I will therefore go with you myself.’\n",
    "\n",
    "So they all set out, guided by birds, and after some days came to the cave where the unfortunate Prince had been chained up for nearly seven years. He recognised the magician immediately, but the old man did not know him, he had grown so thin. However, he undid the chains by the help of magic, and took care of the Prince until he recovered and became strong enough to travel. When he reached home he found that the old King had died that morning, so that he was now raised to the throne. And now after his long suffering came prosperity, which lasted to the end of his life; but he never got back the magic ring, nor has it ever again been seen by mortal eyes.\"\"\"\n",
    "input_ids = prepare_input(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = \"\"\"Harry Potter and the Sorcerer's Stone\n",
    "\n",
    "\n",
    "CHAPTER ONE\n",
    "\n",
    "THE BOY WHO LIVED\n",
    "\n",
    "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
    "that they were perfectly normal, thank you very much. They were the last\n",
    "people you'd expect to be involved in anything strange or mysterious,\n",
    "because they just didn't hold with such nonsense.\n",
    "\n",
    "Mr. Dursley was the director of a firm called Grunnings, which made\n",
    "drills. He was a big, beefy man with hardly any neck, although he did\n",
    "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
    "nearly twice the usual amount of neck, which came in very useful as she\n",
    "spent so much of her time craning over garden fences, spying on the\n",
    "neighbors. The Dursleys had a small son called Dudley and in their\n",
    "opinion there was no finer boy anywhere.\n",
    "\n",
    "The Dursleys had everything they wanted, but they also had a secret, and\n",
    "their greatest fear was that somebody would discover it. They didn't\n",
    "think they could bear it if anyone found out about the Potters. Mrs.\n",
    "Potter was Mrs. Dursley's sister, but they hadn't met for several years;\n",
    "in fact, Mrs. Dursley pretended she didn't have a sister, because her\n",
    "sister and her good-for-nothing husband were as unDursleyish as it was\n",
    "possible to be. The Dursleys shuddered to think what the neighbors would\n",
    "say if the Potters arrived in the street. The Dursleys knew that the\n",
    "Potters had a small son, too, but they had never even seen him. This boy\n",
    "was another good reason for keeping the Potters away; they didn't want\n",
    "Dudley mixing with a child like that.\n",
    "\n",
    "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\n",
    "starts, there was nothing about the cloudy sky outside to suggest that\n",
    "strange and mysterious things would soon be happening all over the\n",
    "country. Mr. Dursley hummed as he picked out his most boring tie for\n",
    "work, and Mrs. Dursley gossiped away happily as she wrestled a screaming\n",
    "Dudley into his high chair.\n",
    "\n",
    "None of them noticed a large, tawny owl flutter past the window.\n",
    "\n",
    "At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.\n",
    "Dursley on the cheek, and tried to kiss Dudley good-bye but missed,\n",
    "because Dudley was now having a tantrum and throwing his cereal at the\n",
    "walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got\n",
    "into his car and backed out of number four's drive.\n",
    "\n",
    "It was on the corner of the street that he noticed the first sign of\n",
    "something peculiar -- a cat reading a map. For a second, Mr. Dursley\n",
    "didn't realize what he had seen -- then he jerked his head around to\n",
    "look again. There was a tabby cat standing on the corner of Privet\n",
    "Drive, but there wasn't a map in sight. What could he have been thinking\n",
    "of? It must have been a trick of the light. Mr. Dursley blinked and\n",
    "stared at the cat. It stared back. As Mr. Dursley drove around the\n",
    "corner and up the road, he watched the cat in his mirror. It was now\n",
    "reading the sign that said Privet Drive -- no, looking at the sign; cats\n",
    "couldn't read maps or signs. Mr. Dursley gave himself a little shake and\n",
    "put the cat out of his mind. As he drove toward town he thought of\n",
    "nothing except a large order of drills he was hoping to get that day.\n",
    "\n",
    "But on the edge of town, drills were driven out of his mind by something\n",
    "else. As he sat in the usual morning traffic jam, he couldn't help\n",
    "noticing that there seemed to be a lot of strangely dressed people\n",
    "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in\n",
    "funny clothes -- the getups you saw on young people! He supposed this\n",
    "was some stupid new fashion. He drummed his fingers on the steering\n",
    "wheel and his eyes fell on a huddle of these weirdos standing quite\n",
    "close by. They were whispering excitedly together. Mr. Dursley was\n",
    "enraged to see that a couple of them weren't young at all; why, that man\n",
    "had to be older than he was, and wearing an emerald-green cloak! The\n",
    "nerve of him! But then it struck Mr. Dursley that this was probably some\n",
    "silly stunt -- these people were obviously collecting for something...\n",
    "yes, that would be it. The traffic moved on and a few minutes later, Mr.\n",
    "Dursley arrived in the Grunnings parking lot, his mind back on drills.\n",
    "\n",
    "Mr. Dursley always sat with his back to the window in his office on the\n",
    "ninth floor. If he hadn't, he might have found it harder to concentrate\n",
    "on drills that morning. He didn't see the owls swoop ing past in broad\n",
    "daylight, though people down in the street did; they pointed and gazed\n",
    "open- mouthed as owl after owl sped overhead. Most of them had never\n",
    "seen an owl even at nighttime. Mr. Dursley, however, had a perfectly\n",
    "normal, owl-free morning. He yelled at five different people. He made\n",
    "several important telephone calls and shouted a bit more. He was in a\n",
    "very good mood until lunchtime, when he thought he'd stretch his legs\n",
    "and walk across the road to buy himself a bun from the bakery.\n",
    "\n",
    "He'd forgotten all about the people in cloaks until he passed a group of\n",
    "them next to the baker's. He eyed them angrily as he passed. He didn't\n",
    "know why, but they made him uneasy. This bunch were whispering\n",
    "excitedly, too, and he couldn't see a single collecting tin. It was on\n",
    "his way back past them, clutching a large doughnut in a bag, that he\n",
    "caught a few words of what they were saying.\n",
    "\n",
    "\"The Potters, that's right, that's what I heard yes, their son, Harry\"\n",
    "\n",
    "Mr. Dursley stopped dead. Fear flooded him. He looked back at the\n",
    "whisperers as if he wanted to say something to them, but thought better\n",
    "of it.\n",
    "\n",
    "He dashed back across the road, hurried up to his office, snapped at his\n",
    "secretary not to disturb him, seized his telephone, and had almost\n",
    "finished dialing his home number when he changed his mind. He put the\n",
    "receiver back down and stroked his mustache, thinking... no, he was\n",
    "being stupid. Potter wasn't such an unusual name. He was sure there were\n",
    "lots of people called Potter who had a son called Harry. Come to think\n",
    "of it, he wasn't even sure his nephew was called Harry. He'd never even\n",
    "seen the boy. It might have been Harvey. Or Harold. There was no point\n",
    "in worrying Mrs. Dursley; she always got so upset at any mention of her\n",
    "sister. He didn't blame her -- if he'd had a sister like that... but all\n",
    "the same, those people in cloaks...\n",
    "\n",
    "He found it a lot harder to concentrate on drills that afternoon and\n",
    "when he left the building at five o'clock, he was still so worried that\n",
    "he walked straight into someone just outside the door.\n",
    "\n",
    "\"Sorry,\" he grunted, as the tiny old man stumbled and almost fell. It\n",
    "was a few seconds before Mr. Dursley realized that the man was wearing a\n",
    "violet cloak. He didn't seem at all upset at being almost knocked to the\n",
    "ground. On the contrary, his face split into a wide smile and he said in\n",
    "a squeaky voice that made passersby stare, \"Don't be sorry, my dear sir,\n",
    "for nothing could upset me today! Rejoice, for You-Know-Who has gone at\n",
    "last! Even Muggles like yourself should be celebrating, this happy,\n",
    "happy day!\"\n",
    "\n",
    "And the old man hugged Mr. Dursley around the middle and walked off.\n",
    "\n",
    "Mr. Dursley stood rooted to the spot. He had been hugged by a complete\n",
    "stranger. He also thought he had been called a Muggle, whatever that\n",
    "was. He was rattled. He hurried to his car and set off for home, hoping\n",
    "he was imagining things, which he had never hoped before, because he\n",
    "didn't approve of imagination.\n",
    "\n",
    "As he pulled into the driveway of number four, the first thing he saw --\n",
    "and it didn't improve his mood -- was the tabby cat he'd spotted that\n",
    "morning. It was now sitting on his garden wall. He was sure it was the\n",
    "same one; it had the same markings around its eyes.\n",
    "\n",
    "\"Shoo!\" said Mr. Dursley loudly. The cat didn't move. It just gave him a\n",
    "stern look. Was this normal cat behavior? Mr. Dursley wondered. Trying\n",
    "to pull himself together, he let himself into the house. He was still\n",
    "determined not to mention anything to his wife.\n",
    "\n",
    "Mrs. Dursley had had a nice, normal day. She told him over dinner all\n",
    "about Mrs. Next Door's problems with her daughter and how Dudley had\n",
    "learned a new word (\"Won't!\"). Mr. Dursley tried to act normally. When\n",
    "Dudley had been put to bed, he went into the living room in time to\n",
    "catch the last report on the evening news:\n",
    "\n",
    "\"And finally, bird-watchers everywhere have reported that the nation's\n",
    "owls have been behaving very unusually today. Although owls normally\n",
    "hunt at night and are hardly ever seen in daylight, there have been\n",
    "hundreds of sightings of these birds flying in every direction since\n",
    "sunrise. Experts are unable to explain why the owls have suddenly\n",
    "changed their sleeping pattern.\" The newscaster allowed himself a grin.\n",
    "\"Most mysterious. And now, over to Jim McGuffin with the weather. Going\n",
    "to be any more showers of owls tonight, Jim?\"\n",
    "\n",
    "\"Well, Ted,\" said the weatherman, \"I don't know about that, but it's not\n",
    "only the owls that have been acting oddly today. Viewers as far apart as\n",
    "Kent, Yorkshire, and Dundee have been phoning in to tell me that instead\n",
    "of the rain I promised yesterday, they've had a downpour of shooting\n",
    "stars! Perhaps people have been celebrating Bonfire Night early -- it's\n",
    "not until next week, folks! But I can promise a wet night tonight.\"\n",
    "\n",
    "Mr. Dursley sat frozen in his armchair. Shooting stars all over Britain?\n",
    "Owls flying by daylight? Mysterious people in cloaks all over the place?\n",
    "And a whisper, a whisper about the Potters...\n",
    "\n",
    "Mrs. Dursley came into the living room carrying two cups of tea. It was\n",
    "no good. He'd have to say something to her. He cleared his throat\n",
    "nervously. \"Er -- Petunia, dear -- you haven't heard from your sister\n",
    "lately, have you?\"\n",
    "\n",
    "As he had expected, Mrs. Dursley looked shocked and angry. After all,\n",
    "they normally pretended she didn't have a sister.\n",
    "\n",
    "\"No,\" she said sharply. \"Why?\"\n",
    "\n",
    "\"Funny stuff on the news,\" Mr. Dursley mumbled. \"Owls... shooting\n",
    "stars... and there were a lot of funny-looking people in town today...\"\n",
    "\n",
    "\"So?\" snapped Mrs. Dursley.\n",
    "\n",
    "\"Well, I just thought... maybe... it was something to do with... you\n",
    "know... her crowd.\"\n",
    "\n",
    "Mrs. Dursley sipped her tea through pursed lips. Mr. Dursley wondered\n",
    "whether he dared tell her he'd heard the name \"Potter.\" He decided he\n",
    "didn't dare. Instead he said, as casually as he could, \"Their son --\n",
    "he'd be about Dudley's age now, wouldn't he?\"\n",
    "\n",
    "\"I suppose so,\" said Mrs. Dursley stiffly.\n",
    "\n",
    "\"What's his name again? Howard, isn't it?\"\n",
    "\n",
    "\"Harry. Nasty, common name, if you ask me.\"\n",
    "\n",
    "\"Oh, yes,\" said Mr. Dursley, his heart sinking horribly. \"Yes, I quite\n",
    "agree.\"\n",
    "\n",
    "He didn't say another word on the subject as they went upstairs to bed.\n",
    "While Mrs. Dursley was in the bathroom, Mr. Dursley crept to the bedroom\n",
    "window and peered down into the front garden. The cat was still there.\n",
    "It was staring down Privet Drive as though it were waiting for\n",
    "something.\n",
    "\n",
    "Was he imagining things? Could all this have anything to do with the\n",
    "Potters? If it did... if it got out that they were related to a pair of\n",
    "-- well, he didn't think he could bear it.\n",
    "\n",
    "The Dursleys got into bed. Mrs. Dursley fell asleep quickly but Mr.\n",
    "Dursley lay awake, turning it all over in his mind. His last, comforting\n",
    "thought before he fell asleep was that even if the Potters were\n",
    "involved, there was no reason for them to come near him and Mrs.\n",
    "Dursley. The Potters knew very well what he and Petunia thought about\n",
    "them and their kind.... He couldn't see how he and Petunia could get\n",
    "mixed up in anything that might be going on -- he yawned and turned over\n",
    "-- it couldn't affect them....\n",
    "\n",
    "How very wrong he was.\n",
    "\n",
    "Mr. Dursley might have been drifting into an uneasy sleep, but the cat\n",
    "on the wall outside was showing no sign of sleepiness. It was sitting as\n",
    "still as a statue, its eyes fixed unblinkingly on the far corner of\n",
    "Privet Drive. It didn't so much as quiver when a car door slammed on the\n",
    "next street, nor when two owls swooped overhead. In fact, it was nearly\n",
    "midnight before the cat moved at all.\n",
    "\n",
    "A man appeared on the corner the cat had been watching, appeared so\n",
    "suddenly and silently you'd have thought he'd just popped out of the\n",
    "ground. The cat's tail twitched and its eyes narrowed.\n",
    "\n",
    "Nothing like this man had ever been seen on Privet Drive. He was tall,\n",
    "thin, and very old, judging by the silver of his hair and beard, which\n",
    "were both long enough to tuck into his belt. He was wearing long robes,\n",
    "a purple cloak that swept the ground, and high-heeled, buckled boots.\n",
    "His blue eyes were light, bright, and sparkling behind half-moon\n",
    "spectacles and his nose was very long and crooked, as though it had been\n",
    "broken at least twice. This man's name was Albus Dumbledore.\n",
    "\n",
    "Albus Dumbledore didn't seem to realize that he had just arrived in a\n",
    "street where everything from his name to his boots was unwelcome. He was\n",
    "busy rummaging in his cloak, looking for something. But he did seem to\n",
    "realize he was being watched, because he looked up suddenly at the cat,\n",
    "which was still staring at him from the other end of the street. For\n",
    "some reason, the sight of the cat seemed to amuse him. He chuckled and\n",
    "muttered, \"I should have known.\"\n",
    "\n",
    "He found what he was looking for in his inside pocket. It seemed to be a\n",
    "silver cigarette lighter. He flicked it open, held it up in the air, and\n",
    "clicked it. The nearest street lamp went out with a little pop. He\n",
    "clicked it again -- the next lamp flickered into darkness. Twelve times\n",
    "he clicked the Put-Outer, until the only lights left on the whole street\n",
    "were two tiny pinpricks in the distance, which were the eyes of the cat\n",
    "watching him. If anyone looked out of their window now, even beady-eyed\n",
    "Mrs. Dursley, they wouldn't be able to see anything that was happening\n",
    "down on the pavement. Dumbledore slipped the Put-Outer back inside his\n",
    "cloak and set off down the street toward number four, where he sat down\n",
    "on the wall next to the cat. He didn't look at it, but after a moment he\n",
    "spoke to it.\n",
    "\n",
    "\"Fancy seeing you here, Professor McGonagall.\"\n",
    "\n",
    "He turned to smile at the tabby, but it had gone. Instead he was smiling\n",
    "at a rather severe-looking woman who was wearing square glasses exactly\n",
    "the shape of the markings the cat had had around its eyes. She, too, was\n",
    "wearing a cloak, an emerald one. Her black hair was drawn into a tight\n",
    "bun. She looked distinctly ruffled.\n",
    "\n",
    "\"How did you know it was me?\" she asked.\n",
    "\n",
    "\"My dear Professor, I 've never seen a cat sit so stiffly.\"\n",
    "\n",
    "\"You'd be stiff if you'd been sitting on a brick wall all day,\" said\n",
    "Professor McGonagall.\n",
    "\n",
    "\"All day? When you could have been celebrating? I must have passed a\n",
    "dozen feasts and parties on my way here.\"\n",
    "\n",
    "Professor McGonagall sniffed angrily.\n",
    "\n",
    "\"Oh yes, everyone's celebrating, all right,\" she said impatiently.\n",
    "\"You'd think they'd be a bit more careful, but no -- even the Muggles\n",
    "have noticed something's going on. It was on their news.\" She jerked her\n",
    "head back at the Dursleys' dark living-room window. \"I heard it. Flocks\n",
    "of owls... shooting stars.... Well, they're not completely stupid. They\n",
    "were bound to notice something. Shooting stars down in Kent -- I'll bet\n",
    "that was Dedalus Diggle. He never had much sense.\"\n",
    "\n",
    "\"You can't blame them,\" said Dumbledore gently. \"We've had precious\n",
    "little to celebrate for eleven years.\"\n",
    "\n",
    "\"I know that,\" said Professor McGonagall irritably. \"But that's no\n",
    "reason to lose our heads. People are being downright careless, out on\n",
    "the streets in broad daylight, not even dressed in Muggle clothes,\n",
    "swapping rumors.\"\n",
    "\n",
    "She threw a sharp, sideways glance at Dumbledore here, as though hoping\n",
    "he was going to tell her something, but he didn't, so she went on. \"A\n",
    "fine thing it would be if, on the very day YouKnow-Who seems to have\n",
    "disappeared at last, the Muggles found out about us all. I suppose he\n",
    "really has gone, Dumbledore?\"\n",
    "\n",
    "\"It certainly seems so,\" said Dumbledore. \"We have much to be thankful\n",
    "for. Would you care for a lemon drop?\"\n",
    "\n",
    "\"A what?\"\n",
    "\n",
    "\"A lemon drop. They're a kind of Muggle sweet I'm rather fond of\"\n",
    "\n",
    "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't\n",
    "think this was the moment for lemon drops. \"As I say, even if\n",
    "You-Know-Who has gone -\"\n",
    "\n",
    "\"My dear Professor, surely a sensible person like yourself can call him\n",
    "by his name? All this 'You- Know-Who' nonsense -- for eleven years I\n",
    "have been trying to persuade people to call him by his proper name:\n",
    "Voldemort.\" Professor McGonagall flinched, but Dumbledore, who was\n",
    "unsticking two lemon drops, seemed not to notice. \"It all gets so\n",
    "confusing if we keep saying 'You-Know-Who.' I have never seen any reason\n",
    "to be frightened of saying Voldemort's name.\n",
    "\n",
    "\"I know you haven 't, said Professor McGonagall, sounding half\n",
    "exasperated, half admiring. \"But you're different. Everyone knows you're\n",
    "the only one You-Know- oh, all right, Voldemort, was frightened of.\"\n",
    "\n",
    "\"You flatter me,\" said Dumbledore calmly. \"Voldemort had powers I will\n",
    "never have.\"\n",
    "\n",
    "\"Only because you're too -- well -- noble to use them.\"\n",
    "\n",
    "\"It's lucky it's dark. I haven't blushed so much since Madam Pomfrey\n",
    "told me she liked my new earmuffs.\"\n",
    "\n",
    "Professor McGonagall shot a sharp look at Dumbledore and said, \"The owls\n",
    "are nothing next to the rumors that are flying around. You know what\n",
    "everyone's saying? About why he's disappeared? About what finally\n",
    "stopped him?\"\n",
    "\n",
    "It seemed that Professor McGonagall had reached the point she was most\n",
    "anxious to discuss, the real reason she had been waiting on a cold, hard\n",
    "wall all day, for neither as a cat nor as a woman had she fixed\n",
    "Dumbledore with such a piercing stare as she did now. It was plain that\n",
    "whatever \"everyone\" was saying, she was not going to believe it until\n",
    "Dumbledore told her it was true. Dumbledore, however, was choosing\n",
    "another lemon drop and did not answer.\n",
    "\n",
    "\"What they're saying,\" she pressed on, \"is that last night Voldemort\n",
    "turned up in Godric's Hollow. He went to find the Potters. The rumor is\n",
    "that Lily and James Potter are -- are -- that they're -- dead. \"\n",
    "\n",
    "Dumbledore bowed his head. Professor McGonagall gasped.\n",
    "\n",
    "\"Lily and James... I can't believe it... I didn't want to believe it...\n",
    "Oh, Albus...\"\n",
    "\n",
    "Dumbledore reached out and patted her on the shoulder. \"I know... I\n",
    "know...\" he said heavily.\n",
    "\n",
    "Professor McGonagall's voice trembled as she went on. \"That's not all.\n",
    "They're saying he tried to kill the Potter's son, Harry. But -- he\n",
    "couldn't. He couldn't kill that little boy. No one knows why, or how,\n",
    "but they're saying that when he couldn't kill Harry Potter, Voldemort's\n",
    "power somehow broke -- and that's why he's gone.\n",
    "\n",
    "Dumbledore nodded glumly.\n",
    "\n",
    "\"It's -- it's true?\" faltered Professor McGonagall. \"After all he's\n",
    "done... all the people he's killed... he couldn't kill a little boy?\n",
    "It's just astounding... of all the things to stop him... but how in the\n",
    "name of heaven did Harry survive?\"\n",
    "\n",
    "\"We can only guess,\" said Dumbledore. \"We may never know.\"\n",
    "\n",
    "Professor McGonagall pulled out a lace handkerchief and dabbed at her\n",
    "eyes beneath her spectacles. Dumbledore gave a great sniff as he took a\n",
    "golden watch from his pocket and examined it. It was a very odd watch.\n",
    "It had twelve hands but no numbers; instead, little planets were moving\n",
    "around the edge. It must have made sense to Dumbledore, though, because\n",
    "he put it back in his pocket and said, \"Hagrid's late. I suppose it was\n",
    "he who told you I'd be here, by the way?\"\n",
    "\n",
    "\"Yes,\" said Professor McGonagall. \"And I don't suppose you're going to\n",
    "tell me why you're here, of all places?\"\n",
    "\n",
    "\"I've come to bring Harry to his aunt and uncle. They're the only family\n",
    "he has left now.\"\n",
    "\n",
    "\"You don't mean -- you can't mean the people who live here?\" cried\n",
    "Professor McGonagall, jumping to her feet and pointing at number four.\n",
    "\"Dumbledore -- you can't. I've been watching them all day. You couldn't\n",
    "find two people who are less like us. And they've got this son -- I saw\n",
    "him kicking his mother all the way up the street, screaming for sweets.\n",
    "Harry Potter come and live here!\"\n",
    "\n",
    "\"It's the best place for him,\" said Dumbledore firmly. \"His aunt and\n",
    "uncle will be able to explain everything to him when he's older. I've\n",
    "written them a letter.\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "input_ids = prepare_input(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luna, a curious bunny, sets out to climb the Great Tree in the Enchanted Forest to make a wish. She meets new friends and faces challenges on her journey, but her bravery and determination lead her to the top, where she grants her wish. Luna returns home with newfound courage and a heart full of wonder, sharing her adventures with others. The end.\n",
      "\n",
      "번역결과  \n",
      "Luna는 감동과 호기심이 가득한 작은 토끼였습니다. 그녀는 매우 친절하고 호기심 많은 동물들과 친구들을 사귀며 매우 행복한 삶을 살았습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것을 좋아했습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 새로운 친구들을 사귀는 것이 가장 큰 행복이라고 믿었습니다. 그녀는 자신이 새로운 것을 발견하고 \n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, min_length=2291, max_length=2500)\n",
    "print(tokenizer.decode(output[0][input_ids.shape[1]:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1f4994b81942f2816c3802b147c879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (15367 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def prepare_columns(example):\n",
    "    input_text = example['text']\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt')['input_ids'][0]\n",
    "    attention_mask = tokenizer(input_text, return_tensors='pt')['attention_mask'][0]\n",
    "    label = deepcopy(input_ids)\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}\n",
    "\n",
    "dataset = load_dataset('togethercomputer/RedPajama-Data-1T-Sample')#.remove_columns('meta')\n",
    "dataset = dataset[\"train\"].shuffle(seed=42).filter(lambda example: len(example['text']) >= 7*7200)\n",
    "dataset = dataset#.select(list(range(500)))\n",
    "dataset = dataset.map(prepare_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check distribution\n",
    "import re\n",
    "\n",
    "source = {'wi':0,\n",
    "        'ar':0,\n",
    "        'bo':0}\n",
    "\n",
    "for D in dataset:\n",
    "    x = D['meta']\n",
    "    pattern = r'\"source\":\\s*\"([^\"]*)\"'\n",
    "    match = re.search(pattern, x.replace(\"'\", \"\\\"\"))\n",
    "    if match:\n",
    "        s = match.group(1)[:2]    \n",
    "        try:\n",
    "            source[s] += len(D['text'])\n",
    "        except:\n",
    "            source[s] = len(D['text'])\n",
    "    else:\n",
    "        if 'wikipedia' in x:\n",
    "            source['wi'] += len(D['text'])\n",
    "        elif 'arxiv' in x:\n",
    "            source['ar'] += len(D['text'])\n",
    "        else:\n",
    "            source['bo'] += len(D['text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source = dict(sorted(source.items(), key=lambda x:-x[1]))\n",
    "plt.bar(height=source.values(), x=source.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source = dict(sorted(source.items(), key=lambda x:-x[1]))\n",
    "plt.bar(height=source.values(), x=source.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution for Seq Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_samples = np.clip(16400 - expon.rvs(scale=4000, size=100_000), 0, 16400)\n",
    "\n",
    "plt.hist(random_samples, bins=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec227250979d4d3ca5d1018c40a3a016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_154997/2451330698.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  random_length = int(7200 - expon.rvs(scale=1500, size=1))\n"
     ]
    }
   ],
   "source": [
    "def resize_sequence(example):\n",
    "    random_length = 0\n",
    "    while random_length < 10:\n",
    "        random_length = int(7200 - expon.rvs(scale=1500, size=1))\n",
    "    input_ids = example['input_ids'][:random_length]\n",
    "    label = example['label'][:random_length]\n",
    "    attention_mask = example['attention_mask'][:random_length]\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}\n",
    "\n",
    "dataset = dataset.map(resize_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = {}\n",
    "for D in datasets['train']:\n",
    "    try:\n",
    "        size[len(D['input_ids'])] += 1\n",
    "    except: \n",
    "        size[len(D['input_ids'])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size_list = []\n",
    "for key, val in size.items():\n",
    "    size_list.extend([key]*val)\n",
    "\n",
    "plt.hist(size_list, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, val_size=.9):\n",
    "    index = int(len(dataset) * val_size)\n",
    "    return dataset.select(range(index)), dataset.select(range(index, len(dataset)))\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(dataset)\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "#key: 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.push_to_hub(repo_id='context_extension-vicuna-v1.3-7k', private=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_dataset('sade-adrien/context_extension-mistral-16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['train'] = datasets['train'].select((i for i in range(len(datasets['train'])) if i != 27710))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/et/.cache/huggingface/datasets/sade-adrien___parquet/sade-adrien--context_extension-mistral-7k-4c55924899f1cd01/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-1887c154ebe66f42.arrow\n",
      "Loading cached processed dataset at /home/et/.cache/huggingface/datasets/sade-adrien___parquet/sade-adrien--context_extension-mistral-7k-4c55924899f1cd01/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-607b5b463987afe3.arrow\n"
     ]
    }
   ],
   "source": [
    "def resize_sequence(example):\n",
    "    random_length = 0\n",
    "    while random_length < 1:\n",
    "        random_length = int(16400 - expon.rvs(scale=4000, size=1))\n",
    "    input_ids = example['input_ids'][:random_length]\n",
    "    label = example['label'][:random_length]\n",
    "    attention_mask = example['attention_mask'][:random_length]\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'label': label}\n",
    "\n",
    "dataset = dataset.map(resize_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets['val'][2]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lora fine tunining\n",
    "lora_r_default = 4\n",
    "lora_alpha_default = 32\n",
    "lora_dropout_default = 0.05\n",
    "lora_config = LoraConfig(\n",
    "        r=lora_r_default, #dimention of the low-rank matrices\n",
    "        lora_alpha=lora_alpha_default, # scaling factor for the weight matrices\n",
    "        lora_dropout=lora_dropout_default, # dropout probability of the LoRA layers\n",
    "        bias=\"none\", # set to all to train all bias parameters\n",
    "        task_type=\"CAUSAL_LM\",  # casual language modeling\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"] # the layer within a neural networkk to which LoRA reg will be applied\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,359,296 || all params: 7,244,091,392 || trainable%: 0.032568556528779914\n"
     ]
    }
   ],
   "source": [
    "model.enable_input_require_grads()\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(datasets['train'], batch_size=1, shuffle=False)\n",
    "val_dataloader = DataLoader(datasets['val'], batch_size=1, shuffle=False)\n",
    "\n",
    "optimizer = RMSprop(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, val_dataloader, step=None, train_loss=None):\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    for step, batch in tqdm(enumerate(val_dataloader)):\n",
    "        input_ids, attention_mask, labels = torch.tensor(batch['input_ids'], device=device).unsqueeze(0), \\\n",
    "                                            torch.tensor(batch['attention_mask'], device=device).unsqueeze(0), \\\n",
    "                                            torch.tensor(batch['label'], device=device).unsqueeze(0)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "    average_loss = total_val_loss / len(val_dataloader)\n",
    "    print(f\"step {step}, train_loss: {train_loss}, val_loss: {average_loss}\")\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast('cuda'):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        \n",
    "        for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "            input_ids, attention_mask, labels = torch.tensor(batch['input_ids'], device=device).unsqueeze(0), \\\n",
    "                                                torch.tensor(batch['attention_mask'], device=device).unsqueeze(0), \\\n",
    "                                                torch.tensor(batch['label'], device=device).unsqueeze(0)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "#            if step%100 == 0 and step>0:\n",
    "#                eval(model, val_dataloader, step, total_train_loss/(step+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_output_dir = \"models/test_tbd\"\n",
    "args_max_steps = 10\n",
    "args_eval_freq_default = 10\n",
    "args_log_freq_default = 10\n",
    "args_save_freq_default = 10\n",
    "args_batch_size = 1\n",
    "args_learning_rate = 1e-4\n",
    "args_lr_scheduler_type=\"cosine\"\n",
    "args_num_warmup_steps = 1\n",
    "args_gradient_accumulation_steps_default = 32\n",
    "args_weight_decay = 0.05\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=args_output_dir,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        max_steps=args_max_steps,\n",
    "        eval_steps=args_eval_freq_default,\n",
    "        save_steps=args_save_freq_default,\n",
    "        logging_steps=args_log_freq_default,\n",
    "        per_device_train_batch_size=args_batch_size,\n",
    "        per_device_eval_batch_size=args_batch_size,\n",
    "        learning_rate=args_learning_rate,\n",
    "        lr_scheduler_type=args_lr_scheduler_type,\n",
    "        warmup_steps=args_num_warmup_steps,\n",
    "        gradient_accumulation_steps=args_gradient_accumulation_steps_default,\n",
    "        gradient_checkpointing=True,\n",
    "        fp16=True,\n",
    "        weight_decay=args_weight_decay,\n",
    "        run_name=\"test_tbd\",\n",
    "        #push_to_hub=True,\n",
    "        #optim='adafactor',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/et/.cache/huggingface/datasets/sade-adrien___parquet/sade-adrien--context_extension-mistral-7k-4c55924899f1cd01/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-2d962e1a293e369e.arrow\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets['train'],\n",
    "    eval_dataset=datasets['val'].filter(lambda example: len(example['input_ids']) > 7180),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(args_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(datasets['train'], batch_size=1, shuffle=False)\n",
    "val_dataloader = DataLoader(datasets['val'], batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:01, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_train_loss = 0.0\n",
    "\n",
    "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "        input_ids, attention_mask, labels = torch.tensor(batch['input_ids'], device=device).unsqueeze(0), \\\n",
    "                                            torch.tensor(batch['attention_mask'], device=device).unsqueeze(0), \\\n",
    "                                            torch.tensor(batch['label'], device=device).unsqueeze(0)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.1016,   0.6260,  -0.7529,  ...,   1.9131,   2.9102,   1.4551],\n",
       "         [-12.1875,  -9.8281,  -2.6367,  ...,  -9.0859,  -9.5000,  -9.2891],\n",
       "         [ -4.8867,  -4.0898,   5.5156,  ...,  -5.4453,  -5.0312,  -6.2656],\n",
       "         ...,\n",
       "         [ -3.7031,  -1.7510,   1.1025,  ...,  -3.3125,  -3.9395,  -2.7461],\n",
       "         [ -5.1211,   3.2402,   7.2344,  ...,  -1.3086,   1.0625,  -1.3213],\n",
       "         [ -5.1172,   1.2061,   9.7109,  ...,  -0.9810,   2.5781,  -0.5752]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6353, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight False\n",
      "model.layers.0.self_attn.q_proj.weight False\n",
      "model.layers.0.self_attn.k_proj.weight False\n",
      "model.layers.0.self_attn.v_proj.weight False\n",
      "model.layers.0.self_attn.o_proj.weight False\n",
      "model.layers.0.mlp.gate_proj.weight False\n",
      "model.layers.0.mlp.up_proj.weight False\n",
      "model.layers.0.mlp.down_proj.weight False\n",
      "model.layers.0.input_layernorm.weight False\n",
      "model.layers.0.post_attention_layernorm.weight False\n",
      "model.layers.1.self_attn.q_proj.weight False\n",
      "model.layers.1.self_attn.k_proj.weight False\n",
      "model.layers.1.self_attn.v_proj.weight False\n",
      "model.layers.1.self_attn.o_proj.weight False\n",
      "model.layers.1.mlp.gate_proj.weight False\n",
      "model.layers.1.mlp.up_proj.weight False\n",
      "model.layers.1.mlp.down_proj.weight False\n",
      "model.layers.1.input_layernorm.weight False\n",
      "model.layers.1.post_attention_layernorm.weight False\n",
      "model.layers.2.self_attn.q_proj.weight False\n",
      "model.layers.2.self_attn.k_proj.weight False\n",
      "model.layers.2.self_attn.v_proj.weight False\n",
      "model.layers.2.self_attn.o_proj.weight False\n",
      "model.layers.2.mlp.gate_proj.weight False\n",
      "model.layers.2.mlp.up_proj.weight False\n",
      "model.layers.2.mlp.down_proj.weight False\n",
      "model.layers.2.input_layernorm.weight False\n",
      "model.layers.2.post_attention_layernorm.weight False\n",
      "model.layers.3.self_attn.q_proj.weight False\n",
      "model.layers.3.self_attn.k_proj.weight False\n",
      "model.layers.3.self_attn.v_proj.weight False\n",
      "model.layers.3.self_attn.o_proj.weight False\n",
      "model.layers.3.mlp.gate_proj.weight False\n",
      "model.layers.3.mlp.up_proj.weight False\n",
      "model.layers.3.mlp.down_proj.weight False\n",
      "model.layers.3.input_layernorm.weight False\n",
      "model.layers.3.post_attention_layernorm.weight False\n",
      "model.layers.4.self_attn.q_proj.weight False\n",
      "model.layers.4.self_attn.k_proj.weight False\n",
      "model.layers.4.self_attn.v_proj.weight False\n",
      "model.layers.4.self_attn.o_proj.weight False\n",
      "model.layers.4.mlp.gate_proj.weight False\n",
      "model.layers.4.mlp.up_proj.weight False\n",
      "model.layers.4.mlp.down_proj.weight False\n",
      "model.layers.4.input_layernorm.weight False\n",
      "model.layers.4.post_attention_layernorm.weight False\n",
      "model.layers.5.self_attn.q_proj.weight False\n",
      "model.layers.5.self_attn.k_proj.weight False\n",
      "model.layers.5.self_attn.v_proj.weight False\n",
      "model.layers.5.self_attn.o_proj.weight False\n",
      "model.layers.5.mlp.gate_proj.weight False\n",
      "model.layers.5.mlp.up_proj.weight False\n",
      "model.layers.5.mlp.down_proj.weight False\n",
      "model.layers.5.input_layernorm.weight False\n",
      "model.layers.5.post_attention_layernorm.weight False\n",
      "model.layers.6.self_attn.q_proj.weight False\n",
      "model.layers.6.self_attn.k_proj.weight False\n",
      "model.layers.6.self_attn.v_proj.weight False\n",
      "model.layers.6.self_attn.o_proj.weight False\n",
      "model.layers.6.mlp.gate_proj.weight False\n",
      "model.layers.6.mlp.up_proj.weight False\n",
      "model.layers.6.mlp.down_proj.weight False\n",
      "model.layers.6.input_layernorm.weight False\n",
      "model.layers.6.post_attention_layernorm.weight False\n",
      "model.layers.7.self_attn.q_proj.weight False\n",
      "model.layers.7.self_attn.k_proj.weight False\n",
      "model.layers.7.self_attn.v_proj.weight False\n",
      "model.layers.7.self_attn.o_proj.weight False\n",
      "model.layers.7.mlp.gate_proj.weight False\n",
      "model.layers.7.mlp.up_proj.weight False\n",
      "model.layers.7.mlp.down_proj.weight False\n",
      "model.layers.7.input_layernorm.weight False\n",
      "model.layers.7.post_attention_layernorm.weight False\n",
      "model.layers.8.self_attn.q_proj.weight False\n",
      "model.layers.8.self_attn.k_proj.weight False\n",
      "model.layers.8.self_attn.v_proj.weight False\n",
      "model.layers.8.self_attn.o_proj.weight False\n",
      "model.layers.8.mlp.gate_proj.weight False\n",
      "model.layers.8.mlp.up_proj.weight False\n",
      "model.layers.8.mlp.down_proj.weight False\n",
      "model.layers.8.input_layernorm.weight False\n",
      "model.layers.8.post_attention_layernorm.weight False\n",
      "model.layers.9.self_attn.q_proj.weight False\n",
      "model.layers.9.self_attn.k_proj.weight False\n",
      "model.layers.9.self_attn.v_proj.weight False\n",
      "model.layers.9.self_attn.o_proj.weight False\n",
      "model.layers.9.mlp.gate_proj.weight False\n",
      "model.layers.9.mlp.up_proj.weight False\n",
      "model.layers.9.mlp.down_proj.weight False\n",
      "model.layers.9.input_layernorm.weight False\n",
      "model.layers.9.post_attention_layernorm.weight False\n",
      "model.layers.10.self_attn.q_proj.weight False\n",
      "model.layers.10.self_attn.k_proj.weight False\n",
      "model.layers.10.self_attn.v_proj.weight False\n",
      "model.layers.10.self_attn.o_proj.weight False\n",
      "model.layers.10.mlp.gate_proj.weight False\n",
      "model.layers.10.mlp.up_proj.weight False\n",
      "model.layers.10.mlp.down_proj.weight False\n",
      "model.layers.10.input_layernorm.weight False\n",
      "model.layers.10.post_attention_layernorm.weight False\n",
      "model.layers.11.self_attn.q_proj.weight False\n",
      "model.layers.11.self_attn.k_proj.weight False\n",
      "model.layers.11.self_attn.v_proj.weight False\n",
      "model.layers.11.self_attn.o_proj.weight False\n",
      "model.layers.11.mlp.gate_proj.weight False\n",
      "model.layers.11.mlp.up_proj.weight False\n",
      "model.layers.11.mlp.down_proj.weight False\n",
      "model.layers.11.input_layernorm.weight False\n",
      "model.layers.11.post_attention_layernorm.weight False\n",
      "model.layers.12.self_attn.q_proj.weight False\n",
      "model.layers.12.self_attn.k_proj.weight False\n",
      "model.layers.12.self_attn.v_proj.weight False\n",
      "model.layers.12.self_attn.o_proj.weight False\n",
      "model.layers.12.mlp.gate_proj.weight False\n",
      "model.layers.12.mlp.up_proj.weight False\n",
      "model.layers.12.mlp.down_proj.weight False\n",
      "model.layers.12.input_layernorm.weight False\n",
      "model.layers.12.post_attention_layernorm.weight False\n",
      "model.layers.13.self_attn.q_proj.weight False\n",
      "model.layers.13.self_attn.k_proj.weight False\n",
      "model.layers.13.self_attn.v_proj.weight False\n",
      "model.layers.13.self_attn.o_proj.weight False\n",
      "model.layers.13.mlp.gate_proj.weight False\n",
      "model.layers.13.mlp.up_proj.weight False\n",
      "model.layers.13.mlp.down_proj.weight False\n",
      "model.layers.13.input_layernorm.weight False\n",
      "model.layers.13.post_attention_layernorm.weight False\n",
      "model.layers.14.self_attn.q_proj.weight False\n",
      "model.layers.14.self_attn.k_proj.weight False\n",
      "model.layers.14.self_attn.v_proj.weight False\n",
      "model.layers.14.self_attn.o_proj.weight False\n",
      "model.layers.14.mlp.gate_proj.weight False\n",
      "model.layers.14.mlp.up_proj.weight False\n",
      "model.layers.14.mlp.down_proj.weight False\n",
      "model.layers.14.input_layernorm.weight False\n",
      "model.layers.14.post_attention_layernorm.weight False\n",
      "model.layers.15.self_attn.q_proj.weight False\n",
      "model.layers.15.self_attn.k_proj.weight False\n",
      "model.layers.15.self_attn.v_proj.weight False\n",
      "model.layers.15.self_attn.o_proj.weight False\n",
      "model.layers.15.mlp.gate_proj.weight False\n",
      "model.layers.15.mlp.up_proj.weight False\n",
      "model.layers.15.mlp.down_proj.weight False\n",
      "model.layers.15.input_layernorm.weight False\n",
      "model.layers.15.post_attention_layernorm.weight False\n",
      "model.layers.16.self_attn.q_proj.weight False\n",
      "model.layers.16.self_attn.k_proj.weight False\n",
      "model.layers.16.self_attn.v_proj.weight False\n",
      "model.layers.16.self_attn.o_proj.weight False\n",
      "model.layers.16.mlp.gate_proj.weight False\n",
      "model.layers.16.mlp.up_proj.weight False\n",
      "model.layers.16.mlp.down_proj.weight False\n",
      "model.layers.16.input_layernorm.weight False\n",
      "model.layers.16.post_attention_layernorm.weight False\n",
      "model.layers.17.self_attn.q_proj.weight False\n",
      "model.layers.17.self_attn.k_proj.weight False\n",
      "model.layers.17.self_attn.v_proj.weight False\n",
      "model.layers.17.self_attn.o_proj.weight False\n",
      "model.layers.17.mlp.gate_proj.weight False\n",
      "model.layers.17.mlp.up_proj.weight False\n",
      "model.layers.17.mlp.down_proj.weight False\n",
      "model.layers.17.input_layernorm.weight False\n",
      "model.layers.17.post_attention_layernorm.weight False\n",
      "model.layers.18.self_attn.q_proj.weight False\n",
      "model.layers.18.self_attn.k_proj.weight False\n",
      "model.layers.18.self_attn.v_proj.weight False\n",
      "model.layers.18.self_attn.o_proj.weight False\n",
      "model.layers.18.mlp.gate_proj.weight False\n",
      "model.layers.18.mlp.up_proj.weight False\n",
      "model.layers.18.mlp.down_proj.weight False\n",
      "model.layers.18.input_layernorm.weight False\n",
      "model.layers.18.post_attention_layernorm.weight False\n",
      "model.layers.19.self_attn.q_proj.weight False\n",
      "model.layers.19.self_attn.k_proj.weight False\n",
      "model.layers.19.self_attn.v_proj.weight False\n",
      "model.layers.19.self_attn.o_proj.weight False\n",
      "model.layers.19.mlp.gate_proj.weight False\n",
      "model.layers.19.mlp.up_proj.weight False\n",
      "model.layers.19.mlp.down_proj.weight False\n",
      "model.layers.19.input_layernorm.weight False\n",
      "model.layers.19.post_attention_layernorm.weight False\n",
      "model.layers.20.self_attn.q_proj.weight False\n",
      "model.layers.20.self_attn.k_proj.weight False\n",
      "model.layers.20.self_attn.v_proj.weight False\n",
      "model.layers.20.self_attn.o_proj.weight False\n",
      "model.layers.20.mlp.gate_proj.weight False\n",
      "model.layers.20.mlp.up_proj.weight False\n",
      "model.layers.20.mlp.down_proj.weight False\n",
      "model.layers.20.input_layernorm.weight False\n",
      "model.layers.20.post_attention_layernorm.weight False\n",
      "model.layers.21.self_attn.q_proj.weight False\n",
      "model.layers.21.self_attn.k_proj.weight False\n",
      "model.layers.21.self_attn.v_proj.weight False\n",
      "model.layers.21.self_attn.o_proj.weight False\n",
      "model.layers.21.mlp.gate_proj.weight False\n",
      "model.layers.21.mlp.up_proj.weight False\n",
      "model.layers.21.mlp.down_proj.weight False\n",
      "model.layers.21.input_layernorm.weight False\n",
      "model.layers.21.post_attention_layernorm.weight False\n",
      "model.layers.22.self_attn.q_proj.weight False\n",
      "model.layers.22.self_attn.k_proj.weight False\n",
      "model.layers.22.self_attn.v_proj.weight False\n",
      "model.layers.22.self_attn.o_proj.weight False\n",
      "model.layers.22.mlp.gate_proj.weight False\n",
      "model.layers.22.mlp.up_proj.weight False\n",
      "model.layers.22.mlp.down_proj.weight False\n",
      "model.layers.22.input_layernorm.weight False\n",
      "model.layers.22.post_attention_layernorm.weight False\n",
      "model.layers.23.self_attn.q_proj.weight False\n",
      "model.layers.23.self_attn.k_proj.weight False\n",
      "model.layers.23.self_attn.v_proj.weight False\n",
      "model.layers.23.self_attn.o_proj.weight False\n",
      "model.layers.23.mlp.gate_proj.weight False\n",
      "model.layers.23.mlp.up_proj.weight False\n",
      "model.layers.23.mlp.down_proj.weight False\n",
      "model.layers.23.input_layernorm.weight False\n",
      "model.layers.23.post_attention_layernorm.weight False\n",
      "model.layers.24.self_attn.q_proj.weight False\n",
      "model.layers.24.self_attn.k_proj.weight False\n",
      "model.layers.24.self_attn.v_proj.weight False\n",
      "model.layers.24.self_attn.o_proj.weight False\n",
      "model.layers.24.mlp.gate_proj.weight False\n",
      "model.layers.24.mlp.up_proj.weight False\n",
      "model.layers.24.mlp.down_proj.weight False\n",
      "model.layers.24.input_layernorm.weight False\n",
      "model.layers.24.post_attention_layernorm.weight False\n",
      "model.layers.25.self_attn.q_proj.weight False\n",
      "model.layers.25.self_attn.k_proj.weight False\n",
      "model.layers.25.self_attn.v_proj.weight False\n",
      "model.layers.25.self_attn.o_proj.weight False\n",
      "model.layers.25.mlp.gate_proj.weight False\n",
      "model.layers.25.mlp.up_proj.weight False\n",
      "model.layers.25.mlp.down_proj.weight False\n",
      "model.layers.25.input_layernorm.weight False\n",
      "model.layers.25.post_attention_layernorm.weight False\n",
      "model.layers.26.self_attn.q_proj.weight False\n",
      "model.layers.26.self_attn.k_proj.weight False\n",
      "model.layers.26.self_attn.v_proj.weight False\n",
      "model.layers.26.self_attn.o_proj.weight False\n",
      "model.layers.26.mlp.gate_proj.weight False\n",
      "model.layers.26.mlp.up_proj.weight False\n",
      "model.layers.26.mlp.down_proj.weight False\n",
      "model.layers.26.input_layernorm.weight False\n",
      "model.layers.26.post_attention_layernorm.weight False\n",
      "model.layers.27.self_attn.q_proj.weight False\n",
      "model.layers.27.self_attn.k_proj.weight False\n",
      "model.layers.27.self_attn.v_proj.weight False\n",
      "model.layers.27.self_attn.o_proj.weight False\n",
      "model.layers.27.mlp.gate_proj.weight False\n",
      "model.layers.27.mlp.up_proj.weight False\n",
      "model.layers.27.mlp.down_proj.weight False\n",
      "model.layers.27.input_layernorm.weight False\n",
      "model.layers.27.post_attention_layernorm.weight False\n",
      "model.layers.28.self_attn.q_proj.weight False\n",
      "model.layers.28.self_attn.k_proj.weight False\n",
      "model.layers.28.self_attn.v_proj.weight False\n",
      "model.layers.28.self_attn.o_proj.weight False\n",
      "model.layers.28.mlp.gate_proj.weight False\n",
      "model.layers.28.mlp.up_proj.weight False\n",
      "model.layers.28.mlp.down_proj.weight False\n",
      "model.layers.28.input_layernorm.weight False\n",
      "model.layers.28.post_attention_layernorm.weight False\n",
      "model.layers.29.self_attn.q_proj.weight False\n",
      "model.layers.29.self_attn.k_proj.weight False\n",
      "model.layers.29.self_attn.v_proj.weight False\n",
      "model.layers.29.self_attn.o_proj.weight False\n",
      "model.layers.29.mlp.gate_proj.weight False\n",
      "model.layers.29.mlp.up_proj.weight False\n",
      "model.layers.29.mlp.down_proj.weight False\n",
      "model.layers.29.input_layernorm.weight False\n",
      "model.layers.29.post_attention_layernorm.weight False\n",
      "model.layers.30.self_attn.q_proj.weight False\n",
      "model.layers.30.self_attn.k_proj.weight False\n",
      "model.layers.30.self_attn.v_proj.weight False\n",
      "model.layers.30.self_attn.o_proj.weight False\n",
      "model.layers.30.mlp.gate_proj.weight False\n",
      "model.layers.30.mlp.up_proj.weight False\n",
      "model.layers.30.mlp.down_proj.weight False\n",
      "model.layers.30.input_layernorm.weight False\n",
      "model.layers.30.post_attention_layernorm.weight False\n",
      "model.layers.31.self_attn.q_proj.weight False\n",
      "model.layers.31.self_attn.k_proj.weight False\n",
      "model.layers.31.self_attn.v_proj.weight False\n",
      "model.layers.31.self_attn.o_proj.weight False\n",
      "model.layers.31.mlp.gate_proj.weight False\n",
      "model.layers.31.mlp.up_proj.weight False\n",
      "model.layers.31.mlp.down_proj.weight False\n",
      "model.layers.31.input_layernorm.weight False\n",
      "model.layers.31.post_attention_layernorm.weight False\n",
      "model.norm.weight False\n",
      "lm_head.weight False\n"
     ]
    }
   ],
   "source": [
    "for n,p in model.named_parameters():\n",
    "    if 'embed' in n:\n",
    "        p.requires_grad = False\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "    print(n, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/datascience1/Adrien/Context_Extension/Context_Extension.ipynb Cell 45\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22474230332d4573706572616e746f227d/mnt/datascience1/Adrien/Context_Extension/Context_Extension.ipynb#Y103sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_memory = model + activations + gradients\n",
    "# total_memory = model + 1.7*tokens + 19*tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.673"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(48774-11428)/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sierp'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Give a list of famous french football players.\"\n",
    "\n",
    "input = tokenizer(prompt, return_tensors='pt')\n",
    "outputs = model(input_ids=input['input_ids'], attention_mask=input['attention_mask'], labels=input['input_ids'])\n",
    "\n",
    "tokenizer.decode(torch.argmax(outputs.logits[-1], dim=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 32000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/et/miniconda3/envs/context_extension/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/et/miniconda3/envs/context_extension/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Give a list of famous french football players. (10 points)\n",
      "\n",
      "1. Thierry Henry\n",
      "2. Zinedine Zidane\n",
      "3. Michel Platini\n",
      "4. Jean-Pierre Papin\n",
      "5. Eric Cantona\n",
      "6. Didier Drogba\n",
      "7. Ronald Koeman\n",
      "8. Patrick Vieira\n",
      "9. Luis Suarez\n",
      "10. Samuel Eto'o</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give a list of famous french football players.\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "output = model.generate(input_ids, max_new_tokens=100)\n",
    "\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor(datasets['train'][0]['input_ids'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def estimate_memory_training(model, sample_input, optimizer_type=torch.optim.Adam, batch_size=1, use_amp=False, device=0):\n",
    "    \"\"\"Predict the maximum memory usage of the model. \n",
    "    Args:\n",
    "        optimizer_type (Type): the class name of the optimizer to instantiate\n",
    "        model (nn.Module): the neural network model\n",
    "        sample_input (torch.Tensor): A sample input to the network. It should be \n",
    "            a single item, not a batch, and it will be replicated batch_size times.\n",
    "        batch_size (int): the batch size\n",
    "        use_amp (bool): whether to estimate based on using mixed precision\n",
    "        device (torch.device): the device to use\n",
    "    \"\"\"\n",
    "    # Reset model and optimizer\n",
    "    model.cpu()\n",
    "    optimizer = optimizer_type(model.parameters(), lr=.001)\n",
    "    a = torch.cuda.memory_allocated(device)\n",
    "    model.to(device)\n",
    "    b = torch.cuda.memory_allocated(device)\n",
    "    model_memory = b - a\n",
    "    model_input = sample_input.unsqueeze(0).repeat(batch_size, 1)\n",
    "    output = model(model_input.to(device)).sum()\n",
    "    c = torch.cuda.memory_allocated(device)\n",
    "    if use_amp:\n",
    "        amp_multiplier = .5\n",
    "    else:\n",
    "        amp_multiplier = 1\n",
    "    forward_pass_memory = (c - b)*amp_multiplier\n",
    "    gradient_memory = model_memory\n",
    "    if isinstance(optimizer, torch.optim.Adam):\n",
    "        o = 2\n",
    "    elif isinstance(optimizer, torch.optim.RMSprop):\n",
    "        o = 1\n",
    "    elif isinstance(optimizer, torch.optim.SGD):\n",
    "        o = 0\n",
    "    elif isinstance(optimizer, torch.optim.Adagrad):\n",
    "        o = 1\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer. Look up how many moments are\" +\n",
    "            \"stored by your optimizer and add a case to the optimizer checker.\")\n",
    "    gradient_moment_memory = o*gradient_memory\n",
    "    total_memory = model_memory + forward_pass_memory + gradient_memory + gradient_moment_memory\n",
    "\n",
    "    return total_memory\n",
    "\n",
    "def estimate_memory_inference(model, sample_input, batch_size=1, use_amp=False, device=0):\n",
    "    \"\"\"Predict the maximum memory usage of the model. \n",
    "    Args:\n",
    "        optimizer_type (Type): the class name of the optimizer to instantiate\n",
    "        model (nn.Module): the neural network model\n",
    "        sample_input (torch.Tensor): A sample input to the network. It should be \n",
    "            a single item, not a batch, and it will be replicated batch_size times.\n",
    "        batch_size (int): the batch size\n",
    "        use_amp (bool): whether to estimate based on using mixed precision\n",
    "        device (torch.device): the device to use\n",
    "    \"\"\"\n",
    "    # Reset model and optimizer\n",
    "    model.cpu()\n",
    "    a = torch.cuda.memory_allocated(device)\n",
    "    model.to(device)\n",
    "    b = torch.cuda.memory_allocated(device)\n",
    "    model_memory = b - a\n",
    "    model_input = sample_input.unsqueeze(0).repeat(batch_size, 1)\n",
    "    output = model(model_input.to(device)).sum()\n",
    "    total_memory = model_memory\n",
    "\n",
    "    return total_memory\n",
    "\n",
    "def test_memory_training(in_size=100, out_size=10, hidden_size=100, optimizer_type=torch.optim.Adam, batch_size=1, use_amp=False, device=0):\n",
    "    sample_input = torch.randn(batch_size, in_size, dtype=torch.float32)\n",
    "    model = nn.Sequential(nn.Linear(in_size, hidden_size),\n",
    "                        *[nn.Linear(hidden_size, hidden_size) for _ in range(200)],\n",
    "                        nn.Linear(hidden_size, out_size))\n",
    "    max_mem_est = estimate_memory_training(model, sample_input[0], optimizer_type=optimizer_type, batch_size=batch_size, use_amp=use_amp)\n",
    "    print(\"Maximum Memory Estimate\", max_mem_est)\n",
    "    optimizer = optimizer_type(model.parameters(), lr=.001)\n",
    "    print(\"Beginning mem:\", torch.cuda.memory_allocated(device), \"Note - this may be higher than 0, which is due to PyTorch caching. Don't worry too much about this number\")\n",
    "    model.to(device)\n",
    "    print(\"After model to device:\", torch.cuda.memory_allocated(device))\n",
    "    for i in range(3):\n",
    "        optimizer.zero_grad()\n",
    "        print(\"Iteration\", i)\n",
    "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "            a = torch.cuda.memory_allocated(device)\n",
    "            out = model(sample_input.to(device)).sum() # Taking the sum here just to get a scalar output\n",
    "            b = torch.cuda.memory_allocated(device)\n",
    "        print(\"1 - After forward pass\", torch.cuda.memory_allocated(device))\n",
    "        print(\"2 - Memory consumed by forward pass\", b - a)\n",
    "        out.backward()\n",
    "        print(\"3 - After backward pass\", torch.cuda.memory_allocated(device))\n",
    "        optimizer.step()\n",
    "        print(\"4 - After optimizer step\", torch.cuda.memory_allocated(device))\n",
    "\n",
    "def test_memory_inference(in_size=100, out_size=10, hidden_size=100, batch_size=1, use_amp=False, device=0):\n",
    "    sample_input = torch.randn(batch_size, in_size, dtype=torch.float32)\n",
    "    model = nn.Sequential(nn.Linear(in_size, hidden_size),\n",
    "                        *[nn.Linear(hidden_size, hidden_size) for _ in range(200)],\n",
    "                        nn.Linear(hidden_size, out_size))\n",
    "    max_mem_est = estimate_memory_inference(model, sample_input[0], batch_size=batch_size, use_amp=use_amp)\n",
    "    print(\"Maximum Memory Estimate\", max_mem_est)\n",
    "    print(\"Beginning mem:\", torch.cuda.memory_allocated(device), \"Note - this may be higher than 0, which is due to PyTorch caching. Don't worry too much about this number\")\n",
    "    model.to(device)\n",
    "    print(\"After model to device:\", torch.cuda.memory_allocated(device))\n",
    "    with torch.no_grad():\n",
    "        for i in range(3):\n",
    "            print(\"Iteration\", i)\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                a = torch.cuda.memory_allocated(device)\n",
    "                out = model(sample_input.to(device)).sum() # Taking the sum here just to get a scalar output\n",
    "                b = torch.cuda.memory_allocated(device)\n",
    "            print(\"1 - After forward pass\", torch.cuda.memory_allocated(device))\n",
    "            print(\"2 - Memory consumed by forward pass\", b - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_memory_training(batch_size=64)\n",
    "# test_memory_inference(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18])\n",
      "As of 202, the current world chess champion is Magnus Carlsen from Norway. However, the title of the greatest chess player in the world is a matter of personal opinion and can vary over time.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"[INST] Who is the greatest chess player in the world? [\\INST]\"\"\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
    "print(input_ids.shape)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=100, min_new_tokens=0)\n",
    "    print(tokenizer.decode(outputs[0, input_ids.shape[1]:], skip_special_tokens=True, do_sample=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model w/ LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Who are the most famous French actors as of 2021?\n",
      "Answer:\n",
      "1. Jean Dujardin\n",
      "2. Jean Reno\n",
      "3. Gérard Depardieu\n",
      "4. Isabelle Adjani\n",
      "5. Marion Cotillard\n",
      "6. Audrey Tautou\n",
      "7. Vincent Cassel\n",
      "8. François Cluzet\n",
      "9. Édith Scob\n",
      "10. Pierre Salvadori\n",
      "11. Éric Elkaïm\n",
      "12. Jean-Paul Belmondo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Who are the most famous French actors as of 2021?'\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').input_ids.cuda()\n",
    "\n",
    "output = model.generate(input_ids, max_new_tokens=100, do_sample=False)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = 'sade-adrien/Mistral-7B-Instruct-v0.1-LC-PI-.5'\n",
    "\n",
    "model.load_adapter(peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare .py training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, Trainer, TrainingArguments, logging\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "from scipy.stats import expon\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "huggingface_api_key = \"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\"\n",
    "os.environ[\"HUGGINGFACE_TOKEN\"] = huggingface_api_key\n",
    "notebook_login()\n",
    "os.environ.pop(\"HUGGINGFACE_TOKEN\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9f53aeb4364029ae5b52e33ebadead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "checkpoint = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "config.update({'_flash_attn_2_enabled' : True})  #Flash Attention\n",
    "#config.update({'sliding_window' : 15_000})  #eliminating sliding window\n",
    "config.update({'rope_scaling' : {\"type\": \"linear\",\n",
    "                                 \"factor\": 4096/16400,\n",
    "                                }})             #Position Interpolation\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast = False, revision = 'main', config = config,)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
    "                                             low_cpu_mem_usage = True,\n",
    "                                             torch_dtype = torch.float16,\n",
    "                                             revision='main',\n",
    "                                             device_map='auto',\n",
    "                                             #load_in_8bit=True,\n",
    "                                             config = config,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object <genexpr> at 0x7fbc601a1f20> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('sade-adrien/context_extension-mistral-16k')['train']\n",
    "dataset = dataset.select((i for i in range(len(dataset)) if i != 27710))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt=None, input_ids=None, attention_mask=None, max_tokens=100, return_only_new=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if not ((input_ids is not None) and (attention_mask is not None)):\n",
    "            input_ids = tokenizer(prompt, return_tensors='pt')['input_ids'].to(device)\n",
    "            attention_mask = tokenizer(prompt, return_tensors='pt')['attention_mask'].to(device)\n",
    "        print(input_ids.shape)\n",
    "        for _ in range(max_tokens):\n",
    "            logits = model(input_ids).logits.squeeze(0)\n",
    "            token = torch.argmax(logits, dim=-1)[-1].item()\n",
    "            input_ids = torch.cat((input_ids.squeeze(), torch.tensor([token]).to(device))).unsqueeze(0)\n",
    "            if return_only_new:\n",
    "                new = torch.cat((new.squeeze(), torch.tensor([token]))).unsqueeze(0)\n",
    "            if token == 2:\n",
    "                break\n",
    "            \n",
    "    return new if return_only_new else input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16386])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Justia Forms Business Contracts Oaktree Acquisition Corp. II Business Combination Agreement, dated as of December 7, 2021\\nBusiness Combination Agreement, dated as of December 7, 2021, by and among OACB, Alvotech and TopCo\\nEX-2.1 2 d266266dex21.htm EX-2.1 EX-2.1\\nExhibit 2.1\\nEXECUTION VERSION\\nBUSINESS COMBINATION AGREEMENT\\nBY AND AMONG\\nALVOTECH LUX HOLDINGS S.A.S.,\\nALVOTECH HOLDINGS S.A.,\\nOAKTREE ACQUISITION CORP. II\\nDATED AS OF DECEMBER 7, 2021\\nARTICLE 1 CERTAIN DEFINITIONS\\nSection 1.1\\nDefinitions 3\\nCertain Defined Terms 15\\nARTICLE 2 MERGERS\\nClosing Transactions 18\\nAllocation Schedule 21\\nClosing 21\\nWithholding 21\\nParent Warrants 21\\nEarn Out 22\\nARTICLE 3 REPRESENTATIONS AND WARRANTIES RELATING TO THE COMPANY\\nOrganization and Qualification 23\\nCapitalization of the Group Companies 24\\nAuthority 25\\nFinancial Statements; Undisclosed Liabilities 25\\nConsents and Requisite Governmental Approvals; No Violations 26\\nPermits 26\\nMaterial Contracts 27\\nAbsence of Changes 29\\nLitigation 29\\nSection 3.10\\nCompliance with Applicable Law 29\\nEmployee Plans 29\\nEnvironmental Matters 31\\nIntellectual Property 32\\nLabor Matters 34\\nTax Matters 35\\nBrokers 37\\nReal and Personal Property 37\\nTransactions with Affiliates 37\\nData Privacy and Security 38\\nCompliance with International Trade & Anti-Corruption Laws 38\\nInformation Supplied 39\\nRegulatory Compliance 39\\nMaterial Suppliers and Partners 41\\nInvestigation; No Other Representations 41\\nEXCLUSIVITY OF REPRESENTATIONS AND WARRANTIES 42\\nARTICLE 4 REPRESENTATIONS AND WARRANTIES RELATING TO TOPCO\\nCorporate Organization 42\\nCapitalization of TopCo 43\\nBusiness Activities 44\\nInvestment Company Act 44\\nARTICLE 5 REPRESENTATIONS AND WARRANTIES RELATING TO PARENT\\nConsents and Requisite Government Approvals; No Violations 46\\nCapitalization of Parent 46\\nSEC Filings 47\\nTrust Account 47\\nInternal Controls; Listing; Financial Statements 49\\nNo Undisclosed Liabilities 50\\nARTICLE 6 COVENANTS\\nConduct of Business of the Company 52\\nEfforts to Consummate 55\\nConfidentiality and Access to Information 57\\nPublic Announcements 58\\nExclusive Dealing 60\\nPreparation of Registration Statement / Proxy Statement 61\\nParent Shareholder Approval 62\\nConduct of Business of Parent 63\\nTopCo Incentive Equity Plan 64\\nNasdaq and Nasdaq First North Listings 64\\nPCAOB Financials 65\\nIndemnification; Directors’ and Officers’ Insurance 65\\nPost-Closing Directors and Officers 66\\nConduct of Business of TopCo 67\\nTermination and Amendment of Agreements 67\\nEmployee Benefit Plan Matters 67\\nAudit 69\\nEmployment Agreements 69\\nARTICLE 7 CONDITIONS TO CONSUMMATION OF THE TRANSACTIONS CONTEMPLATED BY THIS AGREEMENT\\nConditions to the Obligations of the Parties 69\\nOther Conditions to the Obligations of Parent 70\\nOther Conditions to the Obligations of the Company 71\\nFrustration of Closing Conditions 71\\nARTICLE 8 TERMINATION\\nTermination 72\\nEffect of Termination 73\\nARTICLE 9 MISCELLANEOUS\\nNon-Survival 73\\nEntire Agreement; Assignment 73\\nAmendment 74\\nNotices 74\\nGoverning Law 75\\nFees and Expenses 75\\nConstruction; Interpretation 75\\nExhibits and Schedules 76\\nParties in Interest 76\\nSeverability 76\\nCounterparts; Electronic Signatures 76\\nKnowledge of Company; Knowledge of Parent 76\\nNo Recourse 77\\nExtension; Waiver 77\\nWaiver of Jury Trial 77\\nArbitration 78\\nRemedies 78\\nTrust Account Waiver 78\\nForm of Investor Rights Agreement\\nForm of Election on Internal Revenue Service Form 8832\\nExhibit C\\nPlan of Merger\\nExhibit D\\nAgreed TopCo Governing Documents\\nExhibit E\\nForm of Warrant Assumption Agreement\\nExhibit F\\nRelated Party Transactions Amendments\\nExhibit G\\nCayman Plan of Merger\\nThis BUSINESS COMBINATION AGREEMENT (this “Agreement”), dated as of December 7, 2021, is made by and among Alvotech Lux Holdings S.A.S., a simplified joint stock company (société par actions simplifiée) incorporated and existing under the laws of the Grand Duchy of Luxembourg, having its registered office at 9, rue de Bitbourg, L-1273 Luxembourg, Grand Duchy of Luxembourg and registered with the Luxembourg Trade and Company Register (Registre de Commerce et des Sociétés, Luxembourg) (the “RCS”) under number B258884 (“TopCo”), Alvotech Holdings S.A., a public limited liability company (société anonyme) incorporated and existing under the laws of the Grand Duchy of Luxembourg, having its registered office at 9, rue de Bitbourg, L-1273 Luxembourg, Grand Duchy of Luxembourg and registered with the RCS under number B229193 (the “Company”), and Oaktree Acquisition Corp. II, a Cayman Islands exempted company (“Parent”), TopCo, the Company, and Parent shall be referred to herein from time to time collectively as the “Parties”. Capitalized terms used but not otherwise defined herein have the meanings set forth in Section 1.1.\\nWHEREAS, (a) Parent is a blank check company incorporated as a Cayman Islands exempted company on August 5, 2020 and incorporated for the purpose of effecting a merger, share exchange, asset acquisition, share purchase, reorganization or similar business combination with one or more businesses, and (b) TopCo is a newly formed entity that was formed for purposes of consummating the transactions contemplated by this Agreement and the Ancillary Documents as successor to Parent;\\nWHEREAS, pursuant to the Governing Documents of Parent, Parent is required to provide an opportunity for its shareholders to have their outstanding Parent Class A Shares redeemed on the terms and subject to the conditions set forth therein in connection with obtaining the Parent Shareholder Approval;\\nWHEREAS, (a) the Pre-Closing Parent Holders that do not redeem their shares of Parent Class A Shares for cash pursuant to the Parent Shareholder Redemption will receive TopCo Ordinary Shares in respect of such Parent Class A Shares, and (b) the Pre-Closing Parent Holders that hold Parent Class B Shares will receive TopCo Ordinary Shares in respect of such Parent Class B Shares, in the case of each of clauses (a) and (b), in connection with the First Merger and pursuant to the terms and subject to the conditions set forth herein;\\nWHEREAS, as of the date of this Agreement, Oaktree Acquisition Holdings II, L.P., a Cayman Islands exempted limited partnership (the “Sponsor”), owns 6,250,000 Parent Class B Shares (the “Sponsor Shares”) and 4,666,667 Parent Warrants (the “Sponsor Warrants”);\\nWHEREAS, concurrently with the execution of this Agreement, the Sponsor and TopCo are entering into the sponsor letter agreement (the “Sponsor Letter Agreement”), pursuant to which, among other things, (a) the Sponsor has agreed to vote in favor of this Agreement and the transactions contemplated hereby (including the First Merger), (b) the Sponsor has agreed not to effect any sale or distribution of any Parent Class B Shares or Parent Warrants during the period described therein, (c) the Sponsor has agreed to waive any adjustment to the conversion ratio set forth in the Governing Documents of Parent or any other anti-dilution or similar protection with respect to the Parent Class B Shares (whether resulting from the transactions contemplated by the Subscription Agreements or otherwise) and (d) the Sponsor has agreed to, immediately after the First Merger, subject 1,250,000 Sponsor Shares held by Sponsor as of immediately prior to the First Merger Effective Time, which will have been exchanged for TopCo Ordinary Shares, to certain vesting conditions, in each case, on the terms and subject to the conditions set forth in the Sponsor Letter Agreement;\\nWHEREAS, concurrently with the execution of this Agreement, the Company Shareholders who hold capital stock of the Company sufficient to deliver the required Company Shareholders’ consent in order to approve the Second Merger (the “Required Company Shareholders’ Consent”), will, together with the Company, enter into a framework agreement pursuant to which, among other things, (a) the Required Company Shareholders’ Consent will be delivered and (b) certain rights under and in connection with each of the Company’s shareholders agreement and outstanding convertible loans and warrants will be exercised (the “Framework Agreement”), a copy of which will be delivered to Parent;\\nWHEREAS, concurrently with the execution of this Agreement, certain Company Shareholders (collectively, the “Supporting Company Shareholders”) are each executing and delivering to Parent a transaction support agreement (collectively, the “Support Agreements”), pursuant to which each such Supporting Company Shareholder is agreeing to, among other things, (a) certain customary restrictive covenants, and (b) take, or cause to be taken, any actions necessary or advisable to cause certain Related Party Transactions to be terminated or amended effective as of the Closing;\\nWHEREAS, (a) TopCo has made an initial classification election on Internal Revenue Service Form 8832 pursuant to Treasury Regulations Section ###-###-####-3(c), effective as of the date of its formation, to be disregarded as an entity as separate from its owner for U.S. federal income tax purposes, and (b) TopCo will make an election on Internal Revenue Service Form 8832 pursuant to Treasury Regulations Section ###-###-####-3(c), effective as of the date of the First Merger Effective Time, to be classified as an association taxable as a corporation for U.S. federal income tax purposes (the “Election”);\\nWHEREAS, on the Closing Date, Parent will merge with and into TopCo (the “First Merger”), with TopCo as the surviving company in the merger and each issued and outstanding Parent Share will be exchanged for one TopCo Ordinary Share pursuant to a share capital increase of TopCo, and each outstanding Parent Warrant will, by its terms, automatically cease to represent a right to acquire Parent Class A Shares and shall automatically represent a right to acquire one TopCo Ordinary Share, in each case, on the terms and subject to the conditions set forth in this Agreement;\\nWHEREAS, on the Closing Date immediately after the effectiveness of the First Merger but prior to the Conversion, TopCo will redeem and cancel the shares held by the initial sole shareholder of TopCo pursuant to a share capital reduction of TopCo (the “Redemption”) that will be resolved upon on the Approval Date;\\nWHEREAS, on the Closing Date immediately after the effectiveness of the First Merger and the Redemption, the legal form of TopCo shall be changed from a simplified joint stock company (société par actions simplifiée) to a public limited liability company (société anonyme) under Luxembourg law on the terms and subject to the conditions set forth in this Agreement (the “Conversion”) that will be resolved upon on the Approval Date;\\nWHEREAS, on the Closing Date, immediately following the effectiveness of the Conversion, the Company will merge with and into TopCo (the “Second Merger”), with TopCo as the surviving company in the merger, and each issued and outstanding Company Share will be automatically exchanged for TopCo Ordinary Shares, in accordance with the Allocation Schedule and Section 2.2, pursuant to a share capital increase of TopCo, as set forth in this Agreement and that will be resolved upon on the Approval Date;\\nWHEREAS, (a) concurrently with the execution of this Agreement, TopCo and Parent are entering into subscription agreements (collectively, the “Subscription Agreements”) with certain investors (collectively, the “Investors”) pursuant to which, among other things, the Investors have agreed to subscribe for, and TopCo, as successor to Parent in the First Merger, has agreed to issue to the Investors, an aggregate number of TopCo Ordinary Shares set forth in the Subscription Agreements in exchange for an aggregate subscription price of approximately $154,000,000, with the foregoing to be resolved upon on the Approval Date but to become effective on the Closing Date following the effectiveness of the Conversion and prior to the effectiveness of the Second Merger, on the terms and subject to the conditions set forth in the Subscription Agreements (such aggregate purchase price, the “PIPE Financing Amount”, and such equity financing hereinafter referred to as the “PIPE Financing”);\\nWHEREAS, at the Closing, TopCo, the Sponsor and each Company Shareholder that will be an officer or director of TopCo or that holds five percent (5%) or more of the Company Shares immediately prior to the Closing (the “IRA Company Shareholders”) shall enter into an investor rights agreement, substantially in the form attached hereto as Exhibit A (the “Investor Rights Agreement”), pursuant to which, among other things, (a) the Sponsor and each such Company Shareholder will agree not to effect any sale or distribution of any Equity Securities of TopCo issued pursuant to this Agreement or the Subscription Agreements during the lock-up periods described therein and (b) the Sponsor and each such Company Shareholder will be granted certain registration rights with respect to their respective TopCo Ordinary Shares and TopCo Warrants, in each case, on the terms and subject to the conditions therein;\\nWHEREAS, the Parent Board has (a) approved this Agreement, the Ancillary Documents and the transactions contemplated hereby and thereby (including the Mergers) and (b) recommended, among other things, acceptance of the transactions contemplated by this Agreement (including the First Merger) and the authorization of the Cayman Plan of Merger by the holders of Parent Shares entitled to vote thereon;\\nWHEREAS, the board of directors of the Company (a) has, on the terms and subject to the conditions set forth herein, approved this Agreement, the Ancillary Documents and the transactions contemplated hereby and thereby (including the Mergers) (b) has obtained Aztiq Consent and Alvogen Consent (as such terms are defined in the Company Shareholders Agreement) in accordance with the Company Shareholders Agreement, and (c) has recommended, among other things, acceptance of the Second Merger by the holders of Company Shares entitled to vote thereon;\\nWHEREAS, the sole chairman (president) of TopCo has approved this Agreement, the Ancillary Documents and the transactions contemplated hereby and thereby (including the Mergers); and\\nWHEREAS, each of the Parties intends for U.S. federal income tax purposes that (a) this Agreement, along with the other agreements and documents necessary to effectuate the First Merger, the Conversion, and the Second Merger, constitute a “plan of reorganization” within the meaning of Section 368 of the Code and Treasury Regulations promulgated thereunder with respect to each of the transactions described in the subsequent clauses (b)-(d), (b) the First Merger, together with the Election, shall constitute a transaction treated as a “reorganization” within the meaning of Section 368(a)(1)(E) and (F) of the Code, (c) the Conversion shall constitute a transaction treated as a “reorganization” within the meaning of Section 368(a)(1)(F) of the Code and (d) the Second Merger shall constitute a transaction treated as a “reorganization” within the meaning of Section 368(a) of the Code (clauses (a)-(d), the “Intended U.S. Tax Treatment”).\\nNOW, THEREFORE, in consideration of the premises and the mutual promises set forth herein and for other good and valuable consideration, the receipt and sufficiency of which are hereby acknowledged, the Parties, each intending to be legally bound, hereby agree as follows:\\nCERTAIN DEFINITIONS\\nSection 1.1 Definitions. As used in this Agreement, the following terms have the respective meanings set forth below.\\n“Affiliate” means, with respect to any Person, any other Person who directly or indirectly, through one or more intermediaries, controls, is controlled by, or is under common control with, such Person. The term “control” means the possession, directly or indirectly, of the power to direct or cause the direction of the management and policies of a Person, whether through the ownership of voting securities, by contract or otherwise, and the terms “controlled” and “controlling” have meanings correlative thereto.\\n“Aggregate PIPE Proceeds” means the cash proceeds to be actually received by TopCo or any of its Affiliates in respect of the PIPE Financing.\\n“Aggregate TopCo Transaction Proceeds” means an amount equal to (i) the funds contained in the Trust Account as of the First Merger Effective Time, minus (ii) all amounts, if any, payable to the Public Shareholders of Parent pursuant to the Parent Shareholder Redemption, plus (iii) the Aggregate PIPE Proceeds.\\n“Ancillary Documents” means the Investor Rights Agreement, the Framework Agreement, the Sponsor Letter Agreement, the Support Agreements, the Subscription Agreements, the Plan of Merger, the Cayman Plan of Merger and each other agreement, document, corporate resolutions, instrument or certificate contemplated by this Agreement executed or to be executed in connection with the transactions contemplated hereby.\\n“Anti-Corruption Laws” means, collectively, (a) the U.S. Foreign Corrupt Practices Act (FCPA); (b) the UK Bribery Act 2010; and (c) any other national anti-bribery or anti-corruption Laws of other third countries related to combatting bribery, corruption and money laundering.\\n“Approval Date” means the date on which the sole shareholder of TopCo approves the transactions set forth in Section 2.1.\\n“Base Exchange Value” means $1,806,000,000.\\n“Beneficially Own” and correlative terms such as “Beneficial Ownership” shall have the meaning set forth in Rule 13d-3 under the Exchange Act and shall be calculated in accordance therewith.\\n“Business Day” means a day, other than a Saturday or Sunday, on which commercial banks in New York, New York, Luxembourg, Cayman Islands and Iceland are open for the general transaction of business.\\n“CARES Act” means the Coronavirus Aid, Relief, and Economic Security Act (Pub. L. 116-136), the Families First Coronavirus Response Act of 2020 (H.R. 6201), “Division N—Additional Coronavirus Response and Relief” of the Consolidated Appropriations Act, 2021 (H.R. 133) and the American Rescue Plan Act of 2021 (Pub. L. 117-2), as applicable (including, in each case, any changes in state or local Law that are analogous to provisions of the CARES Act or adopted to conform to the CARES Act), and any legislative or regulatory guidance issued pursuant thereto.\\n“COBRA” means Part 6 of Subtitle B of Title I of ERISA, Section 4980B of the Code and any similar state Law.\\n“Code” means the United States Internal Revenue Code of 1986, as amended.\\n“Company Disclosure Schedules” means the disclosure schedules to this Agreement delivered to Parent by the Company on the date hereof.\\n“Company Expenses” means, as of any determination time, the aggregate amount of fees, expense, commissions or other amounts incurred by or on behalf of, and that are due and payable by and not otherwise expressly allocated to Parent pursuant to the terms this Agreement, any Group Company or TopCo in connection with the negotiation, preparation or execution of this Agreement or any Ancillary Documents, the performance of its covenants or agreements in this Agreement or any Ancillary Document or the consummation of the transactions contemplated hereby or thereby, including (a) the fees and expenses of outside legal counsel, accountants, advisors, brokers, investment bankers, consultants, or other agents or service providers of any Group Company or TopCo and (b) any other fees, expenses, commissions or other amounts that are expressly allocated to any Group Company or TopCo pursuant to this Agreement or any Ancillary Document.\\n“Company Fundamental Representations” means the representations and warranties set forth in Sections 3.1(a) and (b) (Organization and Qualification), 3.2(a) and (b) (Capitalization of the Group Companies), 3.3 (Authority), 3.8(a) (No Company Material Adverse Effect), 3.17 (Brokers), 4.1 (Corporate Organization), 4.2 (Authority) and 4.3 (Capitalization of TopCo).\\n“Company IT Systems” means all computer systems, computer software and hardware, communication systems, servers, network equipment and related documentation, in each case, owned, licensed or leased by a Group Company.\\n“Company Licensed Intellectual Property” means Intellectual Property Rights owned by any Person other than a Group Company that are licensed to any Group Company.\\n“Company Material Adverse Effect” means any change, event, effect or occurrence that, individually or in the aggregate with any other change, event, effect or occurrence, has had or would reasonably be expected to have a material adverse effect on (a) the business, assets and liabilities, results of operations or financial condition of the Group Companies, taken as a whole, or (b) the ability of TopCo or the Company (whether on behalf of itself or on behalf of the Company Shareholders, as applicable) to perform any of their respective covenants or obligations under this Agreement or any Ancillary Document or to consummate the transactions contemplated hereby or thereby; provided, however, that, in the case of clause (a), none of the following shall be taken into account in determining whether a Company Material Adverse Effect has occurred or is reasonably likely to occur: any adverse change, event, effect or occurrence arising after the date hereof from or related to (i) general business or economic conditions in or affecting the United States, Luxembourg or Iceland, or changes therein, or the global economy generally, (ii) any national or international political or social conditions in the United States, Luxembourg, Iceland or any other country, including the engagement by the United States, Luxembourg, Iceland or any other country in hostilities, whether or not pursuant to the declaration of a national emergency or war, or the occurrence in any place of any military or terrorist attack, sabotage or cyberterrorism, (iii) changes in conditions of the financial, banking, capital or securities markets generally in the United States, Luxembourg, Iceland or any other country or region in the world, or changes therein, including changes in interest rates in the United States, Luxembourg, Iceland or any other country and changes in exchange rates for the currencies of any countries, (iv) changes in any applicable Laws, (v) any change, event, effect or occurrence that is generally applicable to the industries or markets in which any Group Company operates, (vi) the execution or public announcement of this Agreement or the pendency or consummation of the transactions contemplated by this Agreement, including the impact thereof on the relationships, contractual or otherwise, of the Company with employees, customers, development partners, commercialization partners, investors, contractors, lenders, suppliers, vendors, partners, licensors, licensees, payors or other third parties related thereto (provided that the exception in this clause (vi) shall not apply to the representations and warranties set forth in Section 3.5 to the extent that its purpose is to address the consequences resulting from the public announcement or pendency or consummation of the transactions contemplated by this Agreement or the condition set forth in Section 7.2(a) to the extent it relates to such representations and warranties), (vii) any\\nfailure by any Group Company to meet, or changes to, any internal or published budgets, projections, forecasts, estimates or predictions (although the underlying facts and circumstances resulting in such failure may be taken into account to the extent not otherwise excluded from this definition pursuant to clauses (i) through (vi), (viii) or (ix)), (viii) any hurricane, tornado, flood, earthquake, tsunami, natural disaster, mudslides, wild fires, epidemics, pandemics or quarantines, acts of God or other natural disasters or comparable events in the United States, Luxembourg, Iceland or any other country or region in the world, or any escalation of the foregoing or (ix) pandemics (including COVID-19), epidemics and disease outbreaks, earthquakes, hurricanes, tornados, mudslides or other natural disasters (including in each case governmental action in response thereto, including COVID-19 Measures); provided, however, that any change, event, effect or occurrence resulting from a matter described in any of the foregoing clauses (i) through (v), (viii) or (ix) may be taken into account in determining whether a Company Material Adverse Effect has occurred or is reasonably likely to occur to the extent such change, event, effect or occurrence has a disproportionate adverse effect on the Group Companies, taken as a whole, relative to other participants operating in the industries or markets in which the Group Companies operate.\\n“Company Owned Intellectual Property” means all Intellectual Property Rights that are owned or purported to be owned by the Group Companies.\\n“Company Product” means each product candidate that is being researched, tested, developed or manufactured by or on behalf of the Group Companies.\\n“Company Registered Intellectual Property” means all Registered Intellectual Property owned or purported to be owned by, or filed by or in the name of any Group Company.\\n“Company Sale” means (i) any transaction or series of related transactions that results in any Person or “group” (within the meaning of Section 13(d)(3) of the Exchange Act) acquiring Equity Securities that represent more than 50% of the total voting power of TopCo or (ii) a sale or disposition of all or substantially all of the assets of TopCo and its Subsidiaries on a consolidated basis, in each case other than a transaction or series of related transactions which results in at least 50% of the combined voting power of the then outstanding voting securities of TopCo (or any successor to TopCo) immediately following the closing of such transaction (or series of related transactions) being Beneficially Owned, directly or indirectly, by individuals and entities (or Affiliates of such individuals and entities) who were the Beneficial Owners, respectively, of 50% or more of the Equity Securities of TopCo immediately prior to such transaction (or series of related transactions).\\n“Company Sale Price” means the price per share for one (1) TopCo Ordinary Share in a Company Sale, inclusive of any escrows, holdbacks or fixed deferred purchase price, but exclusive of any contingent deferred purchase price, earnouts or the like. If and to the extent the price is payable in whole or in part with consideration other than cash, the price for such non-cash consideration shall be determined as follows: (i) with respect to any securities: (A) the VWAP over a period of 21 days consisting of the day as of which such value is being determined and the 20 consecutive business days prior to such day or (B) if at any time the securities are not listed on any securities exchange or quoted on Nasdaq (or successor U.S. exchange) or the over-the-counter market, the value of each such security shall be equal to the fair value thereof as of the date of valuation as determined by an independent, internationally recognized investment banking firm on the basis of an orderly sale to a willing, unaffiliated buyer in an arm’s-length transaction, taking into account all factors determinative of value as the investment banking firm determines relevant and (ii) with respect to any other non-cash assets, the fair value thereof as of the date of valuation as determined by an independent, nationally recognized investment banking firm on the basis of an orderly sale to a willing, unaffiliated buyer in an arm’s-length transaction, taking into account all factors determinative of value as the investment banking firm determines relevant.\\n“Company Shareholders” means the holders of Company Shares as of any determination time.\\n“Company Shareholders Agreement” means the shareholders’ agreement relating to the Company dated 21 October 2020 and entered into between the Company, the Company Shareholders and Alvotech hf., as amended, restated, or supplemented from time to time and including all schedules, annexes and exhibits thereto.\\n“Company Shares” means the class A ordinary shares and the class B ordinary shares of the Company.\\n“Confidentiality Agreement” means that certain Confidentiality Agreement, dated as of April 16, 2021, by and between Oaktree Fund GP, LLC and the Company.\\n“Consent” means any notice, authorization, qualification, registration, filing, notification, waiver, order, consent or approval to be obtained from, filed with or delivered to, a Governmental Entity or other Person.\\n“Contract” means any agreement, contract, license, lease, obligation, undertaking or other commitment or arrangement that is legally binding upon a Person or any of his, her or its properties or assets, in each case, as amended, restated or supplemented from to time and including all schedules, annexes and exhibits thereto.\\n“COVID-19” means the novel coronavirus, SARS-CoV-2 or COVID-19 (and all related strains and sequences), including any intensification, resurgence or any evolutions or mutations thereof, or related or associated epidemics, pandemics, disease outbreaks or public health emergencies.\\n“COVID-19 Measures” means any quarantine, “shelter in place,” “stay at home,” workforce reduction, social distancing, shut down, closure, sequester or any other Law, Order or directive by any Governmental Entity in connection with or in response to COVID-19, including the CARES Act.\\n“Earn Out Consideration” means an aggregate of 38,330,000 TopCo Ordinary Shares.\\n“Earn Out Shares” means the Earn Out Consideration, multiplied by the percentage set forth opposite the applicable Company Shareholder’s name on the Allocation Schedule.\\n“Employee Benefit Plan” means each “employee benefit plan” (as such term is defined in Section 3(3) of ERISA, whether or not subject to ERISA), the obligation to contribute to pension funds under Icelandic act 129/1997 on the mandatory pension savings and the operation of pension funds and the relevant collective bargaining agreements, and each other benefit or compensatory plan, program, policy, arrangement or Contract that TopCo or any of its Affiliates (including any Group Company) maintains, sponsors, contributes to, or has an obligation to contribute to in which employees of any Group Company are eligible to participate or under which any employee of any Group Company is (or may become) entitled to any benefit or compensation or under or with respect to which any Group Company has or could reasonably be expected to have any Liability, other than any plan sponsored and maintained by a Governmental Entity.\\n“Environmental Laws” means all Laws and Orders concerning pollution, protection of the environment or natural resources, or human health or safety.\\n“Equity Securities” means any share, share capital, capital stock, partnership, membership, joint venture or similar interest in any Person (including any stock appreciation, phantom stock, profit participation or similar rights), and any option, warrant, right or security (including debt securities) convertible, exchangeable or exercisable therefor.\\n“ERISA” means the Employee Retirement Income Security Act of 1974, as amended.\\n“ERISA Affiliate” means any Person that, together with any Group Company, is (or at a relevant time has been or would be) treated as a single employer under Section 4001(b) of ERISA or Section 414(b), (c), (m) or (o) of the Code.\\n“Exchange Act” means the Securities Exchange Act of 1934.\\n“Exchange Consideration” means an aggregate number of TopCo Ordinary Shares equal to (a) the Exchange Value, divided by (b) the TopCo Ordinary Share Value.\\n“Exchange Value” means the Base Exchange Value, multiplied by the percentage set forth opposite the applicable Company Shareholder’s name on the Allocation Schedule.\\n“FDA” means the U.S. Food and Drug Administration.\\n“Federal Securities Laws” means U.S. federal securities laws and the rules and regulations of the SEC promulgated thereunder or otherwise.\\n“Foreign Benefit Plan” means each Employee Benefit Plan maintained by any of the Group Companies for its current or former employees, officers, directors or other individual service providers located outside of the United States.\\n“GAAP” means United States generally accepted accounting principles.\\n“Governing Documents” means the legal document(s) by which any Person (other than an individual) establishes its legal existence or which govern its internal affairs. For example, the “Governing Documents” of a U.S. corporation are its certificate or articles of incorporation and by-laws, the “Governing Documents” of a U.S. limited partnership are its limited partnership agreement and certificate of limited partnership, the “Governing Documents” of a U.S. limited liability company are its operating or limited liability company agreement and certificate of formation, the “Governing Documents” of a Luxembourg limited liability company are its articles of association (statuts), the “Governing Documents” of an Icelandic limited liability company are its articles of association (samþykktir), and the “Governing Documents” of a Cayman Islands exempted company are its amended and restated memorandum and articles of association.\\n“Governmental Entity” means any United States or non-United States (a) national, supranational, federal, state, provincial, local, municipal or other government, (b) governmental or quasi-governmental entity of any nature (including any notified body, governmental agency, branch, department, official, or entity and any court or other tribunal) or (c) body exercising or entitled to exercise any administrative, executive, judicial, legislative, police, regulatory, or taxing authority or power of any nature, including any arbitral body (public or private).\\n“Group Companies” means, collectively, the Company and its Subsidiaries.\\n“Hazardous Substance” means any material, substance or waste that is regulated by, or may give rise to standards of conduct or Liability pursuant to, any Environmental Law, including any petroleum products or byproducts, asbestos, lead, polychlorinated biphenyls, per- and poly-fluoroalkyl substances or radon.\\n“HSR Act” means the Hart-Scott-Rodino Antitrust Improvements Act of 1976, as amended, and the rules and regulations promulgated thereunder.\\n“Iceland” means the Republic of Iceland.\\n“IFRS” means International Financial Reporting Standards as promulgated by the International Standards Accounting Board.\\n“Indebtedness” means, as of any time, without duplication, with respect to any Person, all outstanding obligations (including all obligations in respect of principal, accrued interest, penalties, breakage costs, fees and premiums) of such Person arising under or in respect of (a) indebtedness for borrowed money, (b) other obligations evidenced by any note, bond, debenture or other debt security, (c) obligations for the deferred purchase price of property or assets, including “earn-outs” and “seller notes” (but excluding any trade payables arising in the ordinary course of business), (d) reimbursement and other obligations with respect to letters of credit, bank guarantees, bankers’ acceptances or other similar instruments, in each case, solely to the extent drawn, (e) leases required to be capitalized under GAAP or IFRS, as applicable, (f) derivative, hedging, swap, foreign exchange or similar arrangements, including swaps, caps, collars, hedges or similar arrangements, (g) arrangements by which such Person assured a creditor against loss, including letters of credit and bankers’ acceptances, in each case to the extent drawn upon or currently payable and not contingent, (h) unfunded pension or retirement agreements, programs, policies, or other arrangements, (i) accrued but unpaid or unfunded obligations arising from any incentive compensation, deferred compensation, severance or similar arrangements, (j) dividends declared or distributions payable and (k) any of the obligations of any other Person of the type referred to in clauses (a) through (j) above directly or indirectly guaranteed by such Person or secured by any assets of such Person, whether or not such Indebtedness has been assumed by such Person.\\n“Initial Shares” means the 4,000,000 shares issued at incorporation of TopCo and held by Floki Holdings.\\n“Intellectual Property Rights” means all intellectual property rights and related priority rights protected, created or arising under the Laws of the United States or any other jurisdiction or under any international convention, including all (a) patents and patent applications, industrial designs and design patent rights, including any continuations, divisionals, continuations-in-part and provisional applications and statutory invention registrations, and any patents issuing on any of the foregoing and any reissues, reexaminations, substitutes, supplementary protection certificates, extensions of any of the foregoing (collectively, “Patents”); (b) trademarks, service marks, trade names, service names, brand names, trade dress rights, logos, Internet domain names, corporate names and other source or business identifiers, together with the goodwill associated with any of the foregoing, and all applications, registrations, extensions and renewals of any of the foregoing (collectively, “Marks”); (c) copyrights and works of authorship, database and design rights, mask work rights and moral rights, whether or not registered or published, and all registrations, applications, renewals, extensions and reversions of any of any of the foregoing (collectively, “Copyrights”); (d) trade secrets, know-how and confidential and proprietary information, including invention disclosures, inventions and formulae, whether patentable or not; (e) rights in or to Software or other technology; and (f) any other intellectual or proprietary rights protectable, arising under or associated with any of the foregoing, including those protected by any Law anywhere in the world.\\n“Investment Company Act” means the Investment Company Act of 1940.\\n“JOBS Act” means the Jumpstart Our Business Startups Act of 2012.\\n“Law” means any federal, state, provincial, local, foreign, national or supranational statute, law (including common law), act, statute, ordinance, treaty, rule, code, regulation or other binding directive or guidance issued, promulgated or enforced by a Governmental Entity having jurisdiction over a given matter.\\n“Liability” means any and all debts, liabilities and obligations, whether accrued or fixed, absolute or contingent, known or unknown, matured or unmatured or determined or determinable, including those arising under any Law (including any Environmental Law), Proceeding or Order and those arising under any Contract, agreement, arrangement, commitment or undertaking.\\n“Lien” means any mortgage, pledge, security interest, encumbrance, lien, license or sub-license, charge, or other similar encumbrance or interest (including, in the case of any Equity Securities, any voting, transfer or similar restrictions).\\n“Luxembourg” means the Grand Duchy of Luxembourg.\\n“Mergers” means, collectively, the First Merger and the Second Merger.\\n“Multiemployer Plan” has the meaning set forth in Section 3(37) or Section 4001(a)(3) of ERISA.\\n“Nasdaq” means the Nasdaq Stock Market.\\n“Nasdaq First North” means the Nasdaq First North Growth Market.\\n“NYSE” means the New York Stock Exchange.\\n“Off-the-Shelf Software” means any Software that is made generally and widely available to the public on a commercial basis and is licensed to the any of the Group Companies on a non-exclusive basis under standard terms and conditions for a one-time license fee of less than $100,000 per license, or an ongoing licensee fee of less than $50,000 per year.\\n“Order” means any outstanding writ, order, judgment, injunction, decision, determination, award, ruling, subpoena, verdict or decree entered, issued or rendered by any Governmental Entity.\\n“Other Parent Shareholder Approval” means the approval, at the Parent Shareholders Meeting where a quorum is present, in the case of each Transaction Proposal (other than the Business Combination Proposal and the Merger Proposal), by an ordinary resolution in accordance with Parent’s Governing Documents requiring the affirmative vote of at least a majority of the votes cast by the holders of the issued Parent Shares present in person or represented by proxy at the Parent Shareholders Meeting and entitled to vote on such matter.\\n“Parent Class A Shares” means Parent’s Class A ordinary shares of $0.0001 par value each.\\n“Parent Class B Shares” means Parent’s Class B ordinary shares of $0.0001 par value each.\\n“Parent Disclosure Schedules” means the disclosure schedules to this Agreement delivered to the Company by Parent on the date hereof.\\n“Parent Expenses” means, as of any determination time, the aggregate amount of fees, expense, commissions or other amounts incurred by or on behalf of, and that are due and payable by and not otherwise expressly allocated to the Company pursuant to the terms of this Agreement, Parent in connection with the negotiation, preparation or execution of this Agreement or any Ancillary Documents, the\\nperformance of its covenants or agreements in this Agreement or any Ancillary Document or the consummation of the transactions contemplated hereby or thereby, including (a) the fees and expenses of outside legal counsel, accountants, advisors, brokers, investment bankers, consultants, or other agents or service providers of Parent and (b) any other fees, expenses, commissions or other amounts that are expressly allocated to Parent pursuant to this Agreement or any Ancillary Document. For the avoidance of doubt, Parent Expenses shall not include any Company Expenses.\\n“Parent Financial Statements” means all of the financial statements of Parent included in the Parent SEC Reports.\\n“Parent Fundamental Representations” means the representations and warranties set forth in Sections 5.1 (Organization and Qualification), 5.2 (Authority), 5.4 (Brokers) and 5.6(a) (Capitalization of the Parent).\\n“Parent Material Adverse Effect” means any change, event, effect or occurrence that, individually or in the aggregate with any other change, event, effect or occurrence, has had or would reasonably be expected to have a material adverse effect on (a) the business, assets and liabilities, results of operations or financial condition of Parent or (b) the ability of Parent to perform any of its covenants or obligations under this Agreement or any Ancillary Document or to consummate the transactions contemplated hereby or thereby.\\n“Parent Shareholder Approval” means, collectively, the Required Parent Shareholder Approval and the Other Parent Shareholder Approval.\\n“Parent Shareholder Redemption” means the right of the holders of Parent Class A Shares to redeem all or a portion of their Parent Class A Shares (in connection with the transactions contemplated by this Agreement or otherwise) as set forth in Governing Documents of Parent.\\n“Parent Shares” means, collectively, the Parent Class A Shares and the Parent Class B Shares.\\n“Parent Warrants” means each warrant to purchase one Parent Class A Share at a price of $11.50 per share, subject to adjustment in accordance with the Warrant Agreement.\\n“PCAOB” means the Public Company Accounting Oversight Board.\\n“Permits” means any approvals, authorizations, clearances, licenses, registrations, permits or certificates of a Governmental Entity.\\n“Permitted Liens” means (a) mechanic’s, materialmen’s, carriers’, repairers’ and other similar statutory Liens arising or incurred in the ordinary course of business for amounts that are not yet delinquent or are being contested in good faith by appropriate proceedings and for which sufficient reserves have been established in accordance with IFRS or GAAP, as applicable, (b) Liens for Taxes, assessments or other governmental charges not yet due and delinquent as of the Closing Date or which are being contested in good faith by appropriate proceedings and for which sufficient reserves have been established in accordance with IFRS or GAAP, as applicable, (c) encumbrances and restrictions on real property (including easements, covenants, conditions, rights of way and similar restrictions) that do not prohibit or materially interfere with any of the Group Companies’ use or occupancy of such real property, (d) zoning, building codes and other land use Laws regulating the use or occupancy of real property or the activities conducted thereon which are imposed by any Governmental Entity having jurisdiction over such real property and which are not violated by the use or occupancy of such real property or the operation of the businesses of the Group Company and do not prohibit or materially interfere with any of the Group Companies’ use or\\noccupancy of such real property, (e) cash deposits or cash pledges to secure the payment of workers’ compensation, unemployment insurance, social security benefits or obligations arising under similar Laws, or to secure the performance of public or statutory obligations, surety or appeal bonds, and other obligations of a like nature, in each case in the ordinary course of business and which are not yet due and payable, (f) non-exclusive licenses of non-material Intellectual Property in the ordinary course of business consistent with past practice and (g) other Liens that do not materially and adversely affect the value, use or operation of the asset subject thereto.\\n“Person” means an individual, partnership, corporation, limited liability company, joint stock company, unincorporated organization or association, trust, joint venture or other similar entity, whether or not a legal entity.\\n“Personal Data” means any data or information relating to an identified or identifiable natural person.\\n“Pre-Closing Equity Financing” means Pre-Closing Financing received by the Company or any of its Subsidiaries following the date hereof and prior to the Closing pursuant to any equity financing transaction whereby any equity securities (which shall not include any debt securities convertible into or exercisable for equity securities unless such convertible debt securities are so converted in full prior to the Redemption Deadline) of the Company or any of its Subsidiaries has been issued in exchange for cash consideration; provided, that (i) to the extent that any Person providing Pre-Closing Equity Financing is not an existing Company Shareholder and party to the Framework Agreement and the Company Shareholders Agreement, such Person shall, as a condition, and prior, to providing the Pre-Closing Equity Financing, deliver a deed of adherence agreeing to be bound by the Framework Agreement, a Support Agreement on terms consistent with those executed and delivered on the date hereof and any other agreements entered into by the Company Shareholders in connection with the transactions contemplated by this Agreement, in each case, in form and substance reasonably acceptable to Parent and (ii) all transactions related to the Pre-Closing Equity Financing shall be consummated prior to the Redemption Deadline. For the avoidance of doubt, no Pre-Closing Equity Financing shall have any effect on the Base Exchange Value.\\n“Pre-Closing Financing” means the aggregate proceeds received by the Company following the date hereof and prior to the Closing pursuant to any equity or debt financing transaction entered into by the Company on arms-length terms which are reasonably acceptable to Parent, in order to fund the capital needs of the Company and its Subsidiaries in the ordinary course of business (including any Pre-Closing Equity Financing); provided, that any such debt financing transactions shall not exceed, in the aggregate, a principle amount of indebtedness in excess of $50,000,000 without the prior written consent of Parent (such consent not to be unreasonably withheld, conditioned or delayed).\\n“Pre-Closing Parent Holders” means the holders of Parent Shares at any time prior to the First Merger Effective Time, as applicable.\\n“Privacy Laws” means Laws in any jurisdiction relating to the Processing or protection of Personal Data, including the European Union General Data Protection Regulation 2016/679, the e-Privacy Directive (2002/58/EC) and any predecessor, successor or implementing legislation of the foregoing, and any amendments or re-enactments of any of the foregoing.\\n“Proceeding” means any lawsuit, litigation, action, audit, examination, investigation, inquiry, claim, complaint, charge, proceeding, suit or arbitration (in each case, whether civil, criminal or administrative and whether public or private) pending by or before or otherwise involving any Governmental Entity.\\n“Process” (or “Processing” or “Processes”) means the collection, use, storage, processing, recording, distribution, transfer, import, export, protection (including security measures), disposal or disclosure or other activity regarding data (whether electronically or in any other form or medium).\\n“Public Health Laws” means all applicable Laws relating to the development, non-clinical testing, clinical testing, manufacture, production, authorization, analysis, distribution, importation, exportation, use, handling, quality, sale or promotion of any drug, biologic or medical device, placebo, or other article (including any ingredient or component of the foregoing products) subject to regulation under the Federal Food, Drug, and Cosmetic Act (21 U.S.C. § 301 et seq.) or similar federal, state, or foreign pharmaceutical Laws, advanced therapy medicinal product Laws, medical devices Laws, Laws on the collection and processing of blood, blood components, tissues or cells, genetically engineered products Laws, infection protocol Laws and clinical investigation Laws.\\n“Real Property Leases” means all leases, sub-leases, licenses or other agreements, in each case, pursuant to which any Group Company leases or sub-leases any real property.\\n“Redemption Deadline” means the last date on which the holders of Parent Class A Shares are permitted to submit an election to redeem all or a portion of their Parent Class A Shares in connection with the transactions contemplated by this Agreement as set forth in Governing Documents of Parent.\\n“Registered Intellectual Property” means all issued Patents, pending Patent applications, registered Marks, pending applications for registration of Marks, registered Copyrights, pending applications for registration of Copyrights and Internet domain name registrations.\\n“Registration Statement / Proxy Statement” means a registration statement on Form F-4 relating to the transactions contemplated by this Agreement and the Ancillary Documents and containing a proxy statement of Parent.\\n“Regulatory Permits” means all Permits granted by FDA or any comparable Governmental Entity or supranational entity or an institutional review board or independent ethics committee to any Group Company, including investigational new drug applications, biologics license applications, new drug applications, orphan drug designations, abbreviated new drug applications, device premarket approval applications, device premarket notifications, investigational device exemptions, product recertifications, manufacturing approvals and authorizations, CE Certificates of Conformity, CE Declarations of Conformity, authorization of tissue establishment, and tissue and cell preparation processes, clinical trial authorizations and ethical reviews, scientific opinions for advanced therapy medicinal product, scientific advice, genetic engineering authorizations, infection protection authorizations or their national or foreign equivalents.\\n“Representatives” means, with respect to any Person, such Person’s Affiliates and its and such Affiliates’ respective directors, officers, employees, members, owners, accountants, consultants, advisors, attorneys, agents and other authorized representatives.\\n“Required Parent Shareholder Approval” means the approval, at the Parent Shareholders Meeting where a quorum is present, (a) in the case of the Business Combination Proposal, by an ordinary resolution in accordance with Parent’s Governing Documents requiring the affirmative vote of at least a majority of the votes cast by the holders of the issued Parent Shares present in person or represented by proxy at the Parent Shareholders Meeting and entitled to vote on such matter, and (b) in the case of the Merger Proposal, by a special resolution in accordance with Parent’s Governing Documents requiring the affirmative vote of at least a two-thirds (2/3) majority of the votes cast by the holders of the issued Parent Shares present in person or represented by proxy at the Parent Shareholders Meeting and entitled to vote on such matter.\\n“RESA” means the Recueil Electronique des Sociétés et Associations (the Luxembourg official gazette).\\n“Sanctions and Export Control Laws” means any Law in any part of the world related to (a) import and export controls, including the U.S. Export Administration Regulations, or (b) economic sanctions, including those administered by the Office of Foreign Assets Control of the U.S. Department of the Treasury, the U.S. Department of State, the European Union, any European Union Member State, the United Nations, and Her Majesty’s Treasury of the United Kingdom.\\n“Sarbanes-Oxley Act” means the Sarbanes-Oxley Act of 2002.\\n“Schedules” means, collectively, the Company Disclosure Schedules and the Parent Disclosure Schedules.\\n“SEC” means the U.S. Securities and Exchange Commission.\\n“Securities Act” means the U.S. Securities Act of 1933.\\n“Securities Laws” means Federal Securities Laws and other applicable foreign and domestic securities or similar Laws.\\n“Software” shall mean any and all (a) computer programs, including any and all software implementations of algorithms, models and methodologies, whether in source code or object code; (b) software as a medical device; (c) databases and compilations, including any and all data and collections of data, whether machine readable or otherwise; (d) descriptions, flowcharts and other work product used to design, plan, organize and develop any of the foregoing, screens, user interfaces, report formats, firmware, development tools, templates, menus, buttons and icons; and (e) all documentation, including user manuals and other training documentation related to any of the foregoing.\\n“Subsidiary” means, with respect to any Person, any corporation, limited liability company, partnership or other legal entity of which (a) if a corporation (including a German GmbH), a majority of the total voting power of shares of stock entitled (without regard to the occurrence of any contingency) to vote in the election of directors, managers or trustees thereof is at the time owned or controlled, directly or indirectly, by such Person or one or more of the other Subsidiaries of such Person or a combination thereof, or (b) if a limited liability company, partnership, association or other business entity (other than a corporation), a majority of the partnership or other similar ownership interests thereof is at the time owned or controlled, directly or indirectly, by such Person or one or more Subsidiaries of such Person or a combination thereof and for this purpose, a Person or Persons own a majority ownership interest in such a business entity (other than a corporation) if such Person or Persons shall be allocated a majority of such business entity’s gains or losses or shall be a, or control any, managing director or general partner of such business entity (other than a corporation). The term “Subsidiary” shall include all Subsidiaries of such Subsidiary.\\n“Tax” means (i) any federal, state, local or non-United States income, gross receipts, franchise, estimated, alternative minimum, sales, use, transfer, value added, excise, stamp, customs, duties, ad valorem, real property, personal property (tangible and intangible), capital stock, social security, unemployment, payroll, wage, employment, severance, occupation, registration, environmental, communication, mortgage, profits, license, lease, service, goods and services, withholding, premium, unclaimed property, escheat, turnover, windfall profits or other taxes of any kind whatever, together with any interest, deficiencies, penalties, additions to tax, or additional amounts payable with respect thereto, whether disputed or not, (ii) any Liability for or in respect of the payment of any amount of a type described in clause (i) of this definition as a result of being a member of an affiliated, combined, consolidated, unitary or other group for Tax purposes, and (iii) any Liability for or in respect of the payment of any amount described in clauses (i) or (ii) of this definition as a transferee or successor, by contract or otherwise.\\n“Tax Authority” means any Governmental Entity responsible for the collection or administration of Taxes or Tax Returns.\\n“Tax Return” means returns, information returns, statements, declarations, claims for refund, schedules, notices, forms, attachments and reports relating to Taxes filed or required to be filed with any Governmental Entity or Tax Authority.\\n“TopCo Ordinary Share” means an ordinary share in the share capital of TopCo.\\n“TopCo Ordinary Share Price” means the closing sale price per share of TopCo Ordinary Shares on Nasdaq (or successor U.S. exchange) reported as of 4:00 p.m., New York, New York time on such date by Bloomberg, or if not available on Bloomberg, as reported by Morningstar.\\n“TopCo Ordinary Share Value” means $10.00.\\n“TopCo Warrant” means each warrant to purchase one TopCo Ordinary Share at a price of $11.50, subject to adjustment.\\n“Unpaid Company Expenses” means the Company Expenses that are unpaid as of immediately prior to the Closing.\\n“Unpaid Parent Expenses” means the Parent Expenses that are unpaid as of immediately prior to the Closing.\\n“VWAP” means the volume weighted average price of TopCo Ordinary Shares or Parent Share, as applicable, as defined by the industry standard.\\n“WARN” means the Worker Adjustment Retraining and Notification Act of 1988, as amended, as well as any analogous foreign, state, provincial or local Laws.\\n“Warrant Agreement” means the Warrant Agreement, dated as of September 21, 2020, between Parent and the Trustee.\\nSection 1.2 Certain Defined Terms. Each of the following terms is defined in the Section set forth opposite such term:\\nTerm Section\\nAcquisition Proposal\\nSection 6.6(a)\\nAdditional Parent SEC Reports\\nAdditional PIPE Financing\\nSection 6.2(d)\\nAllocation Schedule\\nBusiness Combination Proposal\\nSection 2.6(b)\\nCayman Islands Act\\nSection 2.1(b)(ii)\\nCayman Merger Documents\\nSection 2.1(b)(i)\\nSection 3.7(a)(xii)\\nChange in Recommendation\\nClosing Filing\\nClosing Press Release\\nCompany Designee\\nSection 6.15(c)\\nConverted Warrant\\nSection 3.13(d)\\nD&O Persons\\nSection 6.14(a)\\nSection 2.1(f)(vi)\\nFirst Merger\\nFirst Merger Consideration\\nSection 2.1(b)(vi)\\nFirst Merger Documents\\nFirst Merger Effective Time\\nFirst Merger Shareholder Resolution\\nFirst Surviving Company\\nFramework Agreement\\nSection 6.18(f)\\nIntended U.S. Tax Treatment\\nInvestor Rights Agreement\\nIRA Company Shareholders\\nLatest Balance Sheet\\nLeased Real Property\\nSection 3.18(b)\\nLuxembourg Merger Documents\\nMaterial Contracts\\nMaterial Partner\\nMaterial Permits\\nMerger Proposal\\nParent Acquisition Proposal\\nParent Board\\nParent Board Recommendation\\nParent Designee\\nParent Related Parties\\nParent Related Party Transactions\\nParent SEC Reports\\nParent Shareholders Meeting\\nPIPE Financing\\nPIPE Financing Amount\\nPost-Signing Company Financial Statements\\nPrivacy and Data Security Policies\\nPublic Shareholders\\nRelated Proceeding\\nSecond Merger\\nSecond Merger Documents\\nSection 2.1(f)(i)\\nSecond Merger Effective Time\\nSecond Merger Surviving Company\\nSection 2.1(f)(ii)\\nSigning Filing\\nSigning Press Release\\nSponsor Letter Agreement\\nSponsor Shares\\nSponsor Warrants\\nSubscription Agreements\\nTermination Date\\nSection 8.1(e)\\nTopCo\\nTopCo Board\\nTopCo Incentive Equity Plan\\nTransaction Proposals\\nTransition Services Agreement\\nTrust Account Released Claims\\nTrust Agreement\\nWarrant Assumption Agreement\\nSection 2.1 Closing Transactions. On the terms and subject to the conditions set forth in this Agreement, the following transactions shall occur in the order of the subsections in this Section 2.1:\\n(a) Election. On the Closing Date, TopCo shall file an election with the Internal Revenue Service on Internal Revenue Service Form 8832 pursuant to Treasury Regulations Section ###-###-####-3(c), substantially in the form attached hereto as Exhibit B and effective as of the date of the First Merger Effective Time, to be classified as an association taxable as a corporation for U.S. federal income tax purposes.\\n(b) First Merger.\\n(i) At least one month prior to the Approval Date, Parent and TopCo shall cause draft terms of merger, in substantially the form attached hereto as Exhibit C (with such modifications, amendments or supplements thereto as may be required to comply with the Cayman Islands Act and the Luxembourg Company Law, the “Plan of Merger”), along with all other documentation and declarations required under the Luxembourg Company Law in connection with the First Merger, to be duly executed and properly filed with the RCS and published on the RESA, in accordance with the relevant provisions of the Luxembourg Company Law (together, the “Luxembourg Merger Documents”). The First Merger will be approved by TopCo through the First Merger Shareholder Resolution on the Approval Date but the First Merger Shareholder Resolution shall only become effective seven (7) Business Days after the Approval Date following its prior publication in the RESA and subject to (i) the execution of a plan of merger in substantially the form attached hereto as Exhibit G by each of TopCo and Parent (with such modifications, amendments or supplements thereto as may be required to comply with the Cayman Islands Act and the Luxembourg Company Law or otherwise agreed between TopCo and Parent, the “Cayman Plan of Merger”) and the registration of such Cayman Plan of Merger and the filing of the other documents required under the Cayman Islands Act with the Registrar of Companies of the Cayman Islands in accordance with the applicable provisions of the Companies Act (such other documents, together with the Plan of Merger, the “Cayman Merger Documents” and together with the Luxembourg Merger Documents, the “First Merger Documents”) on such date (the time the First Merger becomes effective being referred to herein as the “First Merger Effective Time”), (ii) the delivery, on such date, by Parent to TopCo of (x) a legal opinion from Walkers (Cayman) LLP (in a form reasonably acceptable to TopCo and the Company) regarding the completion of the steps required under the Cayman Islands Act to consummate the First Merger and (y) a certificate evidencing the registration of the Cayman Plan of Merger with the Registrar of Companies of the Cayman Islands as soon as possible after the First Merger Effective Time (it being understood that delivery of such certificate shall not be a condition precedent to the First Merger Effective Time).\\n(ii) In accordance with the Companies Act (as amended) of the Cayman Islands (the “Cayman Islands Act”) and the Luxembourg law of 10 August 1915 on commercial companies, as amended (the “Luxembourg Company Law”), (A) on the Approval Date, the sole shareholder of TopCo shall pass a shareholder resolution in front of a Luxembourg notary (the “First Merger Shareholder Resolution”) to approve, the First Merger (including the Plan of Merger and the Luxembourg Merger Documents) and the resulting increase in the capital of TopCo and, (B) at the First Merger Effective Time, Parent shall merge with and into TopCo. Following the First Merger Effective Time, the separate existence of Parent shall cease and TopCo shall continue as the surviving entity of the First Merger (the “First Surviving Company”) and shall succeed to and assume all the rights and obligations of Parent in accordance with the Cayman Islands Act and the Luxembourg Company Law.\\n(iii) The First Merger shall have the effects as provided in this Agreement, in the First Merger Documents and in the applicable provisions of the Cayman Islands Act and the Luxembourg Company Law. Without limiting the generality of the foregoing, and subject thereto, at the First Merger Effective Time, all of the assets, properties, rights, privileges, immunities, powers and franchises of Parent shall vest in the First Surviving Company and all debts, liabilities and duties of Parent shall become the debts, liabilities, obligations and duties of the First Surviving Company.\\n(iv) At the First Merger Effective Time, the Governing Documents of TopCo as amended pursuant to the First Merger Documents shall be the Governing Documents of the First Surviving Company, in each case, until thereafter changed or amended as provided therein or by applicable Law.\\n(v) At the First Merger Effective Time, the sole chairman (président) of TopCo immediately prior to the First Merger Effective Time shall remain the sole chairman (president) of the First Surviving Company, to hold office in accordance with the Governing Documents of First Surviving Company.\\n(vi) At the First Merger Effective Time, by virtue of the First Merger and without any action on the part of any Party or any other Person, each Parent Share (other than such shares cancelled pursuant to Section 2.1(b)(vii)) issued and outstanding as of immediately prior to the First Merger Effective Time shall be automatically cancelled and extinguished and exchanged for one ordinary share of First Surviving Company (the “First Merger Consideration”). From and after the First Merger Effective Time, all outstanding Parent Shares shall automatically cease to exist, and such Person that, immediately prior to the First Merger Effective Time, was registered as a holder of the Parent Shares in the register of members of Parent shall thereafter cease to be a member of Parent and shall cease to have any rights with respect to such shares except as otherwise provided for herein or under applicable Law.\\n(vii) At the First Merger Effective Time, by virtue of the First Merger and without any action on the part of any Party or any other Person, each Parent Share held immediately prior to the First Merger Effective Time by Parent as treasury shares shall be cancelled and surrendered (as applicable), and no consideration shall be paid with respect thereto.\\n(viii) If after the date hereof and prior to the First Merger Effective Time Parent pays a share dividend in, sub-divides, consolidates into a smaller number of shares, or issues by reclassification, any Parent Shares, then the First Merger Consideration will be appropriately adjusted to provide to the holders of the Parent Shares the same economic effect as contemplated by this Agreement prior to such action, and as so adjusted will, from and after the date of such event, be the First Merger Consideration, subject to further adjustment in accordance with this provision.\\n(c) Redemption. On the Approval Date, TopCo will resolve to redeem and cancel the shares held by its initial sole shareholder and proceed with a reduction of its share capital for an amount equal to the nominal value of these redeemed shares, such Redemption becoming effective immediately after the First Mer111111111111 the11111111111111111'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = dataset[0]\n",
    "output = generate(model, input_ids=torch.tensor(input['input_ids']).to(device).unsqueeze(0),\n",
    "                        attention_mask=torch.tensor(input['attention_mask']).to(device).unsqueeze(0),\n",
    "                        max_tokens=30)\n",
    "tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = model.generate(input_ids=torch.tensor(input['input_ids']).to(device).unsqueeze(0), \n",
    "                        attention_mask=torch.tensor(input['attention_mask']).to(device).unsqueeze(0), \n",
    "                        max_new_tokens=200, \n",
    "                        do_sample=True)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, val_size=.9):\n",
    "    index = int(len(dataset) * val_size)\n",
    "    return dataset.select(range(index)), dataset.select(range(index, len(dataset)))\n",
    "\n",
    "train_dataset, val_dataset = split_dataset(dataset)\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lora fine tunining\n",
    "lora_r_default = 8\n",
    "lora_alpha_default = 32\n",
    "lora_dropout_default = 0.05\n",
    "lora_config = LoraConfig(\n",
    "        r=lora_r_default, #dimention of the low-rank matrices\n",
    "        lora_alpha=lora_alpha_default, # scaling factor for the weight matrices\n",
    "        lora_dropout=lora_dropout_default, # dropout probability of the LoRA layers\n",
    "        bias=\"none\", # set to all to train all bias parameters\n",
    "        task_type=\"CAUSAL_LM\",  # casual language modeling\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\"] # the layer within a neural networkk to which LoRA reg will be applied\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,718,592 || all params: 7,246,450,688 || trainable%: 0.0651159057469874\n"
     ]
    }
   ],
   "source": [
    "model.enable_input_require_grads()\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity_info()\n",
    "\n",
    "args_output_dir = \"models/test_tbd\"\n",
    "args_max_steps = 1000\n",
    "args_eval_freq_default = 100\n",
    "args_log_freq_default = 1\n",
    "args_save_freq_default = 100\n",
    "args_batch_size = 1\n",
    "args_learning_rate = 1e-4\n",
    "args_lr_scheduler_type=\"linear\"\n",
    "args_num_warmup_steps = 30\n",
    "args_gradient_accumulation_steps_default = 32\n",
    "args_weight_decay = 0.05\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=args_output_dir,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        load_best_model_at_end=True,\n",
    "        max_steps=args_max_steps,\n",
    "        eval_steps=args_eval_freq_default,\n",
    "        save_steps=args_save_freq_default,\n",
    "        logging_steps=args_log_freq_default,\n",
    "        per_device_train_batch_size=args_batch_size,\n",
    "        per_device_eval_batch_size=args_batch_size,\n",
    "        learning_rate=args_learning_rate,\n",
    "        lr_scheduler_type=args_lr_scheduler_type,\n",
    "        warmup_steps=args_num_warmup_steps,\n",
    "        gradient_accumulation_steps=args_gradient_accumulation_steps_default,\n",
    "        gradient_checkpointing=True,\n",
    "        fp16=True,\n",
    "        weight_decay=args_weight_decay,\n",
    "        #push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets['train'],\n",
    "    eval_dataset=datasets['val'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: raw_content. If raw_content are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 26,999\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 32\n",
      "  Total optimization steps = 1,000\n",
      "  Number of trainable parameters = 4,718,592\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwen-cheng\u001b[0m (\u001b[33mesperanto-tech\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/datascience1/Adrien/Context_Extension/wandb/run-20231201_104834-kilfxv74</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/esperanto-tech/huggingface/runs/kilfxv74' target=\"_blank\">apricot-plant-309</a></strong> to <a href='https://wandb.ai/esperanto-tech/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/esperanto-tech/huggingface' target=\"_blank\">https://wandb.ai/esperanto-tech/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/esperanto-tech/huggingface/runs/kilfxv74' target=\"_blank\">https://wandb.ai/esperanto-tech/huggingface/runs/kilfxv74</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/datascience1/Adrien/Context_Extension/Context_Extension.ipynb Cell 71\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22474230332d6574227d/mnt/datascience1/Adrien/Context_Extension/Context_Extension.ipynb#Y131sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/context_extension/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1556\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   1557\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1558\u001b[0m         trial\u001b[39m=\u001b[39mtrial,\n\u001b[1;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1560\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/context_extension/lib/python3.11/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1862\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/context_extension/lib/python3.11/site-packages/transformers/trainer.py:2734\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2732\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2733\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2734\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mbackward(loss)\n\u001b[1;32m   2736\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/miniconda3/envs/context_extension/lib/python3.11/site-packages/accelerate/accelerator.py:1987\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1985\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1987\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1989\u001b[0m     loss\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/context_extension/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/context_extension/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(args_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, Trainer, TrainingArguments, logging\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "from scipy.stats import expon\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d0a12c775e4bae8bfd661e6b36635d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "checkpoint = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "config.update({'_flash_attn_2_enabled' : True})  #Flash Attention\n",
    "#config.update({'sliding_window' : 15_000})  #eliminating sliding window\n",
    "config.update({'rope_scaling' : {\"type\": \"linear\",\n",
    "                                 \"factor\": 8192/16400,\n",
    "                                }})             #Position Interpolation\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast = False, revision = 'main', config = config,)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
    "                                             low_cpu_mem_usage = True,\n",
    "                                             torch_dtype = torch.float16,\n",
    "                                             revision='main',\n",
    "                                             device_map='auto',\n",
    "                                             #load_in_8bit=True,\n",
    "                                             config = config,\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lora = \"models/Mistral-7B-Instruct-v0.1-LC16k-PI/checkpoint-100/\"\n",
    "model.load_adapter(checkpoint_lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3411])\n",
      "This paper presents OLID: a novel annotated dataset of offensive language with labels for annotation of offensive language type and target. The dataset is made available as an annotated collection of text. Experiments include using SVMs and neural networks. The dataset was designed in collaboration with the Google News and People Search Team, with funding from the European Research Council under Grant Agreement no. 295622.\n",
      "Aggression identification. J. Q. Taylor,\n"
     ]
    }
   ],
   "source": [
    "inst = \"\"\"\\Below is a very long document, provide a very short summary to get a high level overview of what is stated.\\n\"\"\"\n",
    "input = tokenizer(inst + document + \"\\nSummary:\", return_tensors='pt').to(device)\n",
    "print(input['input_ids'].shape)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**input, max_new_tokens=100, do_sample=True)\n",
    "    print(tokenizer.decode(output[0, input['input_ids'].shape[1]:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"Introduction\\nOffensive content has become pervasive in social media and a reason of concern for government organizations, online communities, and social media platforms. One of the most common strategies to tackle the problem is to train systems capable of recognizing offensive content, which then can be deleted or set aside for human moderation. In the last few years, there have been several studies published on the application of computational methods to deal with this problem. Most prior work focuses on a different aspect of offensive language such as abusive language BIBREF0 , BIBREF1 , (cyber-)aggression BIBREF2 , (cyber-)bullying BIBREF3 , BIBREF4 , toxic comments INLINEFORM0 , hate speech BIBREF5 , BIBREF6 , BIBREF7 , BIBREF8 , BIBREF9 , BIBREF10 , and offensive language BIBREF11 . Prior work has focused on these aspects of offensive language in Twitter BIBREF3 , BIBREF7 , BIBREF8 , BIBREF11 , Wikipedia comments, and Facebook posts BIBREF2 .\\nRecently, Waseem et. al. ( BIBREF12 ) acknowledged the similarities among prior work and discussed the need for a typology that differentiates between whether the (abusive) language is directed towards a specific individual or entity or towards a generalized group and whether the abusive content is explicit or implicit. Wiegand et al. ( BIBREF11 ) followed this trend as well on German tweets. In their evaluation, they have a task to detect offensive vs not offensive tweets and a second task for distinguishing between the offensive tweets as profanity, insult, or abuse. However, no prior work has explored the target of the offensive language, which is important in many scenarios, e.g., when studying hate speech with respect to a specific target.\\nTherefore, we expand on these ideas by proposing a a hierarchical three-level annotation model that encompasses:\\nUsing this annotation model, we create a new large publicly available dataset of English tweets. The key contributions of this paper are as follows:\\nRelated Work\\nDifferent abusive and offense language identification sub-tasks have been explored in the past few years including aggression identification, bullying detection, hate speech, toxic comments, and offensive language.\\nAggression identification: The TRAC shared task on Aggression Identification BIBREF2 provided participants with a dataset containing 15,000 annotated Facebook posts and comments in English and Hindi for training and validation. For testing, two different sets, one from Facebook and one from Twitter were provided. Systems were trained to discriminate between three classes: non-aggressive, covertly aggressive, and overtly aggressive.\\nBullying detection: Several studies have been published on bullying detection. One of them is the one by xu2012learning which apply sentiment analysis to detect bullying in tweets. xu2012learning use topic models to to identify relevant topics in bullying. Another related study is the one by dadvar2013improving which use user-related features such as the frequency of profanity in previous messages to improve bullying detection.\\nHate speech identification: It is perhaps the most widespread abusive language detection sub-task. There have been several studies published on this sub-task such as kwok2013locate and djuric2015hate who build a binary classifier to distinguish between `clean' comments and comments containing hate speech and profanity. More recently, Davidson et al. davidson2017automated presented the hate speech detection dataset containing over 24,000 English tweets labeled as non offensive, hate speech, and profanity.\\nOffensive language: The GermEval BIBREF11 shared task focused on Offensive language identification in German tweets. A dataset of over 8,500 annotated tweets was provided for a course-grained binary classification task in which systems were trained to discriminate between offensive and non-offensive tweets and a second task where the organizers broke down the offensive class into three classes: profanity, insult, and abuse.\\nToxic comments: The Toxic Comment Classification Challenge was an open competition at Kaggle which provided participants with comments from Wikipedia labeled in six classes: toxic, severe toxic, obscene, threat, insult, identity hate.\\nWhile each of these sub-tasks tackle a particular type of abuse or offense, they share similar properties and the hierarchical annotation model proposed in this paper aims to capture this. Considering that, for example, an insult targeted at an individual is commonly known as cyberbulling and that insults targeted at a group are known as hate speech, we pose that OLID's hierarchical annotation model makes it a useful resource for various offensive language identification sub-tasks.\\nHierarchically Modelling Offensive Content\\nIn the OLID dataset, we use a hierarchical annotation model split into three levels to distinguish between whether language is offensive or not (A), and type (B) and target (C) of the offensive language. Each level is described in more detail in the following subsections and examples are shown in Table TABREF10 .\\nLevel A: Offensive language Detection\\nLevel A discriminates between offensive (OFF) and non-offensive (NOT) tweets.\\nNot Offensive (NOT): Posts that do not contain offense or profanity;\\nOffensive (OFF): We label a post as offensive if it contains any form of non-acceptable language (profanity) or a targeted offense, which can be veiled or direct. This category includes insults, threats, and posts containing profane language or swear words.\\nLevel B: Categorization of Offensive Language\\nLevel B categorizes the type of offense and two labels are used: targeted (TIN) and untargeted (INT) insults and threats.\\nTargeted Insult (TIN): Posts which contain an insult/threat to an individual, group, or others (see next layer);\\nUntargeted (UNT): Posts containing non-targeted profanity and swearing. Posts with general profanity are not targeted, but they contain non-acceptable language.\\nLevel C: Offensive Language Target Identification\\nLevel C categorizes the targets of insults and threats as individual (IND), group (GRP), and other (OTH).\\nIndividual (IND): Posts targeting an individual. It can be a a famous person, a named individual or an unnamed participant in the conversation. Insults and threats targeted at individuals are often defined as cyberbulling.\\nGroup (GRP): The target of these offensive posts is a group of people considered as a unity due to the same ethnicity, gender or sexual orientation, political affiliation, religious belief, or other common characteristic. Many of the insults and threats targeted at a group correspond to what is commonly understood as hate speech.\\nOther (OTH): The target of these offensive posts does not belong to any of the previous two categories (e.g. an organization, a situation, an event, or an issue).\\nData Collection\\nThe data included in OLID has been collected from Twitter. We retrieved the data using the Twitter API by searching for keywords and constructions that are often included in offensive messages, such as `she is' or `to:BreitBartNews'. We carried out a first round of trial annotation of 300 instances with six experts. The goal of the trial annotation was to 1) evaluate the proposed tagset; 2) evaluate the data retrieval method; and 3) create a gold standard with instances that could be used as test questions in the training and test setting annotation which was carried out using crowdsourcing. The breakdown of keywords and their offensive content in the trial data of 300 tweets is shown in Table TABREF14 . We included a left (@NewYorker) and far-right (@BreitBartNews) news accounts because there tends to be political offense in the comments. One of the best offensive keywords was tweets that were flagged as not being safe by the Twitter `safe' filter (the `-' indicates `not safe'). The vast majority of content on Twitter is not offensive so we tried different strategies to keep a reasonable number of tweets in the offensive class amounting to around 30% of the dataset including excluding some keywords that were not high in offensive content such as `they are` and `to:NewYorker`. Although `he is' is lower in offensive content we kept it as a keyword to avoid gender bias. In addition to the keywords in the trial set, we searched for more political keywords which tend to be higher in offensive content, and sampled our dataset such that 50% of the the tweets come from political keywords and 50% come from non-political keywords. In addition to the keywords `gun control', and `to:BreitbartNews', political keywords used to collect these tweets are `MAGA', `antifa', `conservative' and `liberal'. We computed Fliess' INLINEFORM0 on the trial set for the five annotators on 21 of the tweets. INLINEFORM1 is .83 for Layer A (OFF vs NOT) indicating high agreement. As to normalization and anonymization, no user metadata or Twitter IDs have been stored, and URLs and Twitter mentions have been substituted to placeholders. We follow prior work in related areas (burnap2015cyber,davidson2017automated) and annotate our data using crowdsourcing using the platform Figure Eight. We ensure data quality by: 1) we only received annotations from individuals who were experienced in the platform; and 2) we used test questions to discard annotations of individuals who did not reach a certain threshold. Each instance in the dataset was annotated by multiple annotators and inter-annotator agreement has been calculated. We first acquired two annotations for each instance. In case of 100% agreement, we considered these as acceptable annotations, and in case of disagreement, we requested more annotations until the agreement was above 66%. After the crowdsourcing annotation, we used expert adjudication to guarantee the quality of the annotation. The breakdown of the data into training and testing for the labels from each level is shown in Table TABREF15 .\\nExperiments and Evaluation\\nWe assess our dataset using traditional and deep learning methods. Our simplest model is a linear SVM trained on word unigrams. SVMs have produced state-of-the-art results for many text classification tasks BIBREF13 . We also train a bidirectional Long Short-Term-Memory (BiLSTM) model, which we adapted from the sentiment analysis system of sentimentSystem,rasooli2018cross and altered to predict offensive labels instead. It consists of (1) an input embedding layer, (2) a bidirectional LSTM layer, (3) an average pooling layer of input features. The concatenation of the LSTM's and average pool layer is passed through a dense layer and the output is passed through a softmax function. We set two input channels for the input embedding layers: pre-trained FastText embeddings BIBREF14 , as well as updatable embeddings learned by the model during training. Finally, we also apply a Convolutional Neural Network (CNN) model based on the architecture of BIBREF15 , using the same multi-channel inputs as the above BiLSTM.\\nOur models are trained on the training data, and evaluated by predicting the labels for the held-out test set. The distribution is described in Table TABREF15 . We evaluate and compare the models using the macro-averaged F1-score as the label distribution is highly imbalanced. Per-class Precision (P), Recall (R), and F1-score (F1), also with other averaged metrics are also reported. The models are compared against baselines of predicting all labels as the majority or minority classes.\\nOffensive Language Detection\\nThe performance on discriminating between offensive (OFF) and non-offensive (NOT) posts is reported in Table TABREF18 . We can see that all systems perform significantly better than chance, with the neural models being substantially better than the SVM. The CNN outperforms the RNN model, achieving a macro-F1 score of 0.80.\\nCategorization of Offensive Language\\nIn this experiment, the two systems were trained to discriminate between insults and threats (TIN) and untargeted (UNT) offenses, which generally refer to profanity. The results are shown in Table TABREF19 .\\nThe CNN system achieved higher performance in this experiment compared to the BiLSTM, with a macro-F1 score of 0.69. All systems performed better at identifying target and threats (TIN) than untargeted offenses (UNT).\\nOffensive Language Target Identification\\nThe results of the offensive target identification experiment are reported in Table TABREF20 . Here the systems were trained to distinguish between three targets: a group (GRP), an individual (IND), or others (OTH). All three models achieved similar results far surpassing the random baselines, with a slight performance edge for the neural models.\\nThe performance of all systems for the OTH class is 0. This poor performances can be explained by two main factors. First, unlike the two other classes, OTH is a heterogeneous collection of targets. It includes offensive tweets targeted at organizations, situations, events, etc. making it more challenging for systems to learn discriminative properties of this class. Second, this class contains fewer training instances than the other two. There are only 395 instances in OTH, and 1,075 in GRP, and 2,407 in IND.\\nConclusion and Future Work\\nThis paper presents OLID, a new dataset with annotation of type and target of offensive language. OLID is the official dataset of the shared task SemEval 2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval) BIBREF16 . In OffensEval, each annotation level in OLID is an independent sub-task. The dataset contains 14,100 tweets and is released freely to the research community. To the best of our knowledge, this is the first dataset to contain annotation of type and target of offenses in social media and it opens several new avenues for research in this area. We present baseline experiments using SVMs and neural networks to identify the offensive tweets, discriminate between insults, threats, and profanity, and finally to identify the target of the offensive messages. The results show that this is a challenging task. A CNN-based sentence classifier achieved the best results in all three sub-tasks.\\nIn future work, we would like to make a cross-corpus comparison of OLID and datasets annotated for similar tasks such as aggression identification BIBREF2 and hate speech detection BIBREF8 . This comparison is, however, far from trivial as the annotation of OLID is different.\\nAcknowledgments\\nThe research presented in this paper was partially supported by an ERAS fellowship awarded by the University of Wolverhampton.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_extension",
   "language": "python",
   "name": "context_extension"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
